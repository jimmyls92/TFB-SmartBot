{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"database_intents.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = df['Intent type'].unique()\n",
    "# Usar get_dummies en vez de las 3 funciones\n",
    "df_oh = pd.concat([df, pd.get_dummies(df['Intent type'])], axis = 1)\n",
    "df_oh = df_oh[['Intent type', 'Sentence', 'Greeting', 'Search', 'Suggestions', 'Farewell',\n",
    "      'Options', 'Headers']]\n",
    "\n",
    "# df_train, df_test = train_test_split(df_oh, train_size = 0.7, test_size = 0.3, random_state = 42,\n",
    "#                                     shuffle = True, stratify = df_oh['Intent type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens = 2000, output_mode='tf-idf')\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(df_oh['Sentence']).batch(32)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump({'config': vectorizer.get_config(),\n",
    "             'weights': vectorizer.get_weights()}\n",
    "            , open(\"tv_layer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x0000014940798158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from_disk = pickle.load(open(\"tv_layer.pkl\", \"rb\"))\n",
    "new_v = TextVectorization.from_config(from_disk['config'])\n",
    "new_v.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "new_v.set_weights(from_disk['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.50d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 103 words (10 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 50\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 50)          5750      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         32128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 219,260\n",
      "Trainable params: 213,510\n",
      "Non-trainable params: 5,750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = vectorizer(np.array([[s] for s in df_train['Sentence']])).numpy()\n",
    "# X_test = vectorizer(np.array([[s] for s in df_test['Sentence']])).numpy()\n",
    "\n",
    "# y_train = np.array(df_train.iloc[:, 2:])\n",
    "# y_test = np.array(df_test.iloc[:, 2:])\n",
    "\n",
    "X = vectorizer(np.array([[s] for s in df_oh['Sentence']])).numpy()\n",
    "y = np.array(df_oh.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 1.8678 - acc: 0.0840\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.5463 - acc: 0.3529\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4794 - acc: 0.4202\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.4299 - acc: 0.4286\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2902 - acc: 0.5210\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2253 - acc: 0.5630\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1485 - acc: 0.5714\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0398 - acc: 0.6807\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0815 - acc: 0.5798\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2538 - acc: 0.5294\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1564 - acc: 0.5378\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8948 - acc: 0.7227\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8320 - acc: 0.7227\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7346 - acc: 0.7563\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6691 - acc: 0.7983\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8229 - acc: 0.7059\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7492 - acc: 0.7059\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6489 - acc: 0.7479\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6522 - acc: 0.7815\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5171 - acc: 0.8319\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4210 - acc: 0.8824\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4164 - acc: 0.8739\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3741 - acc: 0.8824\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4548 - acc: 0.8319\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4693 - acc: 0.8403\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5780 - acc: 0.7983\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6204 - acc: 0.7395\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4961 - acc: 0.8067\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3738 - acc: 0.8655\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3517 - acc: 0.9076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14942282b00>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\", optimizer = \"rmsprop\", metrics = [\"acc\"]\n",
    ")\n",
    "model.fit(X, y, batch_size = 128, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('embbedings.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('embbedings.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Search'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = new_v(string_input)\n",
    "preds = model(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "probabilities = end_to_end_model.predict(\n",
    "    [[\"I want to get information about Barcelona\"]]\n",
    ")\n",
    "\n",
    "class_names[np.argmax(probabilities[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Greeting'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_2 = end_to_end_model.predict(\n",
    "    [[\"Hello, how are you?\"]]\n",
    ")\n",
    "class_names[np.argmax(probabilities_2[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00394532, 0.764308  , 0.18421847, 0.01112663, 0.01940633,\n",
       "        0.01699523]], dtype=float32)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82958037, 0.06267737, 0.05873773, 0.01296815, 0.02891696,\n",
       "        0.00711944]], dtype=float32)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No lo he probado en el chatbot, para hacer pruebas usar el módulo de arriba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHATBOT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    \n",
    "    input_text = input()\n",
    "    \n",
    "    test = pd.DataFrame(data = {'Sentence': [input_text]})\n",
    "    df_test_proc, test_proc = processing(test, cv = cv)\n",
    "    scipy.sparse.csr_matrix.sort_indices(test_proc)\n",
    "    \n",
    "    gret_prob = mlp_greeting.predict(test_proc)\n",
    "    search_prob = mlp_search.predict(test_proc)\n",
    "    sugg_prob = mlp_suggestion.predict(test_proc)\n",
    "    farewell_prob = mlp_farewell.predict(test_proc)\n",
    "    \n",
    "    probs = [gret_prob, search_prob, sugg_prob, farewell_prob]\n",
    "    print(probs)\n",
    "    idx = np.argmax(probs)\n",
    "    \n",
    "    if idx == 0:\n",
    "        print(\"Esto es un saludo\")\n",
    "    elif idx == 1:\n",
    "        print(\"Esto es una búsqueda\")\n",
    "    elif idx == 2:\n",
    "        print(\"Esto es una sugerencia\")\n",
    "    else:\n",
    "        print(\"Esto es una despedida\")\n",
    "        \n",
    "#     print('¿Hemos acertado?')\n",
    "    \n",
    "#     respuesta = input()\n",
    "#     if (respuesta == 'No' or respuesta == 'no'):\n",
    "#         probs = np.delete(probs, idx)\n",
    "#         idx_2 = np.argmax(probs)\n",
    "        \n",
    "#         if idx == 0:\n",
    "#             if idx_2 == 0:\n",
    "#                 print(\"Esto es una búsqueda\")\n",
    "#             else:\n",
    "#                 print(\"Esto es una sugerencia\")\n",
    "#         elif idx == 1:\n",
    "#             if idx_2 == 0:\n",
    "#                 print(\"Esto es un saludo\")\n",
    "#             else:\n",
    "#                 print(\"Esto es una sugerencia\")\n",
    "#         else:\n",
    "#             if idx_2 == 0:\n",
    "#                 print(\"Esto es un saludo\")\n",
    "#             else:\n",
    "#                 print(\"Esto es una búsqueda\")\n",
    "#     else:\n",
    "#         print('¡Genial! ¡Hemos acertado!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "[array([[0.8040894]], dtype=float32), array([[0.00038779]], dtype=float32), array([[3.612887e-05]], dtype=float32), array([[0.00043699]], dtype=float32)]\n",
      "Esto es un saludo\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Opciones\n",
    " * Mostrar un comando *!options* que te de las opciones para hacer.\n",
    " * Detectar un intent\n",
    " * Mostrarlo al inicio\n",
    "\n",
    "\n",
    "* Headers\n",
    " * Dar las opciones una vez se detecta intent de búsqueda búsqueda\n",
    "   * *What is data science?* Y mostrarle los heades para qué elija qué queire saber \n",
    " * Intent nuevo de header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Intent_detection_function(keyboard):\n",
    "    gret_prob = mlp_greeting.predict_proba(test_proc)\n",
    "    search_prob = mlp_search.predict_proba(test_proc)\n",
    "    sugg_prob = mlp_suggestion.predict_proba(test_proc)\n",
    "    farewell_prob = mlp_farewell.predict_proba(test_proc)\n",
    "    cv = joblib.load(\"vectorizer.pkl\")\n",
    "\n",
    "\n",
    "    input_text = pd.DataFrame(data={'Sentence': [keyboard]})\n",
    "    _, test_proc = cv.transform(input_text['Sentence'])\n",
    "    #df_test_proc, test_proc = processing(test, cv=cv)\n",
    "\n",
    "    test_proc = test_proc.toarray()\n",
    "\n",
    "    gret_prob = mlp_greeting.predict(test_proc)\n",
    "\n",
    "    search_prob = mlp_search.predict(test_proc)\n",
    "    sugg_prob = mlp_suggestion.predict(test_proc)\n",
    "    fare_prob = mlp_farewell.predict(test_proc)\n",
    "\n",
    "\n",
    "    probs = [gret_prob, search_prob, sugg_prob, fare_prob]\n",
    "    print(probs)\n",
    "    idx = np.argmax(probs)\n",
    "\n",
    "    if idx == 0:\n",
    "        intent = \"Greeting\"\n",
    "        keyword = None\n",
    "    elif idx == 1:\n",
    "        intent = \"Search\"\n",
    "        keyword = getEntities(keyboard)\n",
    "    elif idx == 2:\n",
    "        intent = \"Suggestions\"\n",
    "        keyword = getEntities(keyboard)\n",
    "    elif idx == 3:\n",
    "        intent = \"Farewell\"\n",
    "        keyword = None\n",
    "\n",
    "    return intent, keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Intent_detection_function()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
