{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"database_intents.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar get_dummies en vez de las 3 funciones\n",
    "df_oh = pd.concat([df, pd.get_dummies(df['Intent type'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_oh, train_size = 0.7, test_size = 0.3, random_state = 42,\n",
    "                                    shuffle = True, stratify = df_oh['Intent type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.99, max_features=100, min_df=0,\n",
       "        ngram_range=(1, 4), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=[], strip_accents='ascii', sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = TfidfVectorizer(\n",
    "    stop_words= stopwords,\n",
    "    ngram_range=(1, 4),\n",
    "    strip_accents='ascii',\n",
    "    max_df=0.99,\n",
    "    min_df=0,\n",
    "    max_features=100\n",
    "    )\n",
    "cv.fit(df_train[\"Sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(cv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(df, pretreatment = False, Tfidf = True, cv = None, stopwords = []):\n",
    "  # Normalizamos y limpiamos el corpus \n",
    "  if pretreatment == True:\n",
    "    df[\"Sentence\"] = df['Sentence'].apply(lambda x: word_treatment(x))\n",
    "    print(\"El corpus ha sido pretratado\")\n",
    "    \n",
    "     # Transformamos nuestro corpus a un vector Tfidf\n",
    "  if Tfidf == True:\n",
    "\n",
    "    if cv == None:\n",
    "      cv = TfidfVectorizer(\n",
    "        stop_words= stopwords,\n",
    "        ngram_range=(1, 4),\n",
    "        strip_accents='ascii',\n",
    "        max_df=0.99,\n",
    "        min_df=0,\n",
    "        max_features=100\n",
    "      )\n",
    "      cv.fit(df[\"Sentence\"])\n",
    "      X = cv.transform(df[\"Sentence\"])\n",
    "      print(\"Se ha realizado una vectorización Tfidf\")\n",
    "      return df, X, cv\n",
    "\n",
    "    else:\n",
    "      X = cv.transform(df[\"Sentence\"])\n",
    "      #print(\"Se ha realizado una vectorización Tfidf basado en el corpus suministrado por cv\")\n",
    "    return df, X\n",
    "  else:\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha realizado una vectorización Tfidf\n"
     ]
    }
   ],
   "source": [
    "df_train, X_train, cv = processing(df_train)\n",
    "df_test, X_test = processing(df_test, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[[\"Greeting\",\"Search\",\"Suggestions\"]]\n",
    "y_test = df_test[[\"Greeting\",\"Search\",\"Suggestions\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, train_size=0.7, \n",
    "test_size=0.3, random_state=42, shuffle=True, stratify=df_train[\"Intent type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape= X_train.shape[1]\n",
    "\n",
    "X_train.sort_indices()\n",
    "X_validation.sort_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_greeting(shape):\n",
    "# define our MLP network\n",
    "    initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=42)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=shape, kernel_initializer = initializer, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2, activation=\"relu\"))\n",
    "# check to see if the regression node should be added\n",
    "    #if regress:\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "    #Compile model\n",
    "    opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss='binary_crossentropy', metrics = [\"accuracy\"], optimizer=opt)\n",
    "# return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_8/dense_40/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_8/dense_40/embedding_lookup_sparse/Reshape:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_8/dense_40/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 - 1s - loss: 0.7284 - accuracy: 0.2542 - val_loss: 0.7049 - val_accuracy: 0.4231\n",
      "Epoch 2/200\n",
      "2/2 - 0s - loss: 0.7058 - accuracy: 0.4576 - val_loss: 0.7028 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "2/2 - 0s - loss: 0.7075 - accuracy: 0.4576 - val_loss: 0.7010 - val_accuracy: 0.5385\n",
      "Epoch 4/200\n",
      "2/2 - 0s - loss: 0.7084 - accuracy: 0.4576 - val_loss: 0.6993 - val_accuracy: 0.5385\n",
      "Epoch 5/200\n",
      "2/2 - 0s - loss: 0.7017 - accuracy: 0.4915 - val_loss: 0.6976 - val_accuracy: 0.5769\n",
      "Epoch 6/200\n",
      "2/2 - 0s - loss: 0.7050 - accuracy: 0.4915 - val_loss: 0.6959 - val_accuracy: 0.5385\n",
      "Epoch 7/200\n",
      "2/2 - 0s - loss: 0.6984 - accuracy: 0.4915 - val_loss: 0.6943 - val_accuracy: 0.5769\n",
      "Epoch 8/200\n",
      "2/2 - 0s - loss: 0.6993 - accuracy: 0.4915 - val_loss: 0.6928 - val_accuracy: 0.6154\n",
      "Epoch 9/200\n",
      "2/2 - 0s - loss: 0.6981 - accuracy: 0.5593 - val_loss: 0.6915 - val_accuracy: 0.6538\n",
      "Epoch 10/200\n",
      "2/2 - 0s - loss: 0.6888 - accuracy: 0.7119 - val_loss: 0.6903 - val_accuracy: 0.6923\n",
      "Epoch 11/200\n",
      "2/2 - 0s - loss: 0.6930 - accuracy: 0.6102 - val_loss: 0.6894 - val_accuracy: 0.6923\n",
      "Epoch 12/200\n",
      "2/2 - 0s - loss: 0.6913 - accuracy: 0.6271 - val_loss: 0.6886 - val_accuracy: 0.7692\n",
      "Epoch 13/200\n",
      "2/2 - 0s - loss: 0.6955 - accuracy: 0.6610 - val_loss: 0.6879 - val_accuracy: 0.7692\n",
      "Epoch 14/200\n",
      "2/2 - 0s - loss: 0.6860 - accuracy: 0.7119 - val_loss: 0.6873 - val_accuracy: 0.6538\n",
      "Epoch 15/200\n",
      "2/2 - 0s - loss: 0.6876 - accuracy: 0.7458 - val_loss: 0.6868 - val_accuracy: 0.6538\n",
      "Epoch 16/200\n",
      "2/2 - 0s - loss: 0.6827 - accuracy: 0.7966 - val_loss: 0.6864 - val_accuracy: 0.6923\n",
      "Epoch 17/200\n",
      "2/2 - 0s - loss: 0.6850 - accuracy: 0.7797 - val_loss: 0.6860 - val_accuracy: 0.6923\n",
      "Epoch 18/200\n",
      "2/2 - 0s - loss: 0.6856 - accuracy: 0.7119 - val_loss: 0.6855 - val_accuracy: 0.6923\n",
      "Epoch 19/200\n",
      "2/2 - 0s - loss: 0.6856 - accuracy: 0.7119 - val_loss: 0.6851 - val_accuracy: 0.7308\n",
      "Epoch 20/200\n",
      "2/2 - 0s - loss: 0.6875 - accuracy: 0.7458 - val_loss: 0.6847 - val_accuracy: 0.7308\n",
      "Epoch 21/200\n",
      "2/2 - 0s - loss: 0.6832 - accuracy: 0.7797 - val_loss: 0.6843 - val_accuracy: 0.7308\n",
      "Epoch 22/200\n",
      "2/2 - 0s - loss: 0.6839 - accuracy: 0.7288 - val_loss: 0.6838 - val_accuracy: 0.7308\n",
      "Epoch 23/200\n",
      "2/2 - 0s - loss: 0.6825 - accuracy: 0.7966 - val_loss: 0.6834 - val_accuracy: 0.7308\n",
      "Epoch 24/200\n",
      "2/2 - 0s - loss: 0.6837 - accuracy: 0.7119 - val_loss: 0.6830 - val_accuracy: 0.7308\n",
      "Epoch 25/200\n",
      "2/2 - 0s - loss: 0.6757 - accuracy: 0.8305 - val_loss: 0.6825 - val_accuracy: 0.7308\n",
      "Epoch 26/200\n",
      "2/2 - 0s - loss: 0.6796 - accuracy: 0.7966 - val_loss: 0.6821 - val_accuracy: 0.7308\n",
      "Epoch 27/200\n",
      "2/2 - 0s - loss: 0.6792 - accuracy: 0.7797 - val_loss: 0.6817 - val_accuracy: 0.7308\n",
      "Epoch 28/200\n",
      "2/2 - 0s - loss: 0.6768 - accuracy: 0.8136 - val_loss: 0.6813 - val_accuracy: 0.7308\n",
      "Epoch 29/200\n",
      "2/2 - 0s - loss: 0.6793 - accuracy: 0.7797 - val_loss: 0.6808 - val_accuracy: 0.7308\n",
      "Epoch 30/200\n",
      "2/2 - 0s - loss: 0.6807 - accuracy: 0.7119 - val_loss: 0.6804 - val_accuracy: 0.7308\n",
      "Epoch 31/200\n",
      "2/2 - 0s - loss: 0.6800 - accuracy: 0.7627 - val_loss: 0.6800 - val_accuracy: 0.7308\n",
      "Epoch 32/200\n",
      "2/2 - 0s - loss: 0.6780 - accuracy: 0.7797 - val_loss: 0.6796 - val_accuracy: 0.7308\n",
      "Epoch 33/200\n",
      "2/2 - 0s - loss: 0.6787 - accuracy: 0.7458 - val_loss: 0.6792 - val_accuracy: 0.7308\n",
      "Epoch 34/200\n",
      "2/2 - 0s - loss: 0.6745 - accuracy: 0.7966 - val_loss: 0.6788 - val_accuracy: 0.7308\n",
      "Epoch 35/200\n",
      "2/2 - 0s - loss: 0.6720 - accuracy: 0.8136 - val_loss: 0.6783 - val_accuracy: 0.7308\n",
      "Epoch 36/200\n",
      "2/2 - 0s - loss: 0.6756 - accuracy: 0.7797 - val_loss: 0.6779 - val_accuracy: 0.7308\n",
      "Epoch 37/200\n",
      "2/2 - 0s - loss: 0.6742 - accuracy: 0.7797 - val_loss: 0.6774 - val_accuracy: 0.7308\n",
      "Epoch 38/200\n",
      "2/2 - 0s - loss: 0.6763 - accuracy: 0.7627 - val_loss: 0.6770 - val_accuracy: 0.7308\n",
      "Epoch 39/200\n",
      "2/2 - 0s - loss: 0.6737 - accuracy: 0.7797 - val_loss: 0.6765 - val_accuracy: 0.7308\n",
      "Epoch 40/200\n",
      "2/2 - 0s - loss: 0.6713 - accuracy: 0.7966 - val_loss: 0.6761 - val_accuracy: 0.7308\n",
      "Epoch 41/200\n",
      "2/2 - 0s - loss: 0.6731 - accuracy: 0.7627 - val_loss: 0.6756 - val_accuracy: 0.7308\n",
      "Epoch 42/200\n",
      "2/2 - 0s - loss: 0.6725 - accuracy: 0.7797 - val_loss: 0.6752 - val_accuracy: 0.7308\n",
      "Epoch 43/200\n",
      "2/2 - 0s - loss: 0.6702 - accuracy: 0.7966 - val_loss: 0.6747 - val_accuracy: 0.7308\n",
      "Epoch 44/200\n",
      "2/2 - 0s - loss: 0.6724 - accuracy: 0.7458 - val_loss: 0.6742 - val_accuracy: 0.7308\n",
      "Epoch 45/200\n",
      "2/2 - 0s - loss: 0.6693 - accuracy: 0.7797 - val_loss: 0.6738 - val_accuracy: 0.7308\n",
      "Epoch 46/200\n",
      "2/2 - 0s - loss: 0.6699 - accuracy: 0.7966 - val_loss: 0.6733 - val_accuracy: 0.7308\n",
      "Epoch 47/200\n",
      "2/2 - 0s - loss: 0.6688 - accuracy: 0.7797 - val_loss: 0.6729 - val_accuracy: 0.7308\n",
      "Epoch 48/200\n",
      "2/2 - 0s - loss: 0.6694 - accuracy: 0.7966 - val_loss: 0.6725 - val_accuracy: 0.7308\n",
      "Epoch 49/200\n",
      "2/2 - 0s - loss: 0.6691 - accuracy: 0.7797 - val_loss: 0.6720 - val_accuracy: 0.7308\n",
      "Epoch 50/200\n",
      "2/2 - 0s - loss: 0.6687 - accuracy: 0.7797 - val_loss: 0.6716 - val_accuracy: 0.7308\n",
      "Epoch 51/200\n",
      "2/2 - 0s - loss: 0.6666 - accuracy: 0.7966 - val_loss: 0.6712 - val_accuracy: 0.7308\n",
      "Epoch 52/200\n",
      "2/2 - 0s - loss: 0.6675 - accuracy: 0.7797 - val_loss: 0.6707 - val_accuracy: 0.7308\n",
      "Epoch 53/200\n",
      "2/2 - 0s - loss: 0.6655 - accuracy: 0.7966 - val_loss: 0.6702 - val_accuracy: 0.7308\n",
      "Epoch 54/200\n",
      "2/2 - 0s - loss: 0.6682 - accuracy: 0.7627 - val_loss: 0.6698 - val_accuracy: 0.7308\n",
      "Epoch 55/200\n",
      "2/2 - 0s - loss: 0.6630 - accuracy: 0.8305 - val_loss: 0.6693 - val_accuracy: 0.7308\n",
      "Epoch 56/200\n",
      "2/2 - 0s - loss: 0.6627 - accuracy: 0.7966 - val_loss: 0.6688 - val_accuracy: 0.7308\n",
      "Epoch 57/200\n",
      "2/2 - 0s - loss: 0.6612 - accuracy: 0.8136 - val_loss: 0.6683 - val_accuracy: 0.7308\n",
      "Epoch 58/200\n",
      "2/2 - 0s - loss: 0.6613 - accuracy: 0.7966 - val_loss: 0.6678 - val_accuracy: 0.7308\n",
      "Epoch 59/200\n",
      "2/2 - 0s - loss: 0.6619 - accuracy: 0.7966 - val_loss: 0.6674 - val_accuracy: 0.7308\n",
      "Epoch 60/200\n",
      "2/2 - 0s - loss: 0.6641 - accuracy: 0.7797 - val_loss: 0.6669 - val_accuracy: 0.7308\n",
      "Epoch 61/200\n",
      "2/2 - 0s - loss: 0.6649 - accuracy: 0.7627 - val_loss: 0.6665 - val_accuracy: 0.7308\n",
      "Epoch 62/200\n",
      "2/2 - 0s - loss: 0.6595 - accuracy: 0.8136 - val_loss: 0.6661 - val_accuracy: 0.7308\n",
      "Epoch 63/200\n",
      "2/2 - 0s - loss: 0.6622 - accuracy: 0.7797 - val_loss: 0.6657 - val_accuracy: 0.7308\n",
      "Epoch 64/200\n",
      "2/2 - 0s - loss: 0.6588 - accuracy: 0.7797 - val_loss: 0.6653 - val_accuracy: 0.7308\n",
      "Epoch 65/200\n",
      "2/2 - 0s - loss: 0.6619 - accuracy: 0.7797 - val_loss: 0.6649 - val_accuracy: 0.7308\n",
      "Epoch 66/200\n",
      "2/2 - 0s - loss: 0.6598 - accuracy: 0.7797 - val_loss: 0.6645 - val_accuracy: 0.7308\n",
      "Epoch 67/200\n",
      "2/2 - 0s - loss: 0.6603 - accuracy: 0.7627 - val_loss: 0.6641 - val_accuracy: 0.7308\n",
      "Epoch 68/200\n",
      "2/2 - 0s - loss: 0.6570 - accuracy: 0.7797 - val_loss: 0.6637 - val_accuracy: 0.7308\n",
      "Epoch 69/200\n",
      "2/2 - 0s - loss: 0.6566 - accuracy: 0.7966 - val_loss: 0.6632 - val_accuracy: 0.7308\n",
      "Epoch 70/200\n",
      "2/2 - 0s - loss: 0.6580 - accuracy: 0.7797 - val_loss: 0.6628 - val_accuracy: 0.7308\n",
      "Epoch 71/200\n",
      "2/2 - 0s - loss: 0.6567 - accuracy: 0.7966 - val_loss: 0.6624 - val_accuracy: 0.7308\n",
      "Epoch 72/200\n",
      "2/2 - 0s - loss: 0.6573 - accuracy: 0.7797 - val_loss: 0.6619 - val_accuracy: 0.7308\n",
      "Epoch 73/200\n",
      "2/2 - 0s - loss: 0.6538 - accuracy: 0.8136 - val_loss: 0.6614 - val_accuracy: 0.7308\n",
      "Epoch 74/200\n",
      "2/2 - 0s - loss: 0.6584 - accuracy: 0.7627 - val_loss: 0.6609 - val_accuracy: 0.7308\n",
      "Epoch 75/200\n",
      "2/2 - 0s - loss: 0.6559 - accuracy: 0.7797 - val_loss: 0.6605 - val_accuracy: 0.7308\n",
      "Epoch 76/200\n",
      "2/2 - 0s - loss: 0.6556 - accuracy: 0.7797 - val_loss: 0.6600 - val_accuracy: 0.7308\n",
      "Epoch 77/200\n",
      "2/2 - 0s - loss: 0.6567 - accuracy: 0.7797 - val_loss: 0.6595 - val_accuracy: 0.7308\n",
      "Epoch 78/200\n",
      "2/2 - 0s - loss: 0.6586 - accuracy: 0.7458 - val_loss: 0.6591 - val_accuracy: 0.7308\n",
      "Epoch 79/200\n",
      "2/2 - 0s - loss: 0.6573 - accuracy: 0.7627 - val_loss: 0.6587 - val_accuracy: 0.7308\n",
      "Epoch 80/200\n",
      "2/2 - 0s - loss: 0.6514 - accuracy: 0.7966 - val_loss: 0.6583 - val_accuracy: 0.7308\n",
      "Epoch 81/200\n",
      "2/2 - 0s - loss: 0.6536 - accuracy: 0.7797 - val_loss: 0.6580 - val_accuracy: 0.7308\n",
      "Epoch 82/200\n",
      "2/2 - 0s - loss: 0.6548 - accuracy: 0.7627 - val_loss: 0.6576 - val_accuracy: 0.7308\n",
      "Epoch 83/200\n",
      "2/2 - 0s - loss: 0.6527 - accuracy: 0.7797 - val_loss: 0.6572 - val_accuracy: 0.7308\n",
      "Epoch 84/200\n",
      "2/2 - 0s - loss: 0.6499 - accuracy: 0.7966 - val_loss: 0.6568 - val_accuracy: 0.7308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "2/2 - 0s - loss: 0.6521 - accuracy: 0.7797 - val_loss: 0.6564 - val_accuracy: 0.7308\n",
      "Epoch 86/200\n",
      "2/2 - 0s - loss: 0.6516 - accuracy: 0.7797 - val_loss: 0.6560 - val_accuracy: 0.7308\n",
      "Epoch 87/200\n",
      "2/2 - 0s - loss: 0.6507 - accuracy: 0.7966 - val_loss: 0.6556 - val_accuracy: 0.7308\n",
      "Epoch 88/200\n",
      "2/2 - 0s - loss: 0.6539 - accuracy: 0.7627 - val_loss: 0.6553 - val_accuracy: 0.7308\n",
      "Epoch 89/200\n",
      "2/2 - 0s - loss: 0.6459 - accuracy: 0.7966 - val_loss: 0.6549 - val_accuracy: 0.7308\n",
      "Epoch 90/200\n",
      "2/2 - 0s - loss: 0.6513 - accuracy: 0.7797 - val_loss: 0.6545 - val_accuracy: 0.7308\n",
      "Epoch 91/200\n",
      "2/2 - 0s - loss: 0.6501 - accuracy: 0.7627 - val_loss: 0.6540 - val_accuracy: 0.7308\n",
      "Epoch 92/200\n",
      "2/2 - 0s - loss: 0.6474 - accuracy: 0.7797 - val_loss: 0.6536 - val_accuracy: 0.7308\n",
      "Epoch 93/200\n",
      "2/2 - 0s - loss: 0.6467 - accuracy: 0.7966 - val_loss: 0.6532 - val_accuracy: 0.7308\n",
      "Epoch 94/200\n",
      "2/2 - 0s - loss: 0.6456 - accuracy: 0.7797 - val_loss: 0.6528 - val_accuracy: 0.7308\n",
      "Epoch 95/200\n",
      "2/2 - 0s - loss: 0.6429 - accuracy: 0.7966 - val_loss: 0.6523 - val_accuracy: 0.7308\n",
      "Epoch 96/200\n",
      "2/2 - 0s - loss: 0.6445 - accuracy: 0.7797 - val_loss: 0.6519 - val_accuracy: 0.7308\n",
      "Epoch 97/200\n",
      "2/2 - 0s - loss: 0.6454 - accuracy: 0.7966 - val_loss: 0.6514 - val_accuracy: 0.7308\n",
      "Epoch 98/200\n",
      "2/2 - 0s - loss: 0.6443 - accuracy: 0.7797 - val_loss: 0.6510 - val_accuracy: 0.7308\n",
      "Epoch 99/200\n",
      "2/2 - 0s - loss: 0.6476 - accuracy: 0.7627 - val_loss: 0.6507 - val_accuracy: 0.7308\n",
      "Epoch 100/200\n",
      "2/2 - 0s - loss: 0.6412 - accuracy: 0.7966 - val_loss: 0.6502 - val_accuracy: 0.7308\n",
      "Epoch 101/200\n",
      "2/2 - 0s - loss: 0.6445 - accuracy: 0.7627 - val_loss: 0.6498 - val_accuracy: 0.7308\n",
      "Epoch 102/200\n",
      "2/2 - 0s - loss: 0.6411 - accuracy: 0.7797 - val_loss: 0.6493 - val_accuracy: 0.7308\n",
      "Epoch 103/200\n",
      "2/2 - 0s - loss: 0.6307 - accuracy: 0.8644 - val_loss: 0.6488 - val_accuracy: 0.7308\n",
      "Epoch 104/200\n",
      "2/2 - 0s - loss: 0.6417 - accuracy: 0.7797 - val_loss: 0.6483 - val_accuracy: 0.7308\n",
      "Epoch 105/200\n",
      "2/2 - 0s - loss: 0.6406 - accuracy: 0.7966 - val_loss: 0.6478 - val_accuracy: 0.7308\n",
      "Epoch 106/200\n",
      "2/2 - 0s - loss: 0.6406 - accuracy: 0.7797 - val_loss: 0.6473 - val_accuracy: 0.7308\n",
      "Epoch 107/200\n",
      "2/2 - 0s - loss: 0.6290 - accuracy: 0.8305 - val_loss: 0.6468 - val_accuracy: 0.7308\n",
      "Epoch 108/200\n",
      "2/2 - 0s - loss: 0.6393 - accuracy: 0.7797 - val_loss: 0.6463 - val_accuracy: 0.7308\n",
      "Epoch 109/200\n",
      "2/2 - 0s - loss: 0.6321 - accuracy: 0.8475 - val_loss: 0.6458 - val_accuracy: 0.6923\n",
      "Epoch 110/200\n",
      "2/2 - 0s - loss: 0.6432 - accuracy: 0.7627 - val_loss: 0.6453 - val_accuracy: 0.6923\n",
      "Epoch 111/200\n",
      "2/2 - 0s - loss: 0.6428 - accuracy: 0.7627 - val_loss: 0.6448 - val_accuracy: 0.6923\n",
      "Epoch 112/200\n",
      "2/2 - 0s - loss: 0.6381 - accuracy: 0.7966 - val_loss: 0.6443 - val_accuracy: 0.6923\n",
      "Epoch 113/200\n",
      "2/2 - 0s - loss: 0.6347 - accuracy: 0.7797 - val_loss: 0.6437 - val_accuracy: 0.6923\n",
      "Epoch 114/200\n",
      "2/2 - 0s - loss: 0.6287 - accuracy: 0.7966 - val_loss: 0.6432 - val_accuracy: 0.6923\n",
      "Epoch 115/200\n",
      "2/2 - 0s - loss: 0.6309 - accuracy: 0.8136 - val_loss: 0.6426 - val_accuracy: 0.6923\n",
      "Epoch 116/200\n",
      "2/2 - 0s - loss: 0.6294 - accuracy: 0.8136 - val_loss: 0.6420 - val_accuracy: 0.6923\n",
      "Epoch 117/200\n",
      "2/2 - 0s - loss: 0.6340 - accuracy: 0.7966 - val_loss: 0.6415 - val_accuracy: 0.6923\n",
      "Epoch 118/200\n",
      "2/2 - 0s - loss: 0.6298 - accuracy: 0.8136 - val_loss: 0.6410 - val_accuracy: 0.6923\n",
      "Epoch 119/200\n",
      "2/2 - 0s - loss: 0.6207 - accuracy: 0.8644 - val_loss: 0.6405 - val_accuracy: 0.6923\n",
      "Epoch 120/200\n",
      "2/2 - 0s - loss: 0.6348 - accuracy: 0.7797 - val_loss: 0.6400 - val_accuracy: 0.6923\n",
      "Epoch 121/200\n",
      "2/2 - 0s - loss: 0.6240 - accuracy: 0.8475 - val_loss: 0.6396 - val_accuracy: 0.6923\n",
      "Epoch 122/200\n",
      "2/2 - 0s - loss: 0.6370 - accuracy: 0.7627 - val_loss: 0.6391 - val_accuracy: 0.6923\n",
      "Epoch 123/200\n",
      "2/2 - 0s - loss: 0.6207 - accuracy: 0.8305 - val_loss: 0.6386 - val_accuracy: 0.6923\n",
      "Epoch 124/200\n",
      "2/2 - 0s - loss: 0.6244 - accuracy: 0.7966 - val_loss: 0.6382 - val_accuracy: 0.7308\n",
      "Epoch 125/200\n",
      "2/2 - 0s - loss: 0.6194 - accuracy: 0.8305 - val_loss: 0.6376 - val_accuracy: 0.7308\n",
      "Epoch 126/200\n",
      "2/2 - 0s - loss: 0.6184 - accuracy: 0.8305 - val_loss: 0.6371 - val_accuracy: 0.8077\n",
      "Epoch 127/200\n",
      "2/2 - 0s - loss: 0.6167 - accuracy: 0.8305 - val_loss: 0.6365 - val_accuracy: 0.8077\n",
      "Epoch 128/200\n",
      "2/2 - 0s - loss: 0.6170 - accuracy: 0.8644 - val_loss: 0.6358 - val_accuracy: 0.8077\n",
      "Epoch 129/200\n",
      "2/2 - 0s - loss: 0.6278 - accuracy: 0.7966 - val_loss: 0.6352 - val_accuracy: 0.8077\n",
      "Epoch 130/200\n",
      "2/2 - 0s - loss: 0.6153 - accuracy: 0.8475 - val_loss: 0.6346 - val_accuracy: 0.8077\n",
      "Epoch 131/200\n",
      "2/2 - 0s - loss: 0.6218 - accuracy: 0.8305 - val_loss: 0.6339 - val_accuracy: 0.8077\n",
      "Epoch 132/200\n",
      "2/2 - 0s - loss: 0.6099 - accuracy: 0.8475 - val_loss: 0.6332 - val_accuracy: 0.8077\n",
      "Epoch 133/200\n",
      "2/2 - 0s - loss: 0.6153 - accuracy: 0.8475 - val_loss: 0.6325 - val_accuracy: 0.8077\n",
      "Epoch 134/200\n",
      "2/2 - 0s - loss: 0.6029 - accuracy: 0.8644 - val_loss: 0.6317 - val_accuracy: 0.8077\n",
      "Epoch 135/200\n",
      "2/2 - 0s - loss: 0.6177 - accuracy: 0.7797 - val_loss: 0.6310 - val_accuracy: 0.8077\n",
      "Epoch 136/200\n",
      "2/2 - 0s - loss: 0.5919 - accuracy: 0.9153 - val_loss: 0.6304 - val_accuracy: 0.8077\n",
      "Epoch 137/200\n",
      "2/2 - 0s - loss: 0.6078 - accuracy: 0.8305 - val_loss: 0.6297 - val_accuracy: 0.8462\n",
      "Epoch 138/200\n",
      "2/2 - 0s - loss: 0.6056 - accuracy: 0.8814 - val_loss: 0.6291 - val_accuracy: 0.8462\n",
      "Epoch 139/200\n",
      "2/2 - 0s - loss: 0.6135 - accuracy: 0.8475 - val_loss: 0.6285 - val_accuracy: 0.8462\n",
      "Epoch 140/200\n",
      "2/2 - 0s - loss: 0.5936 - accuracy: 0.8814 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
      "Epoch 141/200\n",
      "2/2 - 0s - loss: 0.6103 - accuracy: 0.8305 - val_loss: 0.6272 - val_accuracy: 0.8462\n",
      "Epoch 142/200\n",
      "2/2 - 0s - loss: 0.6049 - accuracy: 0.8644 - val_loss: 0.6266 - val_accuracy: 0.8462\n",
      "Epoch 143/200\n",
      "2/2 - 0s - loss: 0.6024 - accuracy: 0.8475 - val_loss: 0.6260 - val_accuracy: 0.8462\n",
      "Epoch 144/200\n",
      "2/2 - 0s - loss: 0.5704 - accuracy: 0.9322 - val_loss: 0.6254 - val_accuracy: 0.8462\n",
      "Epoch 145/200\n",
      "2/2 - 0s - loss: 0.5953 - accuracy: 0.8475 - val_loss: 0.6248 - val_accuracy: 0.8077\n",
      "Epoch 146/200\n",
      "2/2 - 0s - loss: 0.5849 - accuracy: 0.8983 - val_loss: 0.6241 - val_accuracy: 0.8077\n",
      "Epoch 147/200\n",
      "2/2 - 0s - loss: 0.5896 - accuracy: 0.8305 - val_loss: 0.6234 - val_accuracy: 0.8077\n",
      "Epoch 148/200\n",
      "2/2 - 0s - loss: 0.6131 - accuracy: 0.8136 - val_loss: 0.6227 - val_accuracy: 0.8077\n",
      "Epoch 149/200\n",
      "2/2 - 0s - loss: 0.5814 - accuracy: 0.8983 - val_loss: 0.6220 - val_accuracy: 0.8077\n",
      "Epoch 150/200\n",
      "2/2 - 0s - loss: 0.5754 - accuracy: 0.8983 - val_loss: 0.6213 - val_accuracy: 0.8077\n",
      "Epoch 151/200\n",
      "2/2 - 0s - loss: 0.6127 - accuracy: 0.8305 - val_loss: 0.6205 - val_accuracy: 0.8077\n",
      "Epoch 152/200\n",
      "2/2 - 0s - loss: 0.5958 - accuracy: 0.8644 - val_loss: 0.6197 - val_accuracy: 0.8077\n",
      "Epoch 153/200\n",
      "2/2 - 0s - loss: 0.5710 - accuracy: 0.9153 - val_loss: 0.6189 - val_accuracy: 0.8077\n",
      "Epoch 154/200\n",
      "2/2 - 0s - loss: 0.5737 - accuracy: 0.8814 - val_loss: 0.6180 - val_accuracy: 0.8077\n",
      "Epoch 155/200\n",
      "2/2 - 0s - loss: 0.5659 - accuracy: 0.9153 - val_loss: 0.6172 - val_accuracy: 0.8077\n",
      "Epoch 156/200\n",
      "2/2 - 0s - loss: 0.5807 - accuracy: 0.8644 - val_loss: 0.6163 - val_accuracy: 0.8077\n",
      "Epoch 157/200\n",
      "2/2 - 0s - loss: 0.5841 - accuracy: 0.8983 - val_loss: 0.6155 - val_accuracy: 0.8077\n",
      "Epoch 158/200\n",
      "2/2 - 0s - loss: 0.5743 - accuracy: 0.8814 - val_loss: 0.6146 - val_accuracy: 0.8077\n",
      "Epoch 159/200\n",
      "2/2 - 0s - loss: 0.5618 - accuracy: 0.8814 - val_loss: 0.6137 - val_accuracy: 0.8077\n",
      "Epoch 160/200\n",
      "2/2 - 0s - loss: 0.5679 - accuracy: 0.8814 - val_loss: 0.6127 - val_accuracy: 0.8077\n",
      "Epoch 161/200\n",
      "2/2 - 0s - loss: 0.5866 - accuracy: 0.8475 - val_loss: 0.6118 - val_accuracy: 0.8077\n",
      "Epoch 162/200\n",
      "2/2 - 0s - loss: 0.5905 - accuracy: 0.8644 - val_loss: 0.6111 - val_accuracy: 0.8077\n",
      "Epoch 163/200\n",
      "2/2 - 0s - loss: 0.5702 - accuracy: 0.8644 - val_loss: 0.6104 - val_accuracy: 0.8077\n",
      "Epoch 164/200\n",
      "2/2 - 0s - loss: 0.5716 - accuracy: 0.8983 - val_loss: 0.6097 - val_accuracy: 0.8077\n",
      "Epoch 165/200\n",
      "2/2 - 0s - loss: 0.5608 - accuracy: 0.8814 - val_loss: 0.6091 - val_accuracy: 0.8077\n",
      "Epoch 166/200\n",
      "2/2 - 0s - loss: 0.5641 - accuracy: 0.8814 - val_loss: 0.6085 - val_accuracy: 0.8077\n",
      "Epoch 167/200\n",
      "2/2 - 0s - loss: 0.5274 - accuracy: 0.9492 - val_loss: 0.6079 - val_accuracy: 0.8077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200\n",
      "2/2 - 0s - loss: 0.5424 - accuracy: 0.8983 - val_loss: 0.6074 - val_accuracy: 0.8077\n",
      "Epoch 169/200\n",
      "2/2 - 0s - loss: 0.5527 - accuracy: 0.9153 - val_loss: 0.6068 - val_accuracy: 0.8077\n",
      "Epoch 170/200\n",
      "2/2 - 0s - loss: 0.5485 - accuracy: 0.9153 - val_loss: 0.6062 - val_accuracy: 0.8077\n",
      "Epoch 171/200\n",
      "2/2 - 0s - loss: 0.5711 - accuracy: 0.8475 - val_loss: 0.6056 - val_accuracy: 0.8077\n",
      "Epoch 172/200\n",
      "2/2 - 0s - loss: 0.5392 - accuracy: 0.9322 - val_loss: 0.6052 - val_accuracy: 0.8077\n",
      "Epoch 173/200\n",
      "2/2 - 0s - loss: 0.5194 - accuracy: 0.9322 - val_loss: 0.6047 - val_accuracy: 0.8077\n",
      "Epoch 174/200\n",
      "2/2 - 0s - loss: 0.5265 - accuracy: 0.9322 - val_loss: 0.6042 - val_accuracy: 0.8077\n",
      "Epoch 175/200\n",
      "2/2 - 0s - loss: 0.5300 - accuracy: 0.9153 - val_loss: 0.6039 - val_accuracy: 0.8077\n",
      "Epoch 176/200\n",
      "2/2 - 0s - loss: 0.5589 - accuracy: 0.8983 - val_loss: 0.6036 - val_accuracy: 0.8077\n",
      "Epoch 177/200\n",
      "2/2 - 0s - loss: 0.5188 - accuracy: 0.9322 - val_loss: 0.6034 - val_accuracy: 0.8077\n",
      "Epoch 178/200\n",
      "2/2 - 0s - loss: 0.5262 - accuracy: 0.9153 - val_loss: 0.6032 - val_accuracy: 0.8077\n",
      "Epoch 179/200\n",
      "2/2 - 0s - loss: 0.5260 - accuracy: 0.9153 - val_loss: 0.6033 - val_accuracy: 0.8077\n",
      "Epoch 180/200\n",
      "2/2 - 0s - loss: 0.5193 - accuracy: 0.9153 - val_loss: 0.6034 - val_accuracy: 0.8077\n",
      "Epoch 181/200\n",
      "2/2 - 0s - loss: 0.5286 - accuracy: 0.9153 - val_loss: 0.6033 - val_accuracy: 0.8077\n",
      "Epoch 182/200\n",
      "2/2 - 0s - loss: 0.5351 - accuracy: 0.8983 - val_loss: 0.6031 - val_accuracy: 0.8077\n",
      "Epoch 183/200\n",
      "2/2 - 0s - loss: 0.5338 - accuracy: 0.9153 - val_loss: 0.6029 - val_accuracy: 0.8077\n",
      "Epoch 184/200\n",
      "2/2 - 0s - loss: 0.5489 - accuracy: 0.8983 - val_loss: 0.6027 - val_accuracy: 0.8077\n",
      "Epoch 185/200\n",
      "2/2 - 0s - loss: 0.5519 - accuracy: 0.8814 - val_loss: 0.6027 - val_accuracy: 0.8077\n",
      "Epoch 186/200\n",
      "2/2 - 0s - loss: 0.5353 - accuracy: 0.8814 - val_loss: 0.6029 - val_accuracy: 0.8077\n",
      "Epoch 187/200\n",
      "2/2 - 0s - loss: 0.5107 - accuracy: 0.9322 - val_loss: 0.6032 - val_accuracy: 0.8077\n",
      "Epoch 188/200\n",
      "2/2 - 0s - loss: 0.5224 - accuracy: 0.8814 - val_loss: 0.6037 - val_accuracy: 0.8077\n",
      "Epoch 189/200\n",
      "2/2 - 0s - loss: 0.5232 - accuracy: 0.8983 - val_loss: 0.6043 - val_accuracy: 0.8077\n",
      "Epoch 190/200\n",
      "2/2 - 0s - loss: 0.4915 - accuracy: 0.9492 - val_loss: 0.6050 - val_accuracy: 0.8077\n",
      "Epoch 191/200\n",
      "2/2 - 0s - loss: 0.5390 - accuracy: 0.8814 - val_loss: 0.6054 - val_accuracy: 0.8077\n",
      "Epoch 192/200\n",
      "2/2 - 0s - loss: 0.5294 - accuracy: 0.8644 - val_loss: 0.6056 - val_accuracy: 0.8077\n",
      "Epoch 193/200\n",
      "2/2 - 0s - loss: 0.5373 - accuracy: 0.8814 - val_loss: 0.6058 - val_accuracy: 0.8077\n",
      "Epoch 194/200\n",
      "2/2 - 0s - loss: 0.5246 - accuracy: 0.8644 - val_loss: 0.6059 - val_accuracy: 0.8077\n",
      "Epoch 195/200\n",
      "2/2 - 0s - loss: 0.5193 - accuracy: 0.9153 - val_loss: 0.6063 - val_accuracy: 0.8077\n",
      "Epoch 196/200\n",
      "2/2 - 0s - loss: 0.4799 - accuracy: 0.9322 - val_loss: 0.6069 - val_accuracy: 0.8077\n",
      "Epoch 197/200\n",
      "2/2 - 0s - loss: 0.4963 - accuracy: 0.9492 - val_loss: 0.6077 - val_accuracy: 0.8077\n",
      "Epoch 198/200\n",
      "2/2 - 0s - loss: 0.4866 - accuracy: 0.9322 - val_loss: 0.6085 - val_accuracy: 0.8077\n",
      "Epoch 199/200\n",
      "2/2 - 0s - loss: 0.4979 - accuracy: 0.9322 - val_loss: 0.6092 - val_accuracy: 0.8077\n",
      "Epoch 200/200\n",
      "2/2 - 0s - loss: 0.5184 - accuracy: 0.8983 - val_loss: 0.6098 - val_accuracy: 0.8077\n"
     ]
    }
   ],
   "source": [
    "mlp_greeting = mlp_greeting(shape)\n",
    "history = mlp_greeting.fit(X_train, np.asarray(y_train[\"Greeting\"]).reshape(-1,1),\n",
    "                  validation_data=(X_validation, np.asarray(y_validation[\"Greeting\"]).reshape(-1,1)),\n",
    "    epochs=200,\n",
    "    workers = 2, use_multiprocessing= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_search(shape):\n",
    "# define our MLP network\n",
    "    initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=42)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=shape, kernel_initializer = initializer, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2, activation=\"relu\"))\n",
    "# check to see if the regression node should be added\n",
    "    #if regress:\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    #Compile model\n",
    "    opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss='binary_crossentropy', metrics = [\"accuracy\"], optimizer=opt)\n",
    "# return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_9/dense_45/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_9/dense_45/embedding_lookup_sparse/Reshape:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_9/dense_45/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 1s - loss: 0.6960 - accuracy: 0.5085 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
      "Epoch 2/250\n",
      "2/2 - 0s - loss: 0.6986 - accuracy: 0.6102 - val_loss: 0.6947 - val_accuracy: 0.5385\n",
      "Epoch 3/250\n",
      "2/2 - 0s - loss: 0.6949 - accuracy: 0.6271 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 4/250\n",
      "2/2 - 0s - loss: 0.6918 - accuracy: 0.7288 - val_loss: 0.6928 - val_accuracy: 0.6154\n",
      "Epoch 5/250\n",
      "2/2 - 0s - loss: 0.6904 - accuracy: 0.7627 - val_loss: 0.6919 - val_accuracy: 0.6538\n",
      "Epoch 6/250\n",
      "2/2 - 0s - loss: 0.6939 - accuracy: 0.6780 - val_loss: 0.6910 - val_accuracy: 0.6538\n",
      "Epoch 7/250\n",
      "2/2 - 0s - loss: 0.6914 - accuracy: 0.6780 - val_loss: 0.6900 - val_accuracy: 0.6923\n",
      "Epoch 8/250\n",
      "2/2 - 0s - loss: 0.6887 - accuracy: 0.7458 - val_loss: 0.6892 - val_accuracy: 0.7308\n",
      "Epoch 9/250\n",
      "2/2 - 0s - loss: 0.6877 - accuracy: 0.7458 - val_loss: 0.6884 - val_accuracy: 0.7308\n",
      "Epoch 10/250\n",
      "2/2 - 0s - loss: 0.6892 - accuracy: 0.7119 - val_loss: 0.6876 - val_accuracy: 0.7308\n",
      "Epoch 11/250\n",
      "2/2 - 0s - loss: 0.6864 - accuracy: 0.7288 - val_loss: 0.6868 - val_accuracy: 0.7692\n",
      "Epoch 12/250\n",
      "2/2 - 0s - loss: 0.6862 - accuracy: 0.7288 - val_loss: 0.6860 - val_accuracy: 0.7692\n",
      "Epoch 13/250\n",
      "2/2 - 0s - loss: 0.6866 - accuracy: 0.7288 - val_loss: 0.6853 - val_accuracy: 0.7692\n",
      "Epoch 14/250\n",
      "2/2 - 0s - loss: 0.6867 - accuracy: 0.7119 - val_loss: 0.6846 - val_accuracy: 0.7692\n",
      "Epoch 15/250\n",
      "2/2 - 0s - loss: 0.6838 - accuracy: 0.7627 - val_loss: 0.6838 - val_accuracy: 0.7692\n",
      "Epoch 16/250\n",
      "2/2 - 0s - loss: 0.6826 - accuracy: 0.7797 - val_loss: 0.6830 - val_accuracy: 0.7692\n",
      "Epoch 17/250\n",
      "2/2 - 0s - loss: 0.6812 - accuracy: 0.7627 - val_loss: 0.6822 - val_accuracy: 0.7692\n",
      "Epoch 18/250\n",
      "2/2 - 0s - loss: 0.6821 - accuracy: 0.7458 - val_loss: 0.6813 - val_accuracy: 0.7692\n",
      "Epoch 19/250\n",
      "2/2 - 0s - loss: 0.6810 - accuracy: 0.7627 - val_loss: 0.6805 - val_accuracy: 0.7692\n",
      "Epoch 20/250\n",
      "2/2 - 0s - loss: 0.6808 - accuracy: 0.7458 - val_loss: 0.6797 - val_accuracy: 0.7692\n",
      "Epoch 21/250\n",
      "2/2 - 0s - loss: 0.6803 - accuracy: 0.7797 - val_loss: 0.6790 - val_accuracy: 0.7692\n",
      "Epoch 22/250\n",
      "2/2 - 0s - loss: 0.6770 - accuracy: 0.7627 - val_loss: 0.6781 - val_accuracy: 0.7692\n",
      "Epoch 23/250\n",
      "2/2 - 0s - loss: 0.6789 - accuracy: 0.7627 - val_loss: 0.6774 - val_accuracy: 0.7692\n",
      "Epoch 24/250\n",
      "2/2 - 0s - loss: 0.6765 - accuracy: 0.7627 - val_loss: 0.6766 - val_accuracy: 0.7692\n",
      "Epoch 25/250\n",
      "2/2 - 0s - loss: 0.6763 - accuracy: 0.7627 - val_loss: 0.6758 - val_accuracy: 0.7692\n",
      "Epoch 26/250\n",
      "2/2 - 0s - loss: 0.6751 - accuracy: 0.7627 - val_loss: 0.6750 - val_accuracy: 0.7692\n",
      "Epoch 27/250\n",
      "2/2 - 0s - loss: 0.6733 - accuracy: 0.7627 - val_loss: 0.6741 - val_accuracy: 0.7692\n",
      "Epoch 28/250\n",
      "2/2 - 0s - loss: 0.6739 - accuracy: 0.7627 - val_loss: 0.6733 - val_accuracy: 0.7692\n",
      "Epoch 29/250\n",
      "2/2 - 0s - loss: 0.6722 - accuracy: 0.7627 - val_loss: 0.6724 - val_accuracy: 0.7692\n",
      "Epoch 30/250\n",
      "2/2 - 0s - loss: 0.6716 - accuracy: 0.7627 - val_loss: 0.6715 - val_accuracy: 0.7692\n",
      "Epoch 31/250\n",
      "2/2 - 0s - loss: 0.6707 - accuracy: 0.7627 - val_loss: 0.6706 - val_accuracy: 0.7692\n",
      "Epoch 32/250\n",
      "2/2 - 0s - loss: 0.6702 - accuracy: 0.7627 - val_loss: 0.6696 - val_accuracy: 0.7692\n",
      "Epoch 33/250\n",
      "2/2 - 0s - loss: 0.6685 - accuracy: 0.7627 - val_loss: 0.6686 - val_accuracy: 0.7692\n",
      "Epoch 34/250\n",
      "2/2 - 0s - loss: 0.6675 - accuracy: 0.7627 - val_loss: 0.6675 - val_accuracy: 0.7692\n",
      "Epoch 35/250\n",
      "2/2 - 0s - loss: 0.6650 - accuracy: 0.7627 - val_loss: 0.6664 - val_accuracy: 0.7692\n",
      "Epoch 36/250\n",
      "2/2 - 0s - loss: 0.6592 - accuracy: 0.7627 - val_loss: 0.6652 - val_accuracy: 0.7692\n",
      "Epoch 37/250\n",
      "2/2 - 0s - loss: 0.6646 - accuracy: 0.7627 - val_loss: 0.6639 - val_accuracy: 0.7692\n",
      "Epoch 38/250\n",
      "2/2 - 0s - loss: 0.6641 - accuracy: 0.7627 - val_loss: 0.6627 - val_accuracy: 0.7692\n",
      "Epoch 39/250\n",
      "2/2 - 0s - loss: 0.6586 - accuracy: 0.7627 - val_loss: 0.6613 - val_accuracy: 0.7692\n",
      "Epoch 40/250\n",
      "2/2 - 0s - loss: 0.6587 - accuracy: 0.7627 - val_loss: 0.6600 - val_accuracy: 0.7692\n",
      "Epoch 41/250\n",
      "2/2 - 0s - loss: 0.6617 - accuracy: 0.7627 - val_loss: 0.6586 - val_accuracy: 0.7692\n",
      "Epoch 42/250\n",
      "2/2 - 0s - loss: 0.6555 - accuracy: 0.7627 - val_loss: 0.6571 - val_accuracy: 0.7692\n",
      "Epoch 43/250\n",
      "2/2 - 0s - loss: 0.6551 - accuracy: 0.7627 - val_loss: 0.6557 - val_accuracy: 0.7692\n",
      "Epoch 44/250\n",
      "2/2 - 0s - loss: 0.6490 - accuracy: 0.7627 - val_loss: 0.6541 - val_accuracy: 0.7692\n",
      "Epoch 45/250\n",
      "2/2 - 0s - loss: 0.6518 - accuracy: 0.7627 - val_loss: 0.6524 - val_accuracy: 0.7692\n",
      "Epoch 46/250\n",
      "2/2 - 0s - loss: 0.6457 - accuracy: 0.7627 - val_loss: 0.6507 - val_accuracy: 0.7692\n",
      "Epoch 47/250\n",
      "2/2 - 0s - loss: 0.6448 - accuracy: 0.7627 - val_loss: 0.6489 - val_accuracy: 0.7692\n",
      "Epoch 48/250\n",
      "2/2 - 0s - loss: 0.6481 - accuracy: 0.7627 - val_loss: 0.6470 - val_accuracy: 0.7692\n",
      "Epoch 49/250\n",
      "2/2 - 0s - loss: 0.6419 - accuracy: 0.7627 - val_loss: 0.6450 - val_accuracy: 0.7692\n",
      "Epoch 50/250\n",
      "2/2 - 0s - loss: 0.6475 - accuracy: 0.7627 - val_loss: 0.6431 - val_accuracy: 0.7692\n",
      "Epoch 51/250\n",
      "2/2 - 0s - loss: 0.6382 - accuracy: 0.7627 - val_loss: 0.6411 - val_accuracy: 0.7692\n",
      "Epoch 52/250\n",
      "2/2 - 0s - loss: 0.6438 - accuracy: 0.7627 - val_loss: 0.6391 - val_accuracy: 0.7692\n",
      "Epoch 53/250\n",
      "2/2 - 0s - loss: 0.6310 - accuracy: 0.7627 - val_loss: 0.6370 - val_accuracy: 0.7692\n",
      "Epoch 54/250\n",
      "2/2 - 0s - loss: 0.6357 - accuracy: 0.7627 - val_loss: 0.6348 - val_accuracy: 0.7692\n",
      "Epoch 55/250\n",
      "2/2 - 0s - loss: 0.6269 - accuracy: 0.7627 - val_loss: 0.6325 - val_accuracy: 0.7692\n",
      "Epoch 56/250\n",
      "2/2 - 0s - loss: 0.6268 - accuracy: 0.7627 - val_loss: 0.6301 - val_accuracy: 0.7692\n",
      "Epoch 57/250\n",
      "2/2 - 0s - loss: 0.6251 - accuracy: 0.7627 - val_loss: 0.6277 - val_accuracy: 0.7692\n",
      "Epoch 58/250\n",
      "2/2 - 0s - loss: 0.6325 - accuracy: 0.7627 - val_loss: 0.6253 - val_accuracy: 0.7692\n",
      "Epoch 59/250\n",
      "2/2 - 0s - loss: 0.6215 - accuracy: 0.7627 - val_loss: 0.6227 - val_accuracy: 0.7692\n",
      "Epoch 60/250\n",
      "2/2 - 0s - loss: 0.6222 - accuracy: 0.7627 - val_loss: 0.6201 - val_accuracy: 0.7692\n",
      "Epoch 61/250\n",
      "2/2 - 0s - loss: 0.5963 - accuracy: 0.7627 - val_loss: 0.6172 - val_accuracy: 0.7692\n",
      "Epoch 62/250\n",
      "2/2 - 0s - loss: 0.6069 - accuracy: 0.7627 - val_loss: 0.6141 - val_accuracy: 0.7692\n",
      "Epoch 63/250\n",
      "2/2 - 0s - loss: 0.5978 - accuracy: 0.7627 - val_loss: 0.6110 - val_accuracy: 0.7692\n",
      "Epoch 64/250\n",
      "2/2 - 0s - loss: 0.6046 - accuracy: 0.7627 - val_loss: 0.6077 - val_accuracy: 0.7692\n",
      "Epoch 65/250\n",
      "2/2 - 0s - loss: 0.5973 - accuracy: 0.7627 - val_loss: 0.6044 - val_accuracy: 0.7692\n",
      "Epoch 66/250\n",
      "2/2 - 0s - loss: 0.5883 - accuracy: 0.7627 - val_loss: 0.6009 - val_accuracy: 0.7692\n",
      "Epoch 67/250\n",
      "2/2 - 0s - loss: 0.5802 - accuracy: 0.7627 - val_loss: 0.5972 - val_accuracy: 0.7692\n",
      "Epoch 68/250\n",
      "2/2 - 0s - loss: 0.5894 - accuracy: 0.7627 - val_loss: 0.5935 - val_accuracy: 0.7692\n",
      "Epoch 69/250\n",
      "2/2 - 0s - loss: 0.5874 - accuracy: 0.7627 - val_loss: 0.5897 - val_accuracy: 0.7692\n",
      "Epoch 70/250\n",
      "2/2 - 0s - loss: 0.5879 - accuracy: 0.7627 - val_loss: 0.5859 - val_accuracy: 0.7692\n",
      "Epoch 71/250\n",
      "2/2 - 0s - loss: 0.5685 - accuracy: 0.7627 - val_loss: 0.5819 - val_accuracy: 0.7692\n",
      "Epoch 72/250\n",
      "2/2 - 0s - loss: 0.5505 - accuracy: 0.7627 - val_loss: 0.5778 - val_accuracy: 0.7692\n",
      "Epoch 73/250\n",
      "2/2 - 0s - loss: 0.5550 - accuracy: 0.7627 - val_loss: 0.5735 - val_accuracy: 0.7692\n",
      "Epoch 74/250\n",
      "2/2 - 0s - loss: 0.5863 - accuracy: 0.7627 - val_loss: 0.5694 - val_accuracy: 0.7692\n",
      "Epoch 75/250\n",
      "2/2 - 0s - loss: 0.5870 - accuracy: 0.7627 - val_loss: 0.5654 - val_accuracy: 0.7692\n",
      "Epoch 76/250\n",
      "2/2 - 0s - loss: 0.5733 - accuracy: 0.7627 - val_loss: 0.5616 - val_accuracy: 0.7692\n",
      "Epoch 77/250\n",
      "2/2 - 0s - loss: 0.5577 - accuracy: 0.7627 - val_loss: 0.5576 - val_accuracy: 0.7692\n",
      "Epoch 78/250\n",
      "2/2 - 0s - loss: 0.5630 - accuracy: 0.7627 - val_loss: 0.5536 - val_accuracy: 0.7692\n",
      "Epoch 79/250\n",
      "2/2 - 0s - loss: 0.5240 - accuracy: 0.7627 - val_loss: 0.5494 - val_accuracy: 0.7692\n",
      "Epoch 80/250\n",
      "2/2 - 0s - loss: 0.5293 - accuracy: 0.7627 - val_loss: 0.5447 - val_accuracy: 0.7692\n",
      "Epoch 81/250\n",
      "2/2 - 0s - loss: 0.5587 - accuracy: 0.7627 - val_loss: 0.5403 - val_accuracy: 0.7692\n",
      "Epoch 82/250\n",
      "2/2 - 0s - loss: 0.5177 - accuracy: 0.7627 - val_loss: 0.5357 - val_accuracy: 0.7692\n",
      "Epoch 83/250\n",
      "2/2 - 0s - loss: 0.5018 - accuracy: 0.7627 - val_loss: 0.5310 - val_accuracy: 0.7692\n",
      "Epoch 84/250\n",
      "2/2 - 0s - loss: 0.5527 - accuracy: 0.7627 - val_loss: 0.5266 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/250\n",
      "2/2 - 0s - loss: 0.5123 - accuracy: 0.7627 - val_loss: 0.5222 - val_accuracy: 0.7692\n",
      "Epoch 86/250\n",
      "2/2 - 0s - loss: 0.4914 - accuracy: 0.7627 - val_loss: 0.5179 - val_accuracy: 0.7692\n",
      "Epoch 87/250\n",
      "2/2 - 0s - loss: 0.4705 - accuracy: 0.7627 - val_loss: 0.5137 - val_accuracy: 0.7692\n",
      "Epoch 88/250\n",
      "2/2 - 0s - loss: 0.4765 - accuracy: 0.7627 - val_loss: 0.5095 - val_accuracy: 0.7692\n",
      "Epoch 89/250\n",
      "2/2 - 0s - loss: 0.4609 - accuracy: 0.7627 - val_loss: 0.5056 - val_accuracy: 0.7692\n",
      "Epoch 90/250\n",
      "2/2 - 0s - loss: 0.5041 - accuracy: 0.7627 - val_loss: 0.5018 - val_accuracy: 0.7692\n",
      "Epoch 91/250\n",
      "2/2 - 0s - loss: 0.4864 - accuracy: 0.7627 - val_loss: 0.4982 - val_accuracy: 0.7692\n",
      "Epoch 92/250\n",
      "2/2 - 0s - loss: 0.4335 - accuracy: 0.7627 - val_loss: 0.4948 - val_accuracy: 0.7692\n",
      "Epoch 93/250\n",
      "2/2 - 0s - loss: 0.4165 - accuracy: 0.7627 - val_loss: 0.4915 - val_accuracy: 0.7692\n",
      "Epoch 94/250\n",
      "2/2 - 0s - loss: 0.4564 - accuracy: 0.7627 - val_loss: 0.4883 - val_accuracy: 0.7692\n",
      "Epoch 95/250\n",
      "2/2 - 0s - loss: 0.4709 - accuracy: 0.7627 - val_loss: 0.4854 - val_accuracy: 0.7692\n",
      "Epoch 96/250\n",
      "2/2 - 0s - loss: 0.4748 - accuracy: 0.7627 - val_loss: 0.4828 - val_accuracy: 0.7692\n",
      "Epoch 97/250\n",
      "2/2 - 0s - loss: 0.4500 - accuracy: 0.7627 - val_loss: 0.4803 - val_accuracy: 0.7692\n",
      "Epoch 98/250\n",
      "2/2 - 0s - loss: 0.4287 - accuracy: 0.7627 - val_loss: 0.4779 - val_accuracy: 0.7692\n",
      "Epoch 99/250\n",
      "2/2 - 0s - loss: 0.4310 - accuracy: 0.7627 - val_loss: 0.4757 - val_accuracy: 0.7692\n",
      "Epoch 100/250\n",
      "2/2 - 0s - loss: 0.4269 - accuracy: 0.7627 - val_loss: 0.4736 - val_accuracy: 0.7692\n",
      "Epoch 101/250\n",
      "2/2 - 0s - loss: 0.4229 - accuracy: 0.7627 - val_loss: 0.4718 - val_accuracy: 0.7692\n",
      "Epoch 102/250\n",
      "2/2 - 0s - loss: 0.4185 - accuracy: 0.7627 - val_loss: 0.4700 - val_accuracy: 0.7692\n",
      "Epoch 103/250\n",
      "2/2 - 0s - loss: 0.4344 - accuracy: 0.7627 - val_loss: 0.4683 - val_accuracy: 0.7692\n",
      "Epoch 104/250\n",
      "2/2 - 0s - loss: 0.4252 - accuracy: 0.7627 - val_loss: 0.4665 - val_accuracy: 0.7692\n",
      "Epoch 105/250\n",
      "2/2 - 0s - loss: 0.4204 - accuracy: 0.7627 - val_loss: 0.4649 - val_accuracy: 0.7692\n",
      "Epoch 106/250\n",
      "2/2 - 0s - loss: 0.3948 - accuracy: 0.7627 - val_loss: 0.4634 - val_accuracy: 0.7692\n",
      "Epoch 107/250\n",
      "2/2 - 0s - loss: 0.4122 - accuracy: 0.7627 - val_loss: 0.4620 - val_accuracy: 0.7692\n",
      "Epoch 108/250\n",
      "2/2 - 0s - loss: 0.3919 - accuracy: 0.7627 - val_loss: 0.4606 - val_accuracy: 0.7692\n",
      "Epoch 109/250\n",
      "2/2 - 0s - loss: 0.3693 - accuracy: 0.7627 - val_loss: 0.4595 - val_accuracy: 0.7692\n",
      "Epoch 110/250\n",
      "2/2 - 0s - loss: 0.3789 - accuracy: 0.7627 - val_loss: 0.4584 - val_accuracy: 0.7692\n",
      "Epoch 111/250\n",
      "2/2 - 0s - loss: 0.3705 - accuracy: 0.7627 - val_loss: 0.4575 - val_accuracy: 0.7692\n",
      "Epoch 112/250\n",
      "2/2 - 0s - loss: 0.3852 - accuracy: 0.7627 - val_loss: 0.4568 - val_accuracy: 0.7692\n",
      "Epoch 113/250\n",
      "2/2 - 0s - loss: 0.3678 - accuracy: 0.7627 - val_loss: 0.4562 - val_accuracy: 0.7692\n",
      "Epoch 114/250\n",
      "2/2 - 0s - loss: 0.3833 - accuracy: 0.7627 - val_loss: 0.4557 - val_accuracy: 0.7692\n",
      "Epoch 115/250\n",
      "2/2 - 0s - loss: 0.3728 - accuracy: 0.7627 - val_loss: 0.4553 - val_accuracy: 0.7692\n",
      "Epoch 116/250\n",
      "2/2 - 0s - loss: 0.3372 - accuracy: 0.7627 - val_loss: 0.4552 - val_accuracy: 0.7692\n",
      "Epoch 117/250\n",
      "2/2 - 0s - loss: 0.3800 - accuracy: 0.7627 - val_loss: 0.4554 - val_accuracy: 0.7692\n",
      "Epoch 118/250\n",
      "2/2 - 0s - loss: 0.3680 - accuracy: 0.7627 - val_loss: 0.4554 - val_accuracy: 0.7692\n",
      "Epoch 119/250\n",
      "2/2 - 0s - loss: 0.3685 - accuracy: 0.7627 - val_loss: 0.4554 - val_accuracy: 0.7692\n",
      "Epoch 120/250\n",
      "2/2 - 0s - loss: 0.3626 - accuracy: 0.7627 - val_loss: 0.4555 - val_accuracy: 0.7692\n",
      "Epoch 121/250\n",
      "2/2 - 0s - loss: 0.3540 - accuracy: 0.7627 - val_loss: 0.4559 - val_accuracy: 0.7692\n",
      "Epoch 122/250\n",
      "2/2 - 0s - loss: 0.3360 - accuracy: 0.7627 - val_loss: 0.4564 - val_accuracy: 0.7692\n",
      "Epoch 123/250\n",
      "2/2 - 0s - loss: 0.3882 - accuracy: 0.7627 - val_loss: 0.4569 - val_accuracy: 0.7692\n",
      "Epoch 124/250\n",
      "2/2 - 0s - loss: 0.3411 - accuracy: 0.7627 - val_loss: 0.4572 - val_accuracy: 0.7692\n",
      "Epoch 125/250\n",
      "2/2 - 0s - loss: 0.3792 - accuracy: 0.7627 - val_loss: 0.4575 - val_accuracy: 0.7692\n",
      "Epoch 126/250\n",
      "2/2 - 0s - loss: 0.3144 - accuracy: 0.7627 - val_loss: 0.4578 - val_accuracy: 0.7692\n",
      "Epoch 127/250\n",
      "2/2 - 0s - loss: 0.3393 - accuracy: 0.7627 - val_loss: 0.4580 - val_accuracy: 0.7692\n",
      "Epoch 128/250\n",
      "2/2 - 0s - loss: 0.3357 - accuracy: 0.7627 - val_loss: 0.4581 - val_accuracy: 0.7692\n",
      "Epoch 129/250\n",
      "2/2 - 0s - loss: 0.3313 - accuracy: 0.7627 - val_loss: 0.4583 - val_accuracy: 0.7692\n",
      "Epoch 130/250\n",
      "2/2 - 0s - loss: 0.3552 - accuracy: 0.7627 - val_loss: 0.4584 - val_accuracy: 0.7692\n",
      "Epoch 131/250\n",
      "2/2 - 0s - loss: 0.3201 - accuracy: 0.7627 - val_loss: 0.4587 - val_accuracy: 0.7692\n",
      "Epoch 132/250\n",
      "2/2 - 0s - loss: 0.3189 - accuracy: 0.7627 - val_loss: 0.4596 - val_accuracy: 0.7692\n",
      "Epoch 133/250\n",
      "2/2 - 0s - loss: 0.2949 - accuracy: 0.7627 - val_loss: 0.4602 - val_accuracy: 0.7692\n",
      "Epoch 134/250\n",
      "2/2 - 0s - loss: 0.3536 - accuracy: 0.7627 - val_loss: 0.4611 - val_accuracy: 0.7692\n",
      "Epoch 135/250\n",
      "2/2 - 0s - loss: 0.2992 - accuracy: 0.7627 - val_loss: 0.4621 - val_accuracy: 0.7692\n",
      "Epoch 136/250\n",
      "2/2 - 0s - loss: 0.3063 - accuracy: 0.7627 - val_loss: 0.4627 - val_accuracy: 0.7692\n",
      "Epoch 137/250\n",
      "2/2 - 0s - loss: 0.2968 - accuracy: 0.7627 - val_loss: 0.4636 - val_accuracy: 0.7692\n",
      "Epoch 138/250\n",
      "2/2 - 0s - loss: 0.2958 - accuracy: 0.7627 - val_loss: 0.4647 - val_accuracy: 0.7692\n",
      "Epoch 139/250\n",
      "2/2 - 0s - loss: 0.3163 - accuracy: 0.7627 - val_loss: 0.4652 - val_accuracy: 0.7692\n",
      "Epoch 140/250\n",
      "2/2 - 0s - loss: 0.3003 - accuracy: 0.7627 - val_loss: 0.4657 - val_accuracy: 0.7692\n",
      "Epoch 141/250\n",
      "2/2 - 0s - loss: 0.2775 - accuracy: 0.7627 - val_loss: 0.4662 - val_accuracy: 0.7692\n",
      "Epoch 142/250\n",
      "2/2 - 0s - loss: 0.2820 - accuracy: 0.7627 - val_loss: 0.4669 - val_accuracy: 0.7692\n",
      "Epoch 143/250\n",
      "2/2 - 0s - loss: 0.2860 - accuracy: 0.7627 - val_loss: 0.4678 - val_accuracy: 0.7692\n",
      "Epoch 144/250\n",
      "2/2 - 0s - loss: 0.2978 - accuracy: 0.7627 - val_loss: 0.4689 - val_accuracy: 0.7692\n",
      "Epoch 145/250\n",
      "2/2 - 0s - loss: 0.2542 - accuracy: 0.7627 - val_loss: 0.4703 - val_accuracy: 0.7692\n",
      "Epoch 146/250\n",
      "2/2 - 0s - loss: 0.2725 - accuracy: 0.7627 - val_loss: 0.4720 - val_accuracy: 0.7692\n",
      "Epoch 147/250\n",
      "2/2 - 0s - loss: 0.2746 - accuracy: 0.7627 - val_loss: 0.4737 - val_accuracy: 0.7692\n",
      "Epoch 148/250\n",
      "2/2 - 0s - loss: 0.2888 - accuracy: 0.7627 - val_loss: 0.4753 - val_accuracy: 0.7692\n",
      "Epoch 149/250\n",
      "2/2 - 0s - loss: 0.2897 - accuracy: 0.7627 - val_loss: 0.4773 - val_accuracy: 0.7692\n",
      "Epoch 150/250\n",
      "2/2 - 0s - loss: 0.2712 - accuracy: 0.7627 - val_loss: 0.4792 - val_accuracy: 0.7692\n",
      "Epoch 151/250\n",
      "2/2 - 0s - loss: 0.3109 - accuracy: 0.7627 - val_loss: 0.4811 - val_accuracy: 0.7692\n",
      "Epoch 152/250\n",
      "2/2 - 0s - loss: 0.2612 - accuracy: 0.7627 - val_loss: 0.4830 - val_accuracy: 0.7692\n",
      "Epoch 153/250\n",
      "2/2 - 0s - loss: 0.2573 - accuracy: 0.7627 - val_loss: 0.4849 - val_accuracy: 0.7692\n",
      "Epoch 154/250\n",
      "2/2 - 0s - loss: 0.2671 - accuracy: 0.7627 - val_loss: 0.4866 - val_accuracy: 0.7692\n",
      "Epoch 155/250\n",
      "2/2 - 0s - loss: 0.2550 - accuracy: 0.7627 - val_loss: 0.4882 - val_accuracy: 0.7692\n",
      "Epoch 156/250\n",
      "2/2 - 0s - loss: 0.2794 - accuracy: 0.7627 - val_loss: 0.4903 - val_accuracy: 0.7692\n",
      "Epoch 157/250\n",
      "2/2 - 0s - loss: 0.3079 - accuracy: 0.7627 - val_loss: 0.4926 - val_accuracy: 0.7692\n",
      "Epoch 158/250\n",
      "2/2 - 0s - loss: 0.2734 - accuracy: 0.7627 - val_loss: 0.4949 - val_accuracy: 0.7692\n",
      "Epoch 159/250\n",
      "2/2 - 0s - loss: 0.2492 - accuracy: 0.7627 - val_loss: 0.4974 - val_accuracy: 0.7692\n",
      "Epoch 160/250\n",
      "2/2 - 0s - loss: 0.2920 - accuracy: 0.7627 - val_loss: 0.5001 - val_accuracy: 0.7692\n",
      "Epoch 161/250\n",
      "2/2 - 0s - loss: 0.2510 - accuracy: 0.7627 - val_loss: 0.5032 - val_accuracy: 0.7692\n",
      "Epoch 162/250\n",
      "2/2 - 0s - loss: 0.2539 - accuracy: 0.7627 - val_loss: 0.5055 - val_accuracy: 0.7692\n",
      "Epoch 163/250\n",
      "2/2 - 0s - loss: 0.2644 - accuracy: 0.7627 - val_loss: 0.5071 - val_accuracy: 0.7692\n",
      "Epoch 164/250\n",
      "2/2 - 0s - loss: 0.2609 - accuracy: 0.7627 - val_loss: 0.5093 - val_accuracy: 0.7692\n",
      "Epoch 165/250\n",
      "2/2 - 0s - loss: 0.2417 - accuracy: 0.7627 - val_loss: 0.5117 - val_accuracy: 0.7692\n",
      "Epoch 166/250\n",
      "2/2 - 0s - loss: 0.2467 - accuracy: 0.7627 - val_loss: 0.5138 - val_accuracy: 0.7692\n",
      "Epoch 167/250\n",
      "2/2 - 0s - loss: 0.2639 - accuracy: 0.7627 - val_loss: 0.5164 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/250\n",
      "2/2 - 0s - loss: 0.2599 - accuracy: 0.7627 - val_loss: 0.5195 - val_accuracy: 0.7692\n",
      "Epoch 169/250\n",
      "2/2 - 0s - loss: 0.2480 - accuracy: 0.7627 - val_loss: 0.5221 - val_accuracy: 0.7692\n",
      "Epoch 170/250\n",
      "2/2 - 0s - loss: 0.2340 - accuracy: 0.7627 - val_loss: 0.5251 - val_accuracy: 0.7692\n",
      "Epoch 171/250\n",
      "2/2 - 0s - loss: 0.2416 - accuracy: 0.7627 - val_loss: 0.5286 - val_accuracy: 0.7692\n",
      "Epoch 172/250\n",
      "2/2 - 0s - loss: 0.2800 - accuracy: 0.7627 - val_loss: 0.5320 - val_accuracy: 0.7692\n",
      "Epoch 173/250\n",
      "2/2 - 0s - loss: 0.2735 - accuracy: 0.7627 - val_loss: 0.5355 - val_accuracy: 0.7692\n",
      "Epoch 174/250\n",
      "2/2 - 0s - loss: 0.2434 - accuracy: 0.7627 - val_loss: 0.5391 - val_accuracy: 0.7692\n",
      "Epoch 175/250\n",
      "2/2 - 0s - loss: 0.2616 - accuracy: 0.7627 - val_loss: 0.5423 - val_accuracy: 0.7692\n",
      "Epoch 176/250\n",
      "2/2 - 0s - loss: 0.2474 - accuracy: 0.7627 - val_loss: 0.5457 - val_accuracy: 0.7692\n",
      "Epoch 177/250\n",
      "2/2 - 0s - loss: 0.2242 - accuracy: 0.7627 - val_loss: 0.5489 - val_accuracy: 0.7692\n",
      "Epoch 178/250\n",
      "2/2 - 0s - loss: 0.2180 - accuracy: 0.7627 - val_loss: 0.5523 - val_accuracy: 0.7692\n",
      "Epoch 179/250\n",
      "2/2 - 0s - loss: 0.2339 - accuracy: 0.7627 - val_loss: 0.5557 - val_accuracy: 0.7692\n",
      "Epoch 180/250\n",
      "2/2 - 0s - loss: 0.2368 - accuracy: 0.7627 - val_loss: 0.5585 - val_accuracy: 0.7692\n",
      "Epoch 181/250\n",
      "2/2 - 0s - loss: 0.2247 - accuracy: 0.7627 - val_loss: 0.5614 - val_accuracy: 0.7692\n",
      "Epoch 182/250\n",
      "2/2 - 0s - loss: 0.2365 - accuracy: 0.7627 - val_loss: 0.5643 - val_accuracy: 0.7692\n",
      "Epoch 183/250\n",
      "2/2 - 0s - loss: 0.2408 - accuracy: 0.7627 - val_loss: 0.5676 - val_accuracy: 0.7692\n",
      "Epoch 184/250\n",
      "2/2 - 0s - loss: 0.2228 - accuracy: 0.7627 - val_loss: 0.5714 - val_accuracy: 0.7692\n",
      "Epoch 185/250\n",
      "2/2 - 0s - loss: 0.2376 - accuracy: 0.7627 - val_loss: 0.5744 - val_accuracy: 0.7692\n",
      "Epoch 186/250\n",
      "2/2 - 0s - loss: 0.2509 - accuracy: 0.7627 - val_loss: 0.5767 - val_accuracy: 0.7692\n",
      "Epoch 187/250\n",
      "2/2 - 0s - loss: 0.2362 - accuracy: 0.7627 - val_loss: 0.5798 - val_accuracy: 0.7692\n",
      "Epoch 188/250\n",
      "2/2 - 0s - loss: 0.2275 - accuracy: 0.7627 - val_loss: 0.5833 - val_accuracy: 0.7692\n",
      "Epoch 189/250\n",
      "2/2 - 0s - loss: 0.2363 - accuracy: 0.7627 - val_loss: 0.5867 - val_accuracy: 0.7692\n",
      "Epoch 190/250\n",
      "2/2 - 0s - loss: 0.2161 - accuracy: 0.7627 - val_loss: 0.5906 - val_accuracy: 0.7692\n",
      "Epoch 191/250\n",
      "2/2 - 0s - loss: 0.2099 - accuracy: 0.7627 - val_loss: 0.5944 - val_accuracy: 0.7692\n",
      "Epoch 192/250\n",
      "2/2 - 0s - loss: 0.2308 - accuracy: 0.7627 - val_loss: 0.5979 - val_accuracy: 0.7692\n",
      "Epoch 193/250\n",
      "2/2 - 0s - loss: 0.2215 - accuracy: 0.7627 - val_loss: 0.6015 - val_accuracy: 0.7692\n",
      "Epoch 194/250\n",
      "2/2 - 0s - loss: 0.2344 - accuracy: 0.7627 - val_loss: 0.6045 - val_accuracy: 0.7692\n",
      "Epoch 195/250\n",
      "2/2 - 0s - loss: 0.2213 - accuracy: 0.7627 - val_loss: 0.6083 - val_accuracy: 0.7692\n",
      "Epoch 196/250\n",
      "2/2 - 0s - loss: 0.2221 - accuracy: 0.7627 - val_loss: 0.6120 - val_accuracy: 0.7692\n",
      "Epoch 197/250\n",
      "2/2 - 0s - loss: 0.2173 - accuracy: 0.7627 - val_loss: 0.6149 - val_accuracy: 0.7692\n",
      "Epoch 198/250\n",
      "2/2 - 0s - loss: 0.2281 - accuracy: 0.7627 - val_loss: 0.6176 - val_accuracy: 0.7692\n",
      "Epoch 199/250\n",
      "2/2 - 0s - loss: 0.2139 - accuracy: 0.7627 - val_loss: 0.6208 - val_accuracy: 0.7692\n",
      "Epoch 200/250\n",
      "2/2 - 0s - loss: 0.2129 - accuracy: 0.7627 - val_loss: 0.6237 - val_accuracy: 0.7692\n",
      "Epoch 201/250\n",
      "2/2 - 0s - loss: 0.2071 - accuracy: 0.7627 - val_loss: 0.6269 - val_accuracy: 0.7692\n",
      "Epoch 202/250\n",
      "2/2 - 0s - loss: 0.2103 - accuracy: 0.7627 - val_loss: 0.6305 - val_accuracy: 0.7692\n",
      "Epoch 203/250\n",
      "2/2 - 0s - loss: 0.2187 - accuracy: 0.7627 - val_loss: 0.6345 - val_accuracy: 0.7692\n",
      "Epoch 204/250\n",
      "2/2 - 0s - loss: 0.2117 - accuracy: 0.7627 - val_loss: 0.6386 - val_accuracy: 0.7692\n",
      "Epoch 205/250\n",
      "2/2 - 0s - loss: 0.2036 - accuracy: 0.7627 - val_loss: 0.6421 - val_accuracy: 0.7692\n",
      "Epoch 206/250\n",
      "2/2 - 0s - loss: 0.2143 - accuracy: 0.7627 - val_loss: 0.6456 - val_accuracy: 0.7692\n",
      "Epoch 207/250\n",
      "2/2 - 0s - loss: 0.2115 - accuracy: 0.7627 - val_loss: 0.6490 - val_accuracy: 0.7692\n",
      "Epoch 208/250\n",
      "2/2 - 0s - loss: 0.2090 - accuracy: 0.7627 - val_loss: 0.6522 - val_accuracy: 0.7692\n",
      "Epoch 209/250\n",
      "2/2 - 0s - loss: 0.2289 - accuracy: 0.7627 - val_loss: 0.6556 - val_accuracy: 0.7692\n",
      "Epoch 210/250\n",
      "2/2 - 0s - loss: 0.2044 - accuracy: 0.7627 - val_loss: 0.6592 - val_accuracy: 0.7692\n",
      "Epoch 211/250\n",
      "2/2 - 0s - loss: 0.2155 - accuracy: 0.7627 - val_loss: 0.6632 - val_accuracy: 0.7692\n",
      "Epoch 212/250\n",
      "2/2 - 0s - loss: 0.2367 - accuracy: 0.7627 - val_loss: 0.6669 - val_accuracy: 0.7692\n",
      "Epoch 213/250\n",
      "2/2 - 0s - loss: 0.1952 - accuracy: 0.7627 - val_loss: 0.6710 - val_accuracy: 0.7692\n",
      "Epoch 214/250\n",
      "2/2 - 0s - loss: 0.2137 - accuracy: 0.7627 - val_loss: 0.6748 - val_accuracy: 0.7692\n",
      "Epoch 215/250\n",
      "2/2 - 0s - loss: 0.2073 - accuracy: 0.7627 - val_loss: 0.6777 - val_accuracy: 0.7692\n",
      "Epoch 216/250\n",
      "2/2 - 0s - loss: 0.2172 - accuracy: 0.7627 - val_loss: 0.6807 - val_accuracy: 0.7692\n",
      "Epoch 217/250\n",
      "2/2 - 0s - loss: 0.1926 - accuracy: 0.7627 - val_loss: 0.6840 - val_accuracy: 0.7692\n",
      "Epoch 218/250\n",
      "2/2 - 0s - loss: 0.2153 - accuracy: 0.7627 - val_loss: 0.6876 - val_accuracy: 0.7692\n",
      "Epoch 219/250\n",
      "2/2 - 0s - loss: 0.2251 - accuracy: 0.7627 - val_loss: 0.6920 - val_accuracy: 0.7692\n",
      "Epoch 220/250\n",
      "2/2 - 0s - loss: 0.2309 - accuracy: 0.7627 - val_loss: 0.6964 - val_accuracy: 0.7692\n",
      "Epoch 221/250\n",
      "2/2 - 0s - loss: 0.1947 - accuracy: 0.7627 - val_loss: 0.7009 - val_accuracy: 0.7692\n",
      "Epoch 222/250\n",
      "2/2 - 0s - loss: 0.1905 - accuracy: 0.7627 - val_loss: 0.7055 - val_accuracy: 0.7692\n",
      "Epoch 223/250\n",
      "2/2 - 0s - loss: 0.2036 - accuracy: 0.7627 - val_loss: 0.7099 - val_accuracy: 0.7692\n",
      "Epoch 224/250\n",
      "2/2 - 0s - loss: 0.2101 - accuracy: 0.7627 - val_loss: 0.7138 - val_accuracy: 0.7692\n",
      "Epoch 225/250\n",
      "2/2 - 0s - loss: 0.2065 - accuracy: 0.7627 - val_loss: 0.7181 - val_accuracy: 0.7692\n",
      "Epoch 226/250\n",
      "2/2 - 0s - loss: 0.1971 - accuracy: 0.7627 - val_loss: 0.7219 - val_accuracy: 0.7692\n",
      "Epoch 227/250\n",
      "2/2 - 0s - loss: 0.1919 - accuracy: 0.7627 - val_loss: 0.7247 - val_accuracy: 0.7692\n",
      "Epoch 228/250\n",
      "2/2 - 0s - loss: 0.2060 - accuracy: 0.7627 - val_loss: 0.7269 - val_accuracy: 0.7692\n",
      "Epoch 229/250\n",
      "2/2 - 0s - loss: 0.1943 - accuracy: 0.7627 - val_loss: 0.7300 - val_accuracy: 0.7692\n",
      "Epoch 230/250\n",
      "2/2 - 0s - loss: 0.2054 - accuracy: 0.7627 - val_loss: 0.7332 - val_accuracy: 0.7692\n",
      "Epoch 231/250\n",
      "2/2 - 0s - loss: 0.2076 - accuracy: 0.7627 - val_loss: 0.7365 - val_accuracy: 0.7692\n",
      "Epoch 232/250\n",
      "2/2 - 0s - loss: 0.1965 - accuracy: 0.7627 - val_loss: 0.7398 - val_accuracy: 0.7692\n",
      "Epoch 233/250\n",
      "2/2 - 0s - loss: 0.1807 - accuracy: 0.7627 - val_loss: 0.7432 - val_accuracy: 0.7692\n",
      "Epoch 234/250\n",
      "2/2 - 0s - loss: 0.1865 - accuracy: 0.7627 - val_loss: 0.7466 - val_accuracy: 0.7692\n",
      "Epoch 235/250\n",
      "2/2 - 0s - loss: 0.1879 - accuracy: 0.7627 - val_loss: 0.7501 - val_accuracy: 0.7692\n",
      "Epoch 236/250\n",
      "2/2 - 0s - loss: 0.1906 - accuracy: 0.7627 - val_loss: 0.7533 - val_accuracy: 0.7692\n",
      "Epoch 237/250\n",
      "2/2 - 0s - loss: 0.1914 - accuracy: 0.7627 - val_loss: 0.7564 - val_accuracy: 0.7692\n",
      "Epoch 238/250\n",
      "2/2 - 0s - loss: 0.1956 - accuracy: 0.7627 - val_loss: 0.7592 - val_accuracy: 0.7692\n",
      "Epoch 239/250\n",
      "2/2 - 0s - loss: 0.1872 - accuracy: 0.7627 - val_loss: 0.7620 - val_accuracy: 0.7692\n",
      "Epoch 240/250\n",
      "2/2 - 0s - loss: 0.2020 - accuracy: 0.7627 - val_loss: 0.7648 - val_accuracy: 0.7692\n",
      "Epoch 241/250\n",
      "2/2 - 0s - loss: 0.1978 - accuracy: 0.7627 - val_loss: 0.7682 - val_accuracy: 0.7692\n",
      "Epoch 242/250\n",
      "2/2 - 0s - loss: 0.1861 - accuracy: 0.7627 - val_loss: 0.7717 - val_accuracy: 0.7692\n",
      "Epoch 243/250\n",
      "2/2 - 0s - loss: 0.1777 - accuracy: 0.7627 - val_loss: 0.7748 - val_accuracy: 0.7692\n",
      "Epoch 244/250\n",
      "2/2 - 0s - loss: 0.1756 - accuracy: 0.7627 - val_loss: 0.7774 - val_accuracy: 0.7692\n",
      "Epoch 245/250\n",
      "2/2 - 0s - loss: 0.1822 - accuracy: 0.7627 - val_loss: 0.7798 - val_accuracy: 0.7692\n",
      "Epoch 246/250\n",
      "2/2 - 0s - loss: 0.1767 - accuracy: 0.7627 - val_loss: 0.7821 - val_accuracy: 0.7692\n",
      "Epoch 247/250\n",
      "2/2 - 0s - loss: 0.1925 - accuracy: 0.7627 - val_loss: 0.7858 - val_accuracy: 0.7692\n",
      "Epoch 248/250\n",
      "2/2 - 0s - loss: 0.1970 - accuracy: 0.7627 - val_loss: 0.7908 - val_accuracy: 0.7692\n",
      "Epoch 249/250\n",
      "2/2 - 0s - loss: 0.1743 - accuracy: 0.7627 - val_loss: 0.7962 - val_accuracy: 0.7692\n",
      "Epoch 250/250\n",
      "2/2 - 0s - loss: 0.1879 - accuracy: 0.7627 - val_loss: 0.8013 - val_accuracy: 0.7692\n"
     ]
    }
   ],
   "source": [
    "mlp_search = mlp_search(shape)\n",
    "history = mlp_search.fit(X_train, np.asarray(y_train[\"Search\"]).reshape(-1,1),\n",
    "                  validation_data=(X_validation, np.asarray(y_validation[\"Search\"]).reshape(-1,1)),\n",
    "    epochs=250,\n",
    "    workers = 2, use_multiprocessing= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_suggestion(shape):\n",
    "# define our MLP network\n",
    "    initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=42)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=shape, kernel_initializer = initializer, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2, activation=\"relu\"))\n",
    "# check to see if the regression node should be added\n",
    "    #if regress:\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    #Compile model\n",
    "    opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss='binary_crossentropy', metrics = [\"accuracy\"], optimizer = opt)\n",
    "# return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_10/dense_50/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_10/dense_50/embedding_lookup_sparse/Reshape:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_10/dense_50/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 1s - loss: 0.6975 - accuracy: 0.4915 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 2/250\n",
      "2/2 - 0s - loss: 0.7021 - accuracy: 0.4915 - val_loss: 0.6891 - val_accuracy: 0.5000\n",
      "Epoch 3/250\n",
      "2/2 - 0s - loss: 0.6776 - accuracy: 0.6780 - val_loss: 0.6851 - val_accuracy: 0.6538\n",
      "Epoch 4/250\n",
      "2/2 - 0s - loss: 0.6752 - accuracy: 0.6441 - val_loss: 0.6813 - val_accuracy: 0.6154\n",
      "Epoch 5/250\n",
      "2/2 - 0s - loss: 0.6946 - accuracy: 0.6102 - val_loss: 0.6778 - val_accuracy: 0.6154\n",
      "Epoch 6/250\n",
      "2/2 - 0s - loss: 0.6858 - accuracy: 0.5254 - val_loss: 0.6744 - val_accuracy: 0.6923\n",
      "Epoch 7/250\n",
      "2/2 - 0s - loss: 0.6757 - accuracy: 0.6780 - val_loss: 0.6713 - val_accuracy: 0.7692\n",
      "Epoch 8/250\n",
      "2/2 - 0s - loss: 0.6617 - accuracy: 0.6610 - val_loss: 0.6685 - val_accuracy: 0.7692\n",
      "Epoch 9/250\n",
      "2/2 - 0s - loss: 0.6811 - accuracy: 0.5763 - val_loss: 0.6659 - val_accuracy: 0.7692\n",
      "Epoch 10/250\n",
      "2/2 - 0s - loss: 0.6690 - accuracy: 0.6441 - val_loss: 0.6633 - val_accuracy: 0.7692\n",
      "Epoch 11/250\n",
      "2/2 - 0s - loss: 0.6651 - accuracy: 0.6610 - val_loss: 0.6606 - val_accuracy: 0.7692\n",
      "Epoch 12/250\n",
      "2/2 - 0s - loss: 0.6751 - accuracy: 0.6271 - val_loss: 0.6578 - val_accuracy: 0.8077\n",
      "Epoch 13/250\n",
      "2/2 - 0s - loss: 0.6633 - accuracy: 0.5932 - val_loss: 0.6551 - val_accuracy: 0.8077\n",
      "Epoch 14/250\n",
      "2/2 - 0s - loss: 0.6427 - accuracy: 0.7458 - val_loss: 0.6524 - val_accuracy: 0.7692\n",
      "Epoch 15/250\n",
      "2/2 - 0s - loss: 0.6305 - accuracy: 0.7288 - val_loss: 0.6494 - val_accuracy: 0.7692\n",
      "Epoch 16/250\n",
      "2/2 - 0s - loss: 0.6465 - accuracy: 0.6949 - val_loss: 0.6462 - val_accuracy: 0.7692\n",
      "Epoch 17/250\n",
      "2/2 - 0s - loss: 0.6618 - accuracy: 0.6949 - val_loss: 0.6431 - val_accuracy: 0.7692\n",
      "Epoch 18/250\n",
      "2/2 - 0s - loss: 0.6418 - accuracy: 0.7458 - val_loss: 0.6398 - val_accuracy: 0.7692\n",
      "Epoch 19/250\n",
      "2/2 - 0s - loss: 0.6393 - accuracy: 0.6780 - val_loss: 0.6367 - val_accuracy: 0.7692\n",
      "Epoch 20/250\n",
      "2/2 - 0s - loss: 0.6207 - accuracy: 0.7288 - val_loss: 0.6336 - val_accuracy: 0.7692\n",
      "Epoch 21/250\n",
      "2/2 - 0s - loss: 0.6274 - accuracy: 0.7458 - val_loss: 0.6304 - val_accuracy: 0.7692\n",
      "Epoch 22/250\n",
      "2/2 - 0s - loss: 0.6148 - accuracy: 0.7458 - val_loss: 0.6272 - val_accuracy: 0.7692\n",
      "Epoch 23/250\n",
      "2/2 - 0s - loss: 0.6092 - accuracy: 0.7458 - val_loss: 0.6239 - val_accuracy: 0.7692\n",
      "Epoch 24/250\n",
      "2/2 - 0s - loss: 0.6248 - accuracy: 0.7119 - val_loss: 0.6203 - val_accuracy: 0.7692\n",
      "Epoch 25/250\n",
      "2/2 - 0s - loss: 0.6335 - accuracy: 0.7119 - val_loss: 0.6169 - val_accuracy: 0.7692\n",
      "Epoch 26/250\n",
      "2/2 - 0s - loss: 0.5979 - accuracy: 0.7627 - val_loss: 0.6133 - val_accuracy: 0.7692\n",
      "Epoch 27/250\n",
      "2/2 - 0s - loss: 0.6103 - accuracy: 0.7458 - val_loss: 0.6097 - val_accuracy: 0.7692\n",
      "Epoch 28/250\n",
      "2/2 - 0s - loss: 0.6051 - accuracy: 0.7458 - val_loss: 0.6059 - val_accuracy: 0.7692\n",
      "Epoch 29/250\n",
      "2/2 - 0s - loss: 0.6048 - accuracy: 0.7458 - val_loss: 0.6020 - val_accuracy: 0.7692\n",
      "Epoch 30/250\n",
      "2/2 - 0s - loss: 0.5907 - accuracy: 0.7288 - val_loss: 0.5982 - val_accuracy: 0.7692\n",
      "Epoch 31/250\n",
      "2/2 - 0s - loss: 0.5865 - accuracy: 0.7288 - val_loss: 0.5943 - val_accuracy: 0.7692\n",
      "Epoch 32/250\n",
      "2/2 - 0s - loss: 0.5674 - accuracy: 0.7458 - val_loss: 0.5899 - val_accuracy: 0.7692\n",
      "Epoch 33/250\n",
      "2/2 - 0s - loss: 0.5777 - accuracy: 0.7458 - val_loss: 0.5856 - val_accuracy: 0.7692\n",
      "Epoch 34/250\n",
      "2/2 - 0s - loss: 0.5865 - accuracy: 0.7119 - val_loss: 0.5815 - val_accuracy: 0.7692\n",
      "Epoch 35/250\n",
      "2/2 - 0s - loss: 0.5590 - accuracy: 0.7119 - val_loss: 0.5775 - val_accuracy: 0.7692\n",
      "Epoch 36/250\n",
      "2/2 - 0s - loss: 0.5885 - accuracy: 0.7627 - val_loss: 0.5735 - val_accuracy: 0.7692\n",
      "Epoch 37/250\n",
      "2/2 - 0s - loss: 0.5678 - accuracy: 0.7288 - val_loss: 0.5697 - val_accuracy: 0.7692\n",
      "Epoch 38/250\n",
      "2/2 - 0s - loss: 0.5751 - accuracy: 0.7458 - val_loss: 0.5660 - val_accuracy: 0.7692\n",
      "Epoch 39/250\n",
      "2/2 - 0s - loss: 0.5849 - accuracy: 0.7119 - val_loss: 0.5626 - val_accuracy: 0.7692\n",
      "Epoch 40/250\n",
      "2/2 - 0s - loss: 0.5661 - accuracy: 0.7458 - val_loss: 0.5593 - val_accuracy: 0.7692\n",
      "Epoch 41/250\n",
      "2/2 - 0s - loss: 0.5921 - accuracy: 0.7458 - val_loss: 0.5564 - val_accuracy: 0.7692\n",
      "Epoch 42/250\n",
      "2/2 - 0s - loss: 0.5346 - accuracy: 0.7627 - val_loss: 0.5533 - val_accuracy: 0.7692\n",
      "Epoch 43/250\n",
      "2/2 - 0s - loss: 0.5493 - accuracy: 0.7627 - val_loss: 0.5501 - val_accuracy: 0.7692\n",
      "Epoch 44/250\n",
      "2/2 - 0s - loss: 0.5483 - accuracy: 0.7458 - val_loss: 0.5471 - val_accuracy: 0.7692\n",
      "Epoch 45/250\n",
      "2/2 - 0s - loss: 0.5578 - accuracy: 0.7627 - val_loss: 0.5435 - val_accuracy: 0.7692\n",
      "Epoch 46/250\n",
      "2/2 - 0s - loss: 0.5065 - accuracy: 0.7627 - val_loss: 0.5399 - val_accuracy: 0.7692\n",
      "Epoch 47/250\n",
      "2/2 - 0s - loss: 0.5539 - accuracy: 0.7458 - val_loss: 0.5365 - val_accuracy: 0.7692\n",
      "Epoch 48/250\n",
      "2/2 - 0s - loss: 0.5296 - accuracy: 0.7627 - val_loss: 0.5329 - val_accuracy: 0.7692\n",
      "Epoch 49/250\n",
      "2/2 - 0s - loss: 0.5515 - accuracy: 0.7627 - val_loss: 0.5292 - val_accuracy: 0.7692\n",
      "Epoch 50/250\n",
      "2/2 - 0s - loss: 0.5085 - accuracy: 0.7627 - val_loss: 0.5259 - val_accuracy: 0.7692\n",
      "Epoch 51/250\n",
      "2/2 - 0s - loss: 0.5164 - accuracy: 0.7627 - val_loss: 0.5224 - val_accuracy: 0.7692\n",
      "Epoch 52/250\n",
      "2/2 - 0s - loss: 0.4837 - accuracy: 0.7627 - val_loss: 0.5188 - val_accuracy: 0.7692\n",
      "Epoch 53/250\n",
      "2/2 - 0s - loss: 0.5071 - accuracy: 0.7627 - val_loss: 0.5152 - val_accuracy: 0.7692\n",
      "Epoch 54/250\n",
      "2/2 - 0s - loss: 0.5199 - accuracy: 0.7627 - val_loss: 0.5116 - val_accuracy: 0.7692\n",
      "Epoch 55/250\n",
      "2/2 - 0s - loss: 0.5265 - accuracy: 0.7627 - val_loss: 0.5083 - val_accuracy: 0.7692\n",
      "Epoch 56/250\n",
      "2/2 - 0s - loss: 0.5115 - accuracy: 0.7627 - val_loss: 0.5050 - val_accuracy: 0.7692\n",
      "Epoch 57/250\n",
      "2/2 - 0s - loss: 0.5255 - accuracy: 0.7627 - val_loss: 0.5017 - val_accuracy: 0.7692\n",
      "Epoch 58/250\n",
      "2/2 - 0s - loss: 0.5010 - accuracy: 0.7627 - val_loss: 0.4984 - val_accuracy: 0.7692\n",
      "Epoch 59/250\n",
      "2/2 - 0s - loss: 0.5660 - accuracy: 0.7627 - val_loss: 0.4953 - val_accuracy: 0.7692\n",
      "Epoch 60/250\n",
      "2/2 - 0s - loss: 0.5061 - accuracy: 0.7627 - val_loss: 0.4923 - val_accuracy: 0.7692\n",
      "Epoch 61/250\n",
      "2/2 - 0s - loss: 0.4849 - accuracy: 0.7627 - val_loss: 0.4891 - val_accuracy: 0.7692\n",
      "Epoch 62/250\n",
      "2/2 - 0s - loss: 0.4696 - accuracy: 0.7627 - val_loss: 0.4862 - val_accuracy: 0.7692\n",
      "Epoch 63/250\n",
      "2/2 - 0s - loss: 0.4874 - accuracy: 0.7627 - val_loss: 0.4830 - val_accuracy: 0.7692\n",
      "Epoch 64/250\n",
      "2/2 - 0s - loss: 0.4722 - accuracy: 0.7627 - val_loss: 0.4799 - val_accuracy: 0.7692\n",
      "Epoch 65/250\n",
      "2/2 - 0s - loss: 0.4797 - accuracy: 0.7627 - val_loss: 0.4768 - val_accuracy: 0.7692\n",
      "Epoch 66/250\n",
      "2/2 - 0s - loss: 0.4988 - accuracy: 0.7627 - val_loss: 0.4738 - val_accuracy: 0.7692\n",
      "Epoch 67/250\n",
      "2/2 - 0s - loss: 0.4676 - accuracy: 0.7627 - val_loss: 0.4709 - val_accuracy: 0.7692\n",
      "Epoch 68/250\n",
      "2/2 - 0s - loss: 0.4818 - accuracy: 0.7627 - val_loss: 0.4681 - val_accuracy: 0.7692\n",
      "Epoch 69/250\n",
      "2/2 - 0s - loss: 0.4651 - accuracy: 0.7627 - val_loss: 0.4655 - val_accuracy: 0.7692\n",
      "Epoch 70/250\n",
      "2/2 - 0s - loss: 0.4835 - accuracy: 0.7627 - val_loss: 0.4629 - val_accuracy: 0.7692\n",
      "Epoch 71/250\n",
      "2/2 - 0s - loss: 0.4297 - accuracy: 0.7627 - val_loss: 0.4601 - val_accuracy: 0.7692\n",
      "Epoch 72/250\n",
      "2/2 - 0s - loss: 0.5202 - accuracy: 0.7627 - val_loss: 0.4576 - val_accuracy: 0.7692\n",
      "Epoch 73/250\n",
      "2/2 - 0s - loss: 0.4222 - accuracy: 0.7627 - val_loss: 0.4551 - val_accuracy: 0.7692\n",
      "Epoch 74/250\n",
      "2/2 - 0s - loss: 0.4530 - accuracy: 0.7627 - val_loss: 0.4525 - val_accuracy: 0.7692\n",
      "Epoch 75/250\n",
      "2/2 - 0s - loss: 0.4377 - accuracy: 0.7627 - val_loss: 0.4500 - val_accuracy: 0.7692\n",
      "Epoch 76/250\n",
      "2/2 - 0s - loss: 0.4240 - accuracy: 0.7627 - val_loss: 0.4473 - val_accuracy: 0.7692\n",
      "Epoch 77/250\n",
      "2/2 - 0s - loss: 0.4587 - accuracy: 0.7627 - val_loss: 0.4448 - val_accuracy: 0.7692\n",
      "Epoch 78/250\n",
      "2/2 - 0s - loss: 0.4242 - accuracy: 0.7627 - val_loss: 0.4420 - val_accuracy: 0.7692\n",
      "Epoch 79/250\n",
      "2/2 - 0s - loss: 0.4425 - accuracy: 0.7627 - val_loss: 0.4394 - val_accuracy: 0.7692\n",
      "Epoch 80/250\n",
      "2/2 - 0s - loss: 0.4309 - accuracy: 0.7627 - val_loss: 0.4369 - val_accuracy: 0.7692\n",
      "Epoch 81/250\n",
      "2/2 - 0s - loss: 0.4436 - accuracy: 0.7627 - val_loss: 0.4347 - val_accuracy: 0.7692\n",
      "Epoch 82/250\n",
      "2/2 - 0s - loss: 0.4378 - accuracy: 0.7627 - val_loss: 0.4325 - val_accuracy: 0.7692\n",
      "Epoch 83/250\n",
      "2/2 - 0s - loss: 0.4195 - accuracy: 0.7627 - val_loss: 0.4305 - val_accuracy: 0.7692\n",
      "Epoch 84/250\n",
      "2/2 - 0s - loss: 0.4464 - accuracy: 0.7627 - val_loss: 0.4284 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/250\n",
      "2/2 - 0s - loss: 0.4287 - accuracy: 0.7627 - val_loss: 0.4263 - val_accuracy: 0.7692\n",
      "Epoch 86/250\n",
      "2/2 - 0s - loss: 0.4347 - accuracy: 0.7627 - val_loss: 0.4242 - val_accuracy: 0.7692\n",
      "Epoch 87/250\n",
      "2/2 - 0s - loss: 0.4348 - accuracy: 0.7627 - val_loss: 0.4219 - val_accuracy: 0.7692\n",
      "Epoch 88/250\n",
      "2/2 - 0s - loss: 0.4568 - accuracy: 0.7627 - val_loss: 0.4198 - val_accuracy: 0.7692\n",
      "Epoch 89/250\n",
      "2/2 - 0s - loss: 0.4220 - accuracy: 0.7627 - val_loss: 0.4179 - val_accuracy: 0.7692\n",
      "Epoch 90/250\n",
      "2/2 - 0s - loss: 0.4113 - accuracy: 0.7627 - val_loss: 0.4160 - val_accuracy: 0.7692\n",
      "Epoch 91/250\n",
      "2/2 - 0s - loss: 0.4062 - accuracy: 0.7627 - val_loss: 0.4142 - val_accuracy: 0.7692\n",
      "Epoch 92/250\n",
      "2/2 - 0s - loss: 0.4157 - accuracy: 0.7627 - val_loss: 0.4125 - val_accuracy: 0.7692\n",
      "Epoch 93/250\n",
      "2/2 - 0s - loss: 0.3628 - accuracy: 0.7627 - val_loss: 0.4108 - val_accuracy: 0.7692\n",
      "Epoch 94/250\n",
      "2/2 - 0s - loss: 0.4085 - accuracy: 0.7627 - val_loss: 0.4093 - val_accuracy: 0.7692\n",
      "Epoch 95/250\n",
      "2/2 - 0s - loss: 0.4331 - accuracy: 0.7627 - val_loss: 0.4078 - val_accuracy: 0.7692\n",
      "Epoch 96/250\n",
      "2/2 - 0s - loss: 0.4231 - accuracy: 0.7627 - val_loss: 0.4065 - val_accuracy: 0.7692\n",
      "Epoch 97/250\n",
      "2/2 - 0s - loss: 0.3848 - accuracy: 0.7627 - val_loss: 0.4052 - val_accuracy: 0.7692\n",
      "Epoch 98/250\n",
      "2/2 - 0s - loss: 0.3866 - accuracy: 0.7627 - val_loss: 0.4039 - val_accuracy: 0.7692\n",
      "Epoch 99/250\n",
      "2/2 - 0s - loss: 0.4435 - accuracy: 0.7627 - val_loss: 0.4027 - val_accuracy: 0.7692\n",
      "Epoch 100/250\n",
      "2/2 - 0s - loss: 0.3924 - accuracy: 0.7627 - val_loss: 0.4013 - val_accuracy: 0.7692\n",
      "Epoch 101/250\n",
      "2/2 - 0s - loss: 0.3733 - accuracy: 0.7627 - val_loss: 0.4000 - val_accuracy: 0.7692\n",
      "Epoch 102/250\n",
      "2/2 - 0s - loss: 0.3923 - accuracy: 0.7627 - val_loss: 0.3988 - val_accuracy: 0.7692\n",
      "Epoch 103/250\n",
      "2/2 - 0s - loss: 0.3661 - accuracy: 0.7627 - val_loss: 0.3976 - val_accuracy: 0.7692\n",
      "Epoch 104/250\n",
      "2/2 - 0s - loss: 0.3716 - accuracy: 0.7627 - val_loss: 0.3963 - val_accuracy: 0.7692\n",
      "Epoch 105/250\n",
      "2/2 - 0s - loss: 0.4065 - accuracy: 0.7627 - val_loss: 0.3949 - val_accuracy: 0.7692\n",
      "Epoch 106/250\n",
      "2/2 - 0s - loss: 0.3422 - accuracy: 0.7627 - val_loss: 0.3932 - val_accuracy: 0.7692\n",
      "Epoch 107/250\n",
      "2/2 - 0s - loss: 0.3802 - accuracy: 0.7627 - val_loss: 0.3916 - val_accuracy: 0.7692\n",
      "Epoch 108/250\n",
      "2/2 - 0s - loss: 0.3495 - accuracy: 0.7627 - val_loss: 0.3901 - val_accuracy: 0.7692\n",
      "Epoch 109/250\n",
      "2/2 - 0s - loss: 0.3559 - accuracy: 0.7627 - val_loss: 0.3888 - val_accuracy: 0.7692\n",
      "Epoch 110/250\n",
      "2/2 - 0s - loss: 0.3320 - accuracy: 0.7627 - val_loss: 0.3877 - val_accuracy: 0.7692\n",
      "Epoch 111/250\n",
      "2/2 - 0s - loss: 0.3928 - accuracy: 0.7627 - val_loss: 0.3864 - val_accuracy: 0.7692\n",
      "Epoch 112/250\n",
      "2/2 - 0s - loss: 0.3308 - accuracy: 0.7627 - val_loss: 0.3852 - val_accuracy: 0.7692\n",
      "Epoch 113/250\n",
      "2/2 - 0s - loss: 0.3628 - accuracy: 0.7627 - val_loss: 0.3840 - val_accuracy: 0.7692\n",
      "Epoch 114/250\n",
      "2/2 - 0s - loss: 0.3303 - accuracy: 0.7627 - val_loss: 0.3828 - val_accuracy: 0.7692\n",
      "Epoch 115/250\n",
      "2/2 - 0s - loss: 0.3400 - accuracy: 0.7627 - val_loss: 0.3819 - val_accuracy: 0.7692\n",
      "Epoch 116/250\n",
      "2/2 - 0s - loss: 0.3290 - accuracy: 0.7627 - val_loss: 0.3810 - val_accuracy: 0.7692\n",
      "Epoch 117/250\n",
      "2/2 - 0s - loss: 0.3438 - accuracy: 0.7797 - val_loss: 0.3803 - val_accuracy: 0.7692\n",
      "Epoch 118/250\n",
      "2/2 - 0s - loss: 0.3956 - accuracy: 0.7627 - val_loss: 0.3795 - val_accuracy: 0.7692\n",
      "Epoch 119/250\n",
      "2/2 - 0s - loss: 0.3809 - accuracy: 0.7627 - val_loss: 0.3789 - val_accuracy: 0.7692\n",
      "Epoch 120/250\n",
      "2/2 - 0s - loss: 0.3098 - accuracy: 0.7797 - val_loss: 0.3783 - val_accuracy: 0.7692\n",
      "Epoch 121/250\n",
      "2/2 - 0s - loss: 0.3788 - accuracy: 0.7797 - val_loss: 0.3778 - val_accuracy: 0.7692\n",
      "Epoch 122/250\n",
      "2/2 - 0s - loss: 0.2981 - accuracy: 0.7797 - val_loss: 0.3770 - val_accuracy: 0.7692\n",
      "Epoch 123/250\n",
      "2/2 - 0s - loss: 0.3370 - accuracy: 0.7797 - val_loss: 0.3760 - val_accuracy: 0.7692\n",
      "Epoch 124/250\n",
      "2/2 - 0s - loss: 0.2911 - accuracy: 0.7797 - val_loss: 0.3747 - val_accuracy: 0.7692\n",
      "Epoch 125/250\n",
      "2/2 - 0s - loss: 0.3101 - accuracy: 0.7627 - val_loss: 0.3736 - val_accuracy: 0.7692\n",
      "Epoch 126/250\n",
      "2/2 - 0s - loss: 0.3421 - accuracy: 0.7797 - val_loss: 0.3725 - val_accuracy: 0.7692\n",
      "Epoch 127/250\n",
      "2/2 - 0s - loss: 0.3534 - accuracy: 0.7627 - val_loss: 0.3713 - val_accuracy: 0.7692\n",
      "Epoch 128/250\n",
      "2/2 - 0s - loss: 0.3130 - accuracy: 0.8305 - val_loss: 0.3699 - val_accuracy: 0.7692\n",
      "Epoch 129/250\n",
      "2/2 - 0s - loss: 0.3662 - accuracy: 0.7966 - val_loss: 0.3682 - val_accuracy: 0.7692\n",
      "Epoch 130/250\n",
      "2/2 - 0s - loss: 0.2644 - accuracy: 0.8136 - val_loss: 0.3664 - val_accuracy: 0.7692\n",
      "Epoch 131/250\n",
      "2/2 - 0s - loss: 0.3460 - accuracy: 0.8136 - val_loss: 0.3647 - val_accuracy: 0.7692\n",
      "Epoch 132/250\n",
      "2/2 - 0s - loss: 0.3104 - accuracy: 0.7966 - val_loss: 0.3633 - val_accuracy: 0.7692\n",
      "Epoch 133/250\n",
      "2/2 - 0s - loss: 0.3208 - accuracy: 0.7627 - val_loss: 0.3616 - val_accuracy: 0.7692\n",
      "Epoch 134/250\n",
      "2/2 - 0s - loss: 0.3075 - accuracy: 0.8305 - val_loss: 0.3601 - val_accuracy: 0.7692\n",
      "Epoch 135/250\n",
      "2/2 - 0s - loss: 0.2725 - accuracy: 0.8475 - val_loss: 0.3592 - val_accuracy: 0.7692\n",
      "Epoch 136/250\n",
      "2/2 - 0s - loss: 0.2844 - accuracy: 0.8644 - val_loss: 0.3585 - val_accuracy: 0.7692\n",
      "Epoch 137/250\n",
      "2/2 - 0s - loss: 0.2791 - accuracy: 0.8136 - val_loss: 0.3580 - val_accuracy: 0.7692\n",
      "Epoch 138/250\n",
      "2/2 - 0s - loss: 0.2773 - accuracy: 0.8814 - val_loss: 0.3576 - val_accuracy: 0.7692\n",
      "Epoch 139/250\n",
      "2/2 - 0s - loss: 0.3060 - accuracy: 0.8644 - val_loss: 0.3572 - val_accuracy: 0.7692\n",
      "Epoch 140/250\n",
      "2/2 - 0s - loss: 0.2695 - accuracy: 0.8983 - val_loss: 0.3567 - val_accuracy: 0.7692\n",
      "Epoch 141/250\n",
      "2/2 - 0s - loss: 0.2857 - accuracy: 0.8644 - val_loss: 0.3561 - val_accuracy: 0.7692\n",
      "Epoch 142/250\n",
      "2/2 - 0s - loss: 0.2852 - accuracy: 0.8305 - val_loss: 0.3557 - val_accuracy: 0.7692\n",
      "Epoch 143/250\n",
      "2/2 - 0s - loss: 0.3196 - accuracy: 0.8814 - val_loss: 0.3556 - val_accuracy: 0.7692\n",
      "Epoch 144/250\n",
      "2/2 - 0s - loss: 0.3003 - accuracy: 0.8644 - val_loss: 0.3554 - val_accuracy: 0.7692\n",
      "Epoch 145/250\n",
      "2/2 - 0s - loss: 0.2923 - accuracy: 0.8475 - val_loss: 0.3551 - val_accuracy: 0.8462\n",
      "Epoch 146/250\n",
      "2/2 - 0s - loss: 0.3009 - accuracy: 0.8475 - val_loss: 0.3549 - val_accuracy: 0.8846\n",
      "Epoch 147/250\n",
      "2/2 - 0s - loss: 0.2634 - accuracy: 0.8644 - val_loss: 0.3547 - val_accuracy: 0.8846\n",
      "Epoch 148/250\n",
      "2/2 - 0s - loss: 0.2626 - accuracy: 0.8814 - val_loss: 0.3546 - val_accuracy: 0.8846\n",
      "Epoch 149/250\n",
      "2/2 - 0s - loss: 0.2360 - accuracy: 0.8983 - val_loss: 0.3546 - val_accuracy: 0.8846\n",
      "Epoch 150/250\n",
      "2/2 - 0s - loss: 0.2692 - accuracy: 0.8305 - val_loss: 0.3548 - val_accuracy: 0.8846\n",
      "Epoch 151/250\n",
      "2/2 - 0s - loss: 0.2218 - accuracy: 0.9322 - val_loss: 0.3551 - val_accuracy: 0.8846\n",
      "Epoch 152/250\n",
      "2/2 - 0s - loss: 0.2757 - accuracy: 0.8814 - val_loss: 0.3553 - val_accuracy: 0.8846\n",
      "Epoch 153/250\n",
      "2/2 - 0s - loss: 0.2550 - accuracy: 0.8983 - val_loss: 0.3554 - val_accuracy: 0.8846\n",
      "Epoch 154/250\n",
      "2/2 - 0s - loss: 0.2530 - accuracy: 0.8305 - val_loss: 0.3555 - val_accuracy: 0.9231\n",
      "Epoch 155/250\n",
      "2/2 - 0s - loss: 0.2697 - accuracy: 0.8305 - val_loss: 0.3559 - val_accuracy: 0.9231\n",
      "Epoch 156/250\n",
      "2/2 - 0s - loss: 0.2369 - accuracy: 0.8983 - val_loss: 0.3560 - val_accuracy: 0.9231\n",
      "Epoch 157/250\n",
      "2/2 - 0s - loss: 0.2233 - accuracy: 0.8983 - val_loss: 0.3560 - val_accuracy: 0.9231\n",
      "Epoch 158/250\n",
      "2/2 - 0s - loss: 0.2170 - accuracy: 0.8983 - val_loss: 0.3561 - val_accuracy: 0.9231\n",
      "Epoch 159/250\n",
      "2/2 - 0s - loss: 0.2783 - accuracy: 0.8983 - val_loss: 0.3563 - val_accuracy: 0.9231\n",
      "Epoch 160/250\n",
      "2/2 - 0s - loss: 0.2470 - accuracy: 0.8983 - val_loss: 0.3568 - val_accuracy: 0.9231\n",
      "Epoch 161/250\n",
      "2/2 - 0s - loss: 0.2446 - accuracy: 0.8305 - val_loss: 0.3574 - val_accuracy: 0.9231\n",
      "Epoch 162/250\n",
      "2/2 - 0s - loss: 0.2460 - accuracy: 0.8475 - val_loss: 0.3580 - val_accuracy: 0.9231\n",
      "Epoch 163/250\n",
      "2/2 - 0s - loss: 0.2256 - accuracy: 0.8814 - val_loss: 0.3587 - val_accuracy: 0.9231\n",
      "Epoch 164/250\n",
      "2/2 - 0s - loss: 0.1767 - accuracy: 0.9322 - val_loss: 0.3591 - val_accuracy: 0.9231\n",
      "Epoch 165/250\n",
      "2/2 - 0s - loss: 0.2010 - accuracy: 0.9492 - val_loss: 0.3597 - val_accuracy: 0.9231\n",
      "Epoch 166/250\n",
      "2/2 - 0s - loss: 0.1933 - accuracy: 0.9153 - val_loss: 0.3601 - val_accuracy: 0.9231\n",
      "Epoch 167/250\n",
      "2/2 - 0s - loss: 0.2570 - accuracy: 0.8644 - val_loss: 0.3601 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/250\n",
      "2/2 - 0s - loss: 0.2484 - accuracy: 0.8644 - val_loss: 0.3599 - val_accuracy: 0.9231\n",
      "Epoch 169/250\n",
      "2/2 - 0s - loss: 0.2154 - accuracy: 0.9661 - val_loss: 0.3597 - val_accuracy: 0.8846\n",
      "Epoch 170/250\n",
      "2/2 - 0s - loss: 0.2519 - accuracy: 0.9153 - val_loss: 0.3592 - val_accuracy: 0.8846\n",
      "Epoch 171/250\n",
      "2/2 - 0s - loss: 0.2437 - accuracy: 0.8983 - val_loss: 0.3590 - val_accuracy: 0.8846\n",
      "Epoch 172/250\n",
      "2/2 - 0s - loss: 0.2013 - accuracy: 0.9661 - val_loss: 0.3590 - val_accuracy: 0.8846\n",
      "Epoch 173/250\n",
      "2/2 - 0s - loss: 0.1795 - accuracy: 0.8814 - val_loss: 0.3591 - val_accuracy: 0.8846\n",
      "Epoch 174/250\n",
      "2/2 - 0s - loss: 0.2043 - accuracy: 0.8983 - val_loss: 0.3596 - val_accuracy: 0.8846\n",
      "Epoch 175/250\n",
      "2/2 - 0s - loss: 0.2169 - accuracy: 0.9322 - val_loss: 0.3599 - val_accuracy: 0.8462\n",
      "Epoch 176/250\n",
      "2/2 - 0s - loss: 0.1763 - accuracy: 0.9153 - val_loss: 0.3603 - val_accuracy: 0.8462\n",
      "Epoch 177/250\n",
      "2/2 - 0s - loss: 0.2012 - accuracy: 0.8814 - val_loss: 0.3610 - val_accuracy: 0.8462\n",
      "Epoch 178/250\n",
      "2/2 - 0s - loss: 0.1767 - accuracy: 0.8983 - val_loss: 0.3617 - val_accuracy: 0.8462\n",
      "Epoch 179/250\n",
      "2/2 - 0s - loss: 0.1351 - accuracy: 0.9661 - val_loss: 0.3623 - val_accuracy: 0.8462\n",
      "Epoch 180/250\n",
      "2/2 - 0s - loss: 0.1868 - accuracy: 0.9492 - val_loss: 0.3630 - val_accuracy: 0.8462\n",
      "Epoch 181/250\n",
      "2/2 - 0s - loss: 0.1803 - accuracy: 0.8814 - val_loss: 0.3636 - val_accuracy: 0.8462\n",
      "Epoch 182/250\n",
      "2/2 - 0s - loss: 0.2028 - accuracy: 0.9153 - val_loss: 0.3638 - val_accuracy: 0.8462\n",
      "Epoch 183/250\n",
      "2/2 - 0s - loss: 0.1973 - accuracy: 0.8983 - val_loss: 0.3637 - val_accuracy: 0.8462\n",
      "Epoch 184/250\n",
      "2/2 - 0s - loss: 0.1898 - accuracy: 0.9322 - val_loss: 0.3635 - val_accuracy: 0.8462\n",
      "Epoch 185/250\n",
      "2/2 - 0s - loss: 0.1387 - accuracy: 0.9661 - val_loss: 0.3637 - val_accuracy: 0.8462\n",
      "Epoch 186/250\n",
      "2/2 - 0s - loss: 0.2047 - accuracy: 0.9322 - val_loss: 0.3643 - val_accuracy: 0.8462\n",
      "Epoch 187/250\n",
      "2/2 - 0s - loss: 0.1784 - accuracy: 0.9153 - val_loss: 0.3650 - val_accuracy: 0.8462\n",
      "Epoch 188/250\n",
      "2/2 - 0s - loss: 0.1992 - accuracy: 0.8814 - val_loss: 0.3658 - val_accuracy: 0.8462\n",
      "Epoch 189/250\n",
      "2/2 - 0s - loss: 0.2109 - accuracy: 0.8814 - val_loss: 0.3662 - val_accuracy: 0.8462\n",
      "Epoch 190/250\n",
      "2/2 - 0s - loss: 0.1973 - accuracy: 0.8814 - val_loss: 0.3659 - val_accuracy: 0.8462\n",
      "Epoch 191/250\n",
      "2/2 - 0s - loss: 0.1298 - accuracy: 0.9153 - val_loss: 0.3658 - val_accuracy: 0.8462\n",
      "Epoch 192/250\n",
      "2/2 - 0s - loss: 0.2117 - accuracy: 0.8644 - val_loss: 0.3663 - val_accuracy: 0.8462\n",
      "Epoch 193/250\n",
      "2/2 - 0s - loss: 0.1731 - accuracy: 0.8983 - val_loss: 0.3666 - val_accuracy: 0.8462\n",
      "Epoch 194/250\n",
      "2/2 - 0s - loss: 0.1695 - accuracy: 0.9492 - val_loss: 0.3666 - val_accuracy: 0.8462\n",
      "Epoch 195/250\n",
      "2/2 - 0s - loss: 0.1906 - accuracy: 0.9322 - val_loss: 0.3672 - val_accuracy: 0.8462\n",
      "Epoch 196/250\n",
      "2/2 - 0s - loss: 0.1652 - accuracy: 0.9322 - val_loss: 0.3680 - val_accuracy: 0.8462\n",
      "Epoch 197/250\n",
      "2/2 - 0s - loss: 0.1999 - accuracy: 0.8814 - val_loss: 0.3689 - val_accuracy: 0.8462\n",
      "Epoch 198/250\n",
      "2/2 - 0s - loss: 0.1488 - accuracy: 0.9153 - val_loss: 0.3697 - val_accuracy: 0.8462\n",
      "Epoch 199/250\n",
      "2/2 - 0s - loss: 0.2091 - accuracy: 0.8814 - val_loss: 0.3704 - val_accuracy: 0.8462\n",
      "Epoch 200/250\n",
      "2/2 - 0s - loss: 0.1343 - accuracy: 0.9492 - val_loss: 0.3711 - val_accuracy: 0.8846\n",
      "Epoch 201/250\n",
      "2/2 - 0s - loss: 0.1754 - accuracy: 0.8983 - val_loss: 0.3716 - val_accuracy: 0.8846\n",
      "Epoch 202/250\n",
      "2/2 - 0s - loss: 0.1545 - accuracy: 0.9153 - val_loss: 0.3718 - val_accuracy: 0.8846\n",
      "Epoch 203/250\n",
      "2/2 - 0s - loss: 0.1192 - accuracy: 0.9492 - val_loss: 0.3722 - val_accuracy: 0.8846\n",
      "Epoch 204/250\n",
      "2/2 - 0s - loss: 0.2080 - accuracy: 0.8814 - val_loss: 0.3731 - val_accuracy: 0.8846\n",
      "Epoch 205/250\n",
      "2/2 - 0s - loss: 0.1780 - accuracy: 0.8983 - val_loss: 0.3743 - val_accuracy: 0.8846\n",
      "Epoch 206/250\n",
      "2/2 - 0s - loss: 0.1556 - accuracy: 0.8983 - val_loss: 0.3758 - val_accuracy: 0.8846\n",
      "Epoch 207/250\n",
      "2/2 - 0s - loss: 0.1388 - accuracy: 0.9322 - val_loss: 0.3776 - val_accuracy: 0.8846\n",
      "Epoch 208/250\n",
      "2/2 - 0s - loss: 0.1164 - accuracy: 0.9153 - val_loss: 0.3792 - val_accuracy: 0.8846\n",
      "Epoch 209/250\n",
      "2/2 - 0s - loss: 0.1922 - accuracy: 0.8644 - val_loss: 0.3807 - val_accuracy: 0.8846\n",
      "Epoch 210/250\n",
      "2/2 - 0s - loss: 0.1699 - accuracy: 0.8983 - val_loss: 0.3829 - val_accuracy: 0.8846\n",
      "Epoch 211/250\n",
      "2/2 - 0s - loss: 0.1030 - accuracy: 0.9322 - val_loss: 0.3857 - val_accuracy: 0.8846\n",
      "Epoch 212/250\n",
      "2/2 - 0s - loss: 0.1288 - accuracy: 0.9661 - val_loss: 0.3884 - val_accuracy: 0.8846\n",
      "Epoch 213/250\n",
      "2/2 - 0s - loss: 0.1336 - accuracy: 0.9322 - val_loss: 0.3912 - val_accuracy: 0.8846\n",
      "Epoch 214/250\n",
      "2/2 - 0s - loss: 0.1446 - accuracy: 0.9661 - val_loss: 0.3930 - val_accuracy: 0.8846\n",
      "Epoch 215/250\n",
      "2/2 - 0s - loss: 0.1682 - accuracy: 0.9322 - val_loss: 0.3949 - val_accuracy: 0.8846\n",
      "Epoch 216/250\n",
      "2/2 - 0s - loss: 0.0791 - accuracy: 0.9831 - val_loss: 0.3966 - val_accuracy: 0.8846\n",
      "Epoch 217/250\n",
      "2/2 - 0s - loss: 0.1322 - accuracy: 0.8983 - val_loss: 0.3984 - val_accuracy: 0.8846\n",
      "Epoch 218/250\n",
      "2/2 - 0s - loss: 0.1470 - accuracy: 0.8983 - val_loss: 0.4004 - val_accuracy: 0.8846\n",
      "Epoch 219/250\n",
      "2/2 - 0s - loss: 0.0893 - accuracy: 0.9661 - val_loss: 0.4026 - val_accuracy: 0.8846\n",
      "Epoch 220/250\n",
      "2/2 - 0s - loss: 0.0991 - accuracy: 0.9661 - val_loss: 0.4046 - val_accuracy: 0.8462\n",
      "Epoch 221/250\n",
      "2/2 - 0s - loss: 0.1353 - accuracy: 0.8983 - val_loss: 0.4069 - val_accuracy: 0.8462\n",
      "Epoch 222/250\n",
      "2/2 - 0s - loss: 0.1371 - accuracy: 0.9153 - val_loss: 0.4087 - val_accuracy: 0.8462\n",
      "Epoch 223/250\n",
      "2/2 - 0s - loss: 0.1171 - accuracy: 0.9322 - val_loss: 0.4106 - val_accuracy: 0.8462\n",
      "Epoch 224/250\n",
      "2/2 - 0s - loss: 0.1531 - accuracy: 0.9153 - val_loss: 0.4128 - val_accuracy: 0.8462\n",
      "Epoch 225/250\n",
      "2/2 - 0s - loss: 0.1149 - accuracy: 0.9322 - val_loss: 0.4150 - val_accuracy: 0.8462\n",
      "Epoch 226/250\n",
      "2/2 - 0s - loss: 0.1143 - accuracy: 0.9322 - val_loss: 0.4175 - val_accuracy: 0.8462\n",
      "Epoch 227/250\n",
      "2/2 - 0s - loss: 0.1015 - accuracy: 0.9831 - val_loss: 0.4200 - val_accuracy: 0.8462\n",
      "Epoch 228/250\n",
      "2/2 - 0s - loss: 0.1483 - accuracy: 0.8644 - val_loss: 0.4223 - val_accuracy: 0.8462\n",
      "Epoch 229/250\n",
      "2/2 - 0s - loss: 0.1417 - accuracy: 0.8983 - val_loss: 0.4243 - val_accuracy: 0.8462\n",
      "Epoch 230/250\n",
      "2/2 - 0s - loss: 0.1557 - accuracy: 0.8983 - val_loss: 0.4263 - val_accuracy: 0.8462\n",
      "Epoch 231/250\n",
      "2/2 - 0s - loss: 0.1466 - accuracy: 0.9322 - val_loss: 0.4282 - val_accuracy: 0.8462\n",
      "Epoch 232/250\n",
      "2/2 - 0s - loss: 0.1448 - accuracy: 0.8644 - val_loss: 0.4302 - val_accuracy: 0.8462\n",
      "Epoch 233/250\n",
      "2/2 - 0s - loss: 0.1323 - accuracy: 0.8983 - val_loss: 0.4319 - val_accuracy: 0.8462\n",
      "Epoch 234/250\n",
      "2/2 - 0s - loss: 0.1733 - accuracy: 0.8814 - val_loss: 0.4337 - val_accuracy: 0.8462\n",
      "Epoch 235/250\n",
      "2/2 - 0s - loss: 0.1583 - accuracy: 0.8983 - val_loss: 0.4358 - val_accuracy: 0.8462\n",
      "Epoch 236/250\n",
      "2/2 - 0s - loss: 0.1721 - accuracy: 0.9153 - val_loss: 0.4381 - val_accuracy: 0.8462\n",
      "Epoch 237/250\n",
      "2/2 - 0s - loss: 0.1110 - accuracy: 0.9322 - val_loss: 0.4400 - val_accuracy: 0.8462\n",
      "Epoch 238/250\n",
      "2/2 - 0s - loss: 0.0780 - accuracy: 0.9661 - val_loss: 0.4423 - val_accuracy: 0.8462\n",
      "Epoch 239/250\n",
      "2/2 - 0s - loss: 0.1282 - accuracy: 0.9153 - val_loss: 0.4446 - val_accuracy: 0.8462\n",
      "Epoch 240/250\n",
      "2/2 - 0s - loss: 0.1443 - accuracy: 0.9153 - val_loss: 0.4468 - val_accuracy: 0.8462\n",
      "Epoch 241/250\n",
      "2/2 - 0s - loss: 0.1245 - accuracy: 0.9322 - val_loss: 0.4489 - val_accuracy: 0.8462\n",
      "Epoch 242/250\n",
      "2/2 - 0s - loss: 0.1103 - accuracy: 0.9322 - val_loss: 0.4492 - val_accuracy: 0.8462\n",
      "Epoch 243/250\n",
      "2/2 - 0s - loss: 0.0731 - accuracy: 0.9661 - val_loss: 0.4498 - val_accuracy: 0.8462\n",
      "Epoch 244/250\n",
      "2/2 - 0s - loss: 0.1596 - accuracy: 0.8814 - val_loss: 0.4506 - val_accuracy: 0.8462\n",
      "Epoch 245/250\n",
      "2/2 - 0s - loss: 0.0959 - accuracy: 0.9492 - val_loss: 0.4517 - val_accuracy: 0.8462\n",
      "Epoch 246/250\n",
      "2/2 - 0s - loss: 0.1301 - accuracy: 0.9322 - val_loss: 0.4531 - val_accuracy: 0.8462\n",
      "Epoch 247/250\n",
      "2/2 - 0s - loss: 0.1409 - accuracy: 0.8983 - val_loss: 0.4550 - val_accuracy: 0.8462\n",
      "Epoch 248/250\n",
      "2/2 - 0s - loss: 0.0846 - accuracy: 0.9661 - val_loss: 0.4570 - val_accuracy: 0.8462\n",
      "Epoch 249/250\n",
      "2/2 - 0s - loss: 0.0971 - accuracy: 0.9153 - val_loss: 0.4593 - val_accuracy: 0.8462\n",
      "Epoch 250/250\n",
      "2/2 - 0s - loss: 0.1500 - accuracy: 0.9322 - val_loss: 0.4614 - val_accuracy: 0.8462\n"
     ]
    }
   ],
   "source": [
    "mlp_suggestion = mlp_suggestion(shape)\n",
    "history = mlp_suggestion.fit(X_train, np.asarray(y_train[\"Search\"]).reshape(-1,1),\n",
    "                  validation_data=(X_validation, np.asarray(y_validation[\"Search\"]).reshape(-1,1)),\n",
    "    epochs=250,\n",
    "    workers = 2, use_multiprocessing= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_farewell(shape):\n",
    "# define our MLP network\n",
    "    initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=42)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=shape, kernel_initializer = initializer, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2, activation=\"relu\"))\n",
    "# check to see if the regression node should be added\n",
    "    #if regress:\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "    #Compile model\n",
    "    opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss='binary_crossentropy', metrics = [\"accuracy\"], optimizer=opt)\n",
    "# return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_11/dense_55/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_11/dense_55/embedding_lookup_sparse/Reshape:0\", shape=(None, 16), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_11/dense_55/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 1s - loss: 0.6629 - accuracy: 0.7627 - val_loss: 0.6779 - val_accuracy: 0.7692\n",
      "Epoch 2/250\n",
      "2/2 - 0s - loss: 0.6631 - accuracy: 0.7627 - val_loss: 0.6754 - val_accuracy: 0.7692\n",
      "Epoch 3/250\n",
      "2/2 - 0s - loss: 0.6689 - accuracy: 0.7627 - val_loss: 0.6728 - val_accuracy: 0.7692\n",
      "Epoch 4/250\n",
      "2/2 - 0s - loss: 0.6563 - accuracy: 0.7627 - val_loss: 0.6701 - val_accuracy: 0.7692\n",
      "Epoch 5/250\n",
      "2/2 - 0s - loss: 0.6575 - accuracy: 0.7627 - val_loss: 0.6675 - val_accuracy: 0.7692\n",
      "Epoch 6/250\n",
      "2/2 - 0s - loss: 0.6537 - accuracy: 0.7627 - val_loss: 0.6647 - val_accuracy: 0.7692\n",
      "Epoch 7/250\n",
      "2/2 - 0s - loss: 0.6330 - accuracy: 0.7627 - val_loss: 0.6616 - val_accuracy: 0.7692\n",
      "Epoch 8/250\n",
      "2/2 - 0s - loss: 0.6535 - accuracy: 0.7627 - val_loss: 0.6584 - val_accuracy: 0.7692\n",
      "Epoch 9/250\n",
      "2/2 - 0s - loss: 0.6547 - accuracy: 0.7627 - val_loss: 0.6550 - val_accuracy: 0.7692\n",
      "Epoch 10/250\n",
      "2/2 - 0s - loss: 0.6345 - accuracy: 0.7627 - val_loss: 0.6515 - val_accuracy: 0.7692\n",
      "Epoch 11/250\n",
      "2/2 - 0s - loss: 0.6188 - accuracy: 0.7627 - val_loss: 0.6480 - val_accuracy: 0.7692\n",
      "Epoch 12/250\n",
      "2/2 - 0s - loss: 0.6311 - accuracy: 0.7627 - val_loss: 0.6445 - val_accuracy: 0.7692\n",
      "Epoch 13/250\n",
      "2/2 - 0s - loss: 0.6350 - accuracy: 0.7627 - val_loss: 0.6408 - val_accuracy: 0.7692\n",
      "Epoch 14/250\n",
      "2/2 - 0s - loss: 0.6297 - accuracy: 0.7627 - val_loss: 0.6372 - val_accuracy: 0.7692\n",
      "Epoch 15/250\n",
      "2/2 - 0s - loss: 0.6069 - accuracy: 0.7627 - val_loss: 0.6334 - val_accuracy: 0.7692\n",
      "Epoch 16/250\n",
      "2/2 - 0s - loss: 0.5987 - accuracy: 0.7627 - val_loss: 0.6295 - val_accuracy: 0.7692\n",
      "Epoch 17/250\n",
      "2/2 - 0s - loss: 0.6082 - accuracy: 0.7627 - val_loss: 0.6256 - val_accuracy: 0.7692\n",
      "Epoch 18/250\n",
      "2/2 - 0s - loss: 0.6045 - accuracy: 0.7627 - val_loss: 0.6218 - val_accuracy: 0.7692\n",
      "Epoch 19/250\n",
      "2/2 - 0s - loss: 0.5969 - accuracy: 0.7627 - val_loss: 0.6180 - val_accuracy: 0.7692\n",
      "Epoch 20/250\n",
      "2/2 - 0s - loss: 0.6052 - accuracy: 0.7627 - val_loss: 0.6141 - val_accuracy: 0.7692\n",
      "Epoch 21/250\n",
      "2/2 - 0s - loss: 0.5897 - accuracy: 0.7627 - val_loss: 0.6102 - val_accuracy: 0.7692\n",
      "Epoch 22/250\n",
      "2/2 - 0s - loss: 0.5826 - accuracy: 0.7627 - val_loss: 0.6063 - val_accuracy: 0.7692\n",
      "Epoch 23/250\n",
      "2/2 - 0s - loss: 0.5719 - accuracy: 0.7627 - val_loss: 0.6022 - val_accuracy: 0.7692\n",
      "Epoch 24/250\n",
      "2/2 - 0s - loss: 0.5741 - accuracy: 0.7627 - val_loss: 0.5980 - val_accuracy: 0.7692\n",
      "Epoch 25/250\n",
      "2/2 - 0s - loss: 0.5856 - accuracy: 0.7627 - val_loss: 0.5939 - val_accuracy: 0.7692\n",
      "Epoch 26/250\n",
      "2/2 - 0s - loss: 0.5570 - accuracy: 0.7627 - val_loss: 0.5899 - val_accuracy: 0.7692\n",
      "Epoch 27/250\n",
      "2/2 - 0s - loss: 0.5619 - accuracy: 0.7627 - val_loss: 0.5858 - val_accuracy: 0.7692\n",
      "Epoch 28/250\n",
      "2/2 - 0s - loss: 0.5384 - accuracy: 0.7627 - val_loss: 0.5817 - val_accuracy: 0.7692\n",
      "Epoch 29/250\n",
      "2/2 - 0s - loss: 0.5685 - accuracy: 0.7627 - val_loss: 0.5778 - val_accuracy: 0.7692\n",
      "Epoch 30/250\n",
      "2/2 - 0s - loss: 0.5390 - accuracy: 0.7627 - val_loss: 0.5739 - val_accuracy: 0.7692\n",
      "Epoch 31/250\n",
      "2/2 - 0s - loss: 0.5463 - accuracy: 0.7627 - val_loss: 0.5700 - val_accuracy: 0.7692\n",
      "Epoch 32/250\n",
      "2/2 - 0s - loss: 0.5434 - accuracy: 0.7627 - val_loss: 0.5662 - val_accuracy: 0.7692\n",
      "Epoch 33/250\n",
      "2/2 - 0s - loss: 0.5789 - accuracy: 0.7627 - val_loss: 0.5628 - val_accuracy: 0.7692\n",
      "Epoch 34/250\n",
      "2/2 - 0s - loss: 0.5187 - accuracy: 0.7627 - val_loss: 0.5595 - val_accuracy: 0.7692\n",
      "Epoch 35/250\n",
      "2/2 - 0s - loss: 0.5588 - accuracy: 0.7627 - val_loss: 0.5564 - val_accuracy: 0.7692\n",
      "Epoch 36/250\n",
      "2/2 - 0s - loss: 0.4976 - accuracy: 0.7627 - val_loss: 0.5531 - val_accuracy: 0.7692\n",
      "Epoch 37/250\n",
      "2/2 - 0s - loss: 0.5462 - accuracy: 0.7627 - val_loss: 0.5497 - val_accuracy: 0.7692\n",
      "Epoch 38/250\n",
      "2/2 - 0s - loss: 0.5136 - accuracy: 0.7627 - val_loss: 0.5464 - val_accuracy: 0.7692\n",
      "Epoch 39/250\n",
      "2/2 - 0s - loss: 0.5176 - accuracy: 0.7627 - val_loss: 0.5432 - val_accuracy: 0.7692\n",
      "Epoch 40/250\n",
      "2/2 - 0s - loss: 0.5620 - accuracy: 0.7627 - val_loss: 0.5400 - val_accuracy: 0.7692\n",
      "Epoch 41/250\n",
      "2/2 - 0s - loss: 0.5161 - accuracy: 0.7627 - val_loss: 0.5368 - val_accuracy: 0.7692\n",
      "Epoch 42/250\n",
      "2/2 - 0s - loss: 0.4941 - accuracy: 0.7627 - val_loss: 0.5336 - val_accuracy: 0.7692\n",
      "Epoch 43/250\n",
      "2/2 - 0s - loss: 0.4971 - accuracy: 0.7627 - val_loss: 0.5307 - val_accuracy: 0.7692\n",
      "Epoch 44/250\n",
      "2/2 - 0s - loss: 0.4787 - accuracy: 0.7627 - val_loss: 0.5277 - val_accuracy: 0.7692\n",
      "Epoch 45/250\n",
      "2/2 - 0s - loss: 0.4839 - accuracy: 0.7627 - val_loss: 0.5248 - val_accuracy: 0.7692\n",
      "Epoch 46/250\n",
      "2/2 - 0s - loss: 0.4954 - accuracy: 0.7627 - val_loss: 0.5221 - val_accuracy: 0.7692\n",
      "Epoch 47/250\n",
      "2/2 - 0s - loss: 0.4953 - accuracy: 0.7627 - val_loss: 0.5195 - val_accuracy: 0.7692\n",
      "Epoch 48/250\n",
      "2/2 - 0s - loss: 0.4999 - accuracy: 0.7627 - val_loss: 0.5169 - val_accuracy: 0.7692\n",
      "Epoch 49/250\n",
      "2/2 - 0s - loss: 0.4886 - accuracy: 0.7627 - val_loss: 0.5144 - val_accuracy: 0.7692\n",
      "Epoch 50/250\n",
      "2/2 - 0s - loss: 0.4623 - accuracy: 0.7627 - val_loss: 0.5120 - val_accuracy: 0.7692\n",
      "Epoch 51/250\n",
      "2/2 - 0s - loss: 0.4485 - accuracy: 0.7627 - val_loss: 0.5097 - val_accuracy: 0.7692\n",
      "Epoch 52/250\n",
      "2/2 - 0s - loss: 0.5143 - accuracy: 0.7627 - val_loss: 0.5074 - val_accuracy: 0.7692\n",
      "Epoch 53/250\n",
      "2/2 - 0s - loss: 0.4647 - accuracy: 0.7627 - val_loss: 0.5051 - val_accuracy: 0.7692\n",
      "Epoch 54/250\n",
      "2/2 - 0s - loss: 0.4745 - accuracy: 0.7627 - val_loss: 0.5030 - val_accuracy: 0.7692\n",
      "Epoch 55/250\n",
      "2/2 - 0s - loss: 0.4898 - accuracy: 0.7627 - val_loss: 0.5011 - val_accuracy: 0.7692\n",
      "Epoch 56/250\n",
      "2/2 - 0s - loss: 0.4749 - accuracy: 0.7627 - val_loss: 0.4991 - val_accuracy: 0.7692\n",
      "Epoch 57/250\n",
      "2/2 - 0s - loss: 0.4101 - accuracy: 0.7627 - val_loss: 0.4970 - val_accuracy: 0.7692\n",
      "Epoch 58/250\n",
      "2/2 - 0s - loss: 0.4417 - accuracy: 0.7627 - val_loss: 0.4950 - val_accuracy: 0.7692\n",
      "Epoch 59/250\n",
      "2/2 - 0s - loss: 0.4536 - accuracy: 0.7627 - val_loss: 0.4930 - val_accuracy: 0.7692\n",
      "Epoch 60/250\n",
      "2/2 - 0s - loss: 0.4409 - accuracy: 0.7627 - val_loss: 0.4912 - val_accuracy: 0.7692\n",
      "Epoch 61/250\n",
      "2/2 - 0s - loss: 0.4189 - accuracy: 0.7627 - val_loss: 0.4893 - val_accuracy: 0.7692\n",
      "Epoch 62/250\n",
      "2/2 - 0s - loss: 0.3774 - accuracy: 0.7627 - val_loss: 0.4875 - val_accuracy: 0.7692\n",
      "Epoch 63/250\n",
      "2/2 - 0s - loss: 0.4642 - accuracy: 0.7627 - val_loss: 0.4856 - val_accuracy: 0.7692\n",
      "Epoch 64/250\n",
      "2/2 - 0s - loss: 0.4636 - accuracy: 0.7627 - val_loss: 0.4839 - val_accuracy: 0.7692\n",
      "Epoch 65/250\n",
      "2/2 - 0s - loss: 0.4680 - accuracy: 0.7627 - val_loss: 0.4822 - val_accuracy: 0.7692\n",
      "Epoch 66/250\n",
      "2/2 - 0s - loss: 0.4160 - accuracy: 0.7627 - val_loss: 0.4806 - val_accuracy: 0.7692\n",
      "Epoch 67/250\n",
      "2/2 - 0s - loss: 0.4003 - accuracy: 0.7627 - val_loss: 0.4790 - val_accuracy: 0.7692\n",
      "Epoch 68/250\n",
      "2/2 - 0s - loss: 0.4447 - accuracy: 0.7627 - val_loss: 0.4777 - val_accuracy: 0.7692\n",
      "Epoch 69/250\n",
      "2/2 - 0s - loss: 0.4266 - accuracy: 0.7627 - val_loss: 0.4765 - val_accuracy: 0.7692\n",
      "Epoch 70/250\n",
      "2/2 - 0s - loss: 0.4423 - accuracy: 0.7627 - val_loss: 0.4753 - val_accuracy: 0.7692\n",
      "Epoch 71/250\n",
      "2/2 - 0s - loss: 0.3833 - accuracy: 0.7627 - val_loss: 0.4743 - val_accuracy: 0.7692\n",
      "Epoch 72/250\n",
      "2/2 - 0s - loss: 0.4137 - accuracy: 0.7627 - val_loss: 0.4732 - val_accuracy: 0.7692\n",
      "Epoch 73/250\n",
      "2/2 - 0s - loss: 0.4027 - accuracy: 0.7627 - val_loss: 0.4721 - val_accuracy: 0.7692\n",
      "Epoch 74/250\n",
      "2/2 - 0s - loss: 0.4079 - accuracy: 0.7627 - val_loss: 0.4709 - val_accuracy: 0.7692\n",
      "Epoch 75/250\n",
      "2/2 - 0s - loss: 0.4400 - accuracy: 0.7627 - val_loss: 0.4698 - val_accuracy: 0.7692\n",
      "Epoch 76/250\n",
      "2/2 - 0s - loss: 0.4221 - accuracy: 0.7627 - val_loss: 0.4686 - val_accuracy: 0.7692\n",
      "Epoch 77/250\n",
      "2/2 - 0s - loss: 0.4417 - accuracy: 0.7627 - val_loss: 0.4677 - val_accuracy: 0.7692\n",
      "Epoch 78/250\n",
      "2/2 - 0s - loss: 0.4200 - accuracy: 0.7627 - val_loss: 0.4666 - val_accuracy: 0.7692\n",
      "Epoch 79/250\n",
      "2/2 - 0s - loss: 0.3808 - accuracy: 0.7627 - val_loss: 0.4655 - val_accuracy: 0.7692\n",
      "Epoch 80/250\n",
      "2/2 - 0s - loss: 0.3889 - accuracy: 0.7627 - val_loss: 0.4645 - val_accuracy: 0.7692\n",
      "Epoch 81/250\n",
      "2/2 - 0s - loss: 0.3564 - accuracy: 0.7627 - val_loss: 0.4635 - val_accuracy: 0.7692\n",
      "Epoch 82/250\n",
      "2/2 - 0s - loss: 0.3485 - accuracy: 0.7627 - val_loss: 0.4627 - val_accuracy: 0.7692\n",
      "Epoch 83/250\n",
      "2/2 - 0s - loss: 0.4279 - accuracy: 0.7627 - val_loss: 0.4618 - val_accuracy: 0.7692\n",
      "Epoch 84/250\n",
      "2/2 - 0s - loss: 0.3942 - accuracy: 0.7627 - val_loss: 0.4610 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/250\n",
      "2/2 - 0s - loss: 0.4022 - accuracy: 0.7627 - val_loss: 0.4602 - val_accuracy: 0.7692\n",
      "Epoch 86/250\n",
      "2/2 - 0s - loss: 0.3601 - accuracy: 0.7627 - val_loss: 0.4597 - val_accuracy: 0.7692\n",
      "Epoch 87/250\n",
      "2/2 - 0s - loss: 0.3570 - accuracy: 0.7627 - val_loss: 0.4595 - val_accuracy: 0.7692\n",
      "Epoch 88/250\n",
      "2/2 - 0s - loss: 0.4062 - accuracy: 0.7627 - val_loss: 0.4590 - val_accuracy: 0.7692\n",
      "Epoch 89/250\n",
      "2/2 - 0s - loss: 0.4097 - accuracy: 0.7627 - val_loss: 0.4587 - val_accuracy: 0.7692\n",
      "Epoch 90/250\n",
      "2/2 - 0s - loss: 0.4176 - accuracy: 0.7627 - val_loss: 0.4581 - val_accuracy: 0.7692\n",
      "Epoch 91/250\n",
      "2/2 - 0s - loss: 0.3643 - accuracy: 0.7627 - val_loss: 0.4574 - val_accuracy: 0.7692\n",
      "Epoch 92/250\n",
      "2/2 - 0s - loss: 0.3907 - accuracy: 0.7627 - val_loss: 0.4571 - val_accuracy: 0.7692\n",
      "Epoch 93/250\n",
      "2/2 - 0s - loss: 0.3803 - accuracy: 0.7627 - val_loss: 0.4567 - val_accuracy: 0.7692\n",
      "Epoch 94/250\n",
      "2/2 - 0s - loss: 0.3293 - accuracy: 0.7627 - val_loss: 0.4567 - val_accuracy: 0.7692\n",
      "Epoch 95/250\n",
      "2/2 - 0s - loss: 0.3684 - accuracy: 0.7627 - val_loss: 0.4568 - val_accuracy: 0.7692\n",
      "Epoch 96/250\n",
      "2/2 - 0s - loss: 0.3734 - accuracy: 0.7627 - val_loss: 0.4569 - val_accuracy: 0.7692\n",
      "Epoch 97/250\n",
      "2/2 - 0s - loss: 0.3040 - accuracy: 0.7627 - val_loss: 0.4569 - val_accuracy: 0.7692\n",
      "Epoch 98/250\n",
      "2/2 - 0s - loss: 0.3438 - accuracy: 0.7627 - val_loss: 0.4571 - val_accuracy: 0.7692\n",
      "Epoch 99/250\n",
      "2/2 - 0s - loss: 0.3220 - accuracy: 0.7627 - val_loss: 0.4571 - val_accuracy: 0.7692\n",
      "Epoch 100/250\n",
      "2/2 - 0s - loss: 0.3615 - accuracy: 0.7627 - val_loss: 0.4571 - val_accuracy: 0.7692\n",
      "Epoch 101/250\n",
      "2/2 - 0s - loss: 0.3230 - accuracy: 0.7627 - val_loss: 0.4572 - val_accuracy: 0.7692\n",
      "Epoch 102/250\n",
      "2/2 - 0s - loss: 0.3251 - accuracy: 0.7627 - val_loss: 0.4577 - val_accuracy: 0.7692\n",
      "Epoch 103/250\n",
      "2/2 - 0s - loss: 0.3419 - accuracy: 0.7627 - val_loss: 0.4585 - val_accuracy: 0.7692\n",
      "Epoch 104/250\n",
      "2/2 - 0s - loss: 0.3742 - accuracy: 0.7627 - val_loss: 0.4587 - val_accuracy: 0.7692\n",
      "Epoch 105/250\n",
      "2/2 - 0s - loss: 0.3050 - accuracy: 0.7627 - val_loss: 0.4592 - val_accuracy: 0.7692\n",
      "Epoch 106/250\n",
      "2/2 - 0s - loss: 0.3541 - accuracy: 0.7627 - val_loss: 0.4592 - val_accuracy: 0.7692\n",
      "Epoch 107/250\n",
      "2/2 - 0s - loss: 0.3146 - accuracy: 0.7627 - val_loss: 0.4589 - val_accuracy: 0.7692\n",
      "Epoch 108/250\n",
      "2/2 - 0s - loss: 0.3675 - accuracy: 0.7627 - val_loss: 0.4586 - val_accuracy: 0.7692\n",
      "Epoch 109/250\n",
      "2/2 - 0s - loss: 0.2970 - accuracy: 0.7627 - val_loss: 0.4586 - val_accuracy: 0.7692\n",
      "Epoch 110/250\n",
      "2/2 - 0s - loss: 0.3209 - accuracy: 0.7627 - val_loss: 0.4588 - val_accuracy: 0.7692\n",
      "Epoch 111/250\n",
      "2/2 - 0s - loss: 0.3196 - accuracy: 0.7627 - val_loss: 0.4592 - val_accuracy: 0.7692\n",
      "Epoch 112/250\n",
      "2/2 - 0s - loss: 0.3282 - accuracy: 0.7627 - val_loss: 0.4598 - val_accuracy: 0.7692\n",
      "Epoch 113/250\n",
      "2/2 - 0s - loss: 0.2989 - accuracy: 0.7627 - val_loss: 0.4604 - val_accuracy: 0.7692\n",
      "Epoch 114/250\n",
      "2/2 - 0s - loss: 0.3197 - accuracy: 0.7627 - val_loss: 0.4608 - val_accuracy: 0.7692\n",
      "Epoch 115/250\n",
      "2/2 - 0s - loss: 0.2921 - accuracy: 0.7627 - val_loss: 0.4613 - val_accuracy: 0.7692\n",
      "Epoch 116/250\n",
      "2/2 - 0s - loss: 0.3495 - accuracy: 0.7627 - val_loss: 0.4618 - val_accuracy: 0.7692\n",
      "Epoch 117/250\n",
      "2/2 - 0s - loss: 0.3121 - accuracy: 0.7627 - val_loss: 0.4628 - val_accuracy: 0.7692\n",
      "Epoch 118/250\n",
      "2/2 - 0s - loss: 0.3127 - accuracy: 0.7627 - val_loss: 0.4637 - val_accuracy: 0.7692\n",
      "Epoch 119/250\n",
      "2/2 - 0s - loss: 0.2812 - accuracy: 0.7627 - val_loss: 0.4654 - val_accuracy: 0.7692\n",
      "Epoch 120/250\n",
      "2/2 - 0s - loss: 0.3309 - accuracy: 0.7627 - val_loss: 0.4670 - val_accuracy: 0.7692\n",
      "Epoch 121/250\n",
      "2/2 - 0s - loss: 0.3022 - accuracy: 0.7627 - val_loss: 0.4688 - val_accuracy: 0.7692\n",
      "Epoch 122/250\n",
      "2/2 - 0s - loss: 0.2714 - accuracy: 0.7627 - val_loss: 0.4705 - val_accuracy: 0.7692\n",
      "Epoch 123/250\n",
      "2/2 - 0s - loss: 0.2909 - accuracy: 0.7627 - val_loss: 0.4727 - val_accuracy: 0.7692\n",
      "Epoch 124/250\n",
      "2/2 - 0s - loss: 0.2625 - accuracy: 0.7627 - val_loss: 0.4748 - val_accuracy: 0.7692\n",
      "Epoch 125/250\n",
      "2/2 - 0s - loss: 0.2811 - accuracy: 0.7627 - val_loss: 0.4767 - val_accuracy: 0.7692\n",
      "Epoch 126/250\n",
      "2/2 - 0s - loss: 0.2914 - accuracy: 0.7627 - val_loss: 0.4789 - val_accuracy: 0.7692\n",
      "Epoch 127/250\n",
      "2/2 - 0s - loss: 0.2832 - accuracy: 0.7627 - val_loss: 0.4804 - val_accuracy: 0.7692\n",
      "Epoch 128/250\n",
      "2/2 - 0s - loss: 0.3120 - accuracy: 0.7627 - val_loss: 0.4820 - val_accuracy: 0.7692\n",
      "Epoch 129/250\n",
      "2/2 - 0s - loss: 0.2850 - accuracy: 0.7627 - val_loss: 0.4838 - val_accuracy: 0.7692\n",
      "Epoch 130/250\n",
      "2/2 - 0s - loss: 0.2623 - accuracy: 0.7627 - val_loss: 0.4852 - val_accuracy: 0.7692\n",
      "Epoch 131/250\n",
      "2/2 - 0s - loss: 0.2677 - accuracy: 0.7627 - val_loss: 0.4871 - val_accuracy: 0.7692\n",
      "Epoch 132/250\n",
      "2/2 - 0s - loss: 0.2985 - accuracy: 0.7627 - val_loss: 0.4890 - val_accuracy: 0.7692\n",
      "Epoch 133/250\n",
      "2/2 - 0s - loss: 0.2545 - accuracy: 0.7627 - val_loss: 0.4913 - val_accuracy: 0.7692\n",
      "Epoch 134/250\n",
      "2/2 - 0s - loss: 0.3126 - accuracy: 0.7627 - val_loss: 0.4938 - val_accuracy: 0.7692\n",
      "Epoch 135/250\n",
      "2/2 - 0s - loss: 0.2879 - accuracy: 0.7627 - val_loss: 0.4958 - val_accuracy: 0.7692\n",
      "Epoch 136/250\n",
      "2/2 - 0s - loss: 0.2566 - accuracy: 0.7627 - val_loss: 0.4972 - val_accuracy: 0.7692\n",
      "Epoch 137/250\n",
      "2/2 - 0s - loss: 0.2463 - accuracy: 0.7627 - val_loss: 0.4990 - val_accuracy: 0.7692\n",
      "Epoch 138/250\n",
      "2/2 - 0s - loss: 0.2598 - accuracy: 0.7627 - val_loss: 0.5013 - val_accuracy: 0.7692\n",
      "Epoch 139/250\n",
      "2/2 - 0s - loss: 0.2403 - accuracy: 0.7627 - val_loss: 0.5041 - val_accuracy: 0.7692\n",
      "Epoch 140/250\n",
      "2/2 - 0s - loss: 0.3177 - accuracy: 0.7627 - val_loss: 0.5063 - val_accuracy: 0.7692\n",
      "Epoch 141/250\n",
      "2/2 - 0s - loss: 0.2503 - accuracy: 0.7627 - val_loss: 0.5093 - val_accuracy: 0.7692\n",
      "Epoch 142/250\n",
      "2/2 - 0s - loss: 0.2593 - accuracy: 0.7627 - val_loss: 0.5117 - val_accuracy: 0.7692\n",
      "Epoch 143/250\n",
      "2/2 - 0s - loss: 0.2600 - accuracy: 0.7627 - val_loss: 0.5140 - val_accuracy: 0.7692\n",
      "Epoch 144/250\n",
      "2/2 - 0s - loss: 0.2595 - accuracy: 0.7627 - val_loss: 0.5168 - val_accuracy: 0.7692\n",
      "Epoch 145/250\n",
      "2/2 - 0s - loss: 0.2804 - accuracy: 0.7627 - val_loss: 0.5201 - val_accuracy: 0.7692\n",
      "Epoch 146/250\n",
      "2/2 - 0s - loss: 0.2439 - accuracy: 0.7627 - val_loss: 0.5231 - val_accuracy: 0.7692\n",
      "Epoch 147/250\n",
      "2/2 - 0s - loss: 0.2374 - accuracy: 0.7627 - val_loss: 0.5260 - val_accuracy: 0.7692\n",
      "Epoch 148/250\n",
      "2/2 - 0s - loss: 0.2358 - accuracy: 0.7627 - val_loss: 0.5287 - val_accuracy: 0.7692\n",
      "Epoch 149/250\n",
      "2/2 - 0s - loss: 0.2363 - accuracy: 0.7627 - val_loss: 0.5312 - val_accuracy: 0.7692\n",
      "Epoch 150/250\n",
      "2/2 - 0s - loss: 0.2199 - accuracy: 0.7627 - val_loss: 0.5337 - val_accuracy: 0.7692\n",
      "Epoch 151/250\n",
      "2/2 - 0s - loss: 0.2437 - accuracy: 0.7627 - val_loss: 0.5363 - val_accuracy: 0.7692\n",
      "Epoch 152/250\n",
      "2/2 - 0s - loss: 0.2837 - accuracy: 0.7627 - val_loss: 0.5383 - val_accuracy: 0.7692\n",
      "Epoch 153/250\n",
      "2/2 - 0s - loss: 0.2254 - accuracy: 0.7627 - val_loss: 0.5407 - val_accuracy: 0.7692\n",
      "Epoch 154/250\n",
      "2/2 - 0s - loss: 0.2592 - accuracy: 0.7627 - val_loss: 0.5425 - val_accuracy: 0.7692\n",
      "Epoch 155/250\n",
      "2/2 - 0s - loss: 0.2566 - accuracy: 0.7627 - val_loss: 0.5449 - val_accuracy: 0.7692\n",
      "Epoch 156/250\n",
      "2/2 - 0s - loss: 0.2531 - accuracy: 0.7627 - val_loss: 0.5471 - val_accuracy: 0.7692\n",
      "Epoch 157/250\n",
      "2/2 - 0s - loss: 0.2606 - accuracy: 0.7627 - val_loss: 0.5489 - val_accuracy: 0.7692\n",
      "Epoch 158/250\n",
      "2/2 - 0s - loss: 0.2310 - accuracy: 0.7627 - val_loss: 0.5516 - val_accuracy: 0.7692\n",
      "Epoch 159/250\n",
      "2/2 - 0s - loss: 0.2731 - accuracy: 0.7627 - val_loss: 0.5550 - val_accuracy: 0.7692\n",
      "Epoch 160/250\n",
      "2/2 - 0s - loss: 0.2643 - accuracy: 0.7627 - val_loss: 0.5588 - val_accuracy: 0.7692\n",
      "Epoch 161/250\n",
      "2/2 - 0s - loss: 0.2246 - accuracy: 0.7627 - val_loss: 0.5620 - val_accuracy: 0.7692\n",
      "Epoch 162/250\n",
      "2/2 - 0s - loss: 0.2518 - accuracy: 0.7627 - val_loss: 0.5656 - val_accuracy: 0.7692\n",
      "Epoch 163/250\n",
      "2/2 - 0s - loss: 0.2505 - accuracy: 0.7627 - val_loss: 0.5688 - val_accuracy: 0.7692\n",
      "Epoch 164/250\n",
      "2/2 - 0s - loss: 0.2370 - accuracy: 0.7627 - val_loss: 0.5710 - val_accuracy: 0.7692\n",
      "Epoch 165/250\n",
      "2/2 - 0s - loss: 0.2559 - accuracy: 0.7627 - val_loss: 0.5733 - val_accuracy: 0.7692\n",
      "Epoch 166/250\n",
      "2/2 - 0s - loss: 0.2429 - accuracy: 0.7627 - val_loss: 0.5750 - val_accuracy: 0.7692\n",
      "Epoch 167/250\n",
      "2/2 - 0s - loss: 0.2585 - accuracy: 0.7627 - val_loss: 0.5778 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/250\n",
      "2/2 - 0s - loss: 0.2336 - accuracy: 0.7627 - val_loss: 0.5805 - val_accuracy: 0.7692\n",
      "Epoch 169/250\n",
      "2/2 - 0s - loss: 0.2260 - accuracy: 0.7627 - val_loss: 0.5827 - val_accuracy: 0.7692\n",
      "Epoch 170/250\n",
      "2/2 - 0s - loss: 0.2331 - accuracy: 0.7627 - val_loss: 0.5836 - val_accuracy: 0.7692\n",
      "Epoch 171/250\n",
      "2/2 - 0s - loss: 0.2033 - accuracy: 0.7627 - val_loss: 0.5852 - val_accuracy: 0.7692\n",
      "Epoch 172/250\n",
      "2/2 - 0s - loss: 0.2634 - accuracy: 0.7627 - val_loss: 0.5859 - val_accuracy: 0.7692\n",
      "Epoch 173/250\n",
      "2/2 - 0s - loss: 0.2458 - accuracy: 0.7627 - val_loss: 0.5876 - val_accuracy: 0.7692\n",
      "Epoch 174/250\n",
      "2/2 - 0s - loss: 0.2179 - accuracy: 0.7627 - val_loss: 0.5898 - val_accuracy: 0.7692\n",
      "Epoch 175/250\n",
      "2/2 - 0s - loss: 0.2229 - accuracy: 0.7627 - val_loss: 0.5927 - val_accuracy: 0.7692\n",
      "Epoch 176/250\n",
      "2/2 - 0s - loss: 0.2192 - accuracy: 0.7627 - val_loss: 0.5958 - val_accuracy: 0.7692\n",
      "Epoch 177/250\n",
      "2/2 - 0s - loss: 0.2756 - accuracy: 0.7627 - val_loss: 0.5990 - val_accuracy: 0.7692\n",
      "Epoch 178/250\n",
      "2/2 - 0s - loss: 0.2240 - accuracy: 0.7627 - val_loss: 0.6015 - val_accuracy: 0.7692\n",
      "Epoch 179/250\n",
      "2/2 - 0s - loss: 0.2480 - accuracy: 0.7627 - val_loss: 0.6038 - val_accuracy: 0.7692\n",
      "Epoch 180/250\n",
      "2/2 - 0s - loss: 0.2370 - accuracy: 0.8305 - val_loss: 0.6062 - val_accuracy: 0.7692\n",
      "Epoch 181/250\n",
      "2/2 - 0s - loss: 0.2154 - accuracy: 0.8814 - val_loss: 0.6083 - val_accuracy: 0.7692\n",
      "Epoch 182/250\n",
      "2/2 - 0s - loss: 0.1983 - accuracy: 0.8644 - val_loss: 0.6101 - val_accuracy: 0.7692\n",
      "Epoch 183/250\n",
      "2/2 - 0s - loss: 0.2467 - accuracy: 0.8983 - val_loss: 0.6121 - val_accuracy: 0.7692\n",
      "Epoch 184/250\n",
      "2/2 - 0s - loss: 0.2252 - accuracy: 0.8814 - val_loss: 0.6144 - val_accuracy: 0.7692\n",
      "Epoch 185/250\n",
      "2/2 - 0s - loss: 0.2190 - accuracy: 0.8814 - val_loss: 0.6162 - val_accuracy: 0.7692\n",
      "Epoch 186/250\n",
      "2/2 - 0s - loss: 0.2250 - accuracy: 0.8305 - val_loss: 0.6159 - val_accuracy: 0.7692\n",
      "Epoch 187/250\n",
      "2/2 - 0s - loss: 0.2050 - accuracy: 0.8814 - val_loss: 0.6154 - val_accuracy: 0.7692\n",
      "Epoch 188/250\n",
      "2/2 - 0s - loss: 0.2110 - accuracy: 0.8983 - val_loss: 0.6149 - val_accuracy: 0.7692\n",
      "Epoch 189/250\n",
      "2/2 - 0s - loss: 0.2112 - accuracy: 0.8814 - val_loss: 0.6147 - val_accuracy: 0.7692\n",
      "Epoch 190/250\n",
      "2/2 - 0s - loss: 0.2284 - accuracy: 0.9153 - val_loss: 0.6147 - val_accuracy: 0.7692\n",
      "Epoch 191/250\n",
      "2/2 - 0s - loss: 0.2109 - accuracy: 0.9492 - val_loss: 0.6159 - val_accuracy: 0.7692\n",
      "Epoch 192/250\n",
      "2/2 - 0s - loss: 0.2260 - accuracy: 0.9153 - val_loss: 0.6186 - val_accuracy: 0.7692\n",
      "Epoch 193/250\n",
      "2/2 - 0s - loss: 0.2022 - accuracy: 0.8814 - val_loss: 0.6215 - val_accuracy: 0.7692\n",
      "Epoch 194/250\n",
      "2/2 - 0s - loss: 0.1987 - accuracy: 0.9322 - val_loss: 0.6249 - val_accuracy: 0.7692\n",
      "Epoch 195/250\n",
      "2/2 - 0s - loss: 0.2402 - accuracy: 0.9153 - val_loss: 0.6291 - val_accuracy: 0.7692\n",
      "Epoch 196/250\n",
      "2/2 - 0s - loss: 0.2441 - accuracy: 0.8983 - val_loss: 0.6338 - val_accuracy: 0.7692\n",
      "Epoch 197/250\n",
      "2/2 - 0s - loss: 0.1814 - accuracy: 0.8814 - val_loss: 0.6380 - val_accuracy: 0.7692\n",
      "Epoch 198/250\n",
      "2/2 - 0s - loss: 0.2255 - accuracy: 0.9153 - val_loss: 0.6423 - val_accuracy: 0.7692\n",
      "Epoch 199/250\n",
      "2/2 - 0s - loss: 0.1920 - accuracy: 0.9492 - val_loss: 0.6464 - val_accuracy: 0.7692\n",
      "Epoch 200/250\n",
      "2/2 - 0s - loss: 0.1880 - accuracy: 0.9153 - val_loss: 0.6510 - val_accuracy: 0.7692\n",
      "Epoch 201/250\n",
      "2/2 - 0s - loss: 0.2181 - accuracy: 0.9322 - val_loss: 0.6564 - val_accuracy: 0.7692\n",
      "Epoch 202/250\n",
      "2/2 - 0s - loss: 0.2774 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 0.7692\n",
      "Epoch 203/250\n",
      "2/2 - 0s - loss: 0.2062 - accuracy: 0.9492 - val_loss: 0.6680 - val_accuracy: 0.7692\n",
      "Epoch 204/250\n",
      "2/2 - 0s - loss: 0.2197 - accuracy: 0.8983 - val_loss: 0.6717 - val_accuracy: 0.7692\n",
      "Epoch 205/250\n",
      "2/2 - 0s - loss: 0.2327 - accuracy: 0.9322 - val_loss: 0.6743 - val_accuracy: 0.7692\n",
      "Epoch 206/250\n",
      "2/2 - 0s - loss: 0.2233 - accuracy: 0.9153 - val_loss: 0.6772 - val_accuracy: 0.7692\n",
      "Epoch 207/250\n",
      "2/2 - 0s - loss: 0.2242 - accuracy: 0.9153 - val_loss: 0.6809 - val_accuracy: 0.7692\n",
      "Epoch 208/250\n",
      "2/2 - 0s - loss: 0.2037 - accuracy: 0.9153 - val_loss: 0.6838 - val_accuracy: 0.7692\n",
      "Epoch 209/250\n",
      "2/2 - 0s - loss: 0.2612 - accuracy: 0.8475 - val_loss: 0.6841 - val_accuracy: 0.7692\n",
      "Epoch 210/250\n",
      "2/2 - 0s - loss: 0.2607 - accuracy: 0.9322 - val_loss: 0.6832 - val_accuracy: 0.7692\n",
      "Epoch 211/250\n",
      "2/2 - 0s - loss: 0.2007 - accuracy: 0.8814 - val_loss: 0.6826 - val_accuracy: 0.7692\n",
      "Epoch 212/250\n",
      "2/2 - 0s - loss: 0.2491 - accuracy: 0.9153 - val_loss: 0.6835 - val_accuracy: 0.7692\n",
      "Epoch 213/250\n",
      "2/2 - 0s - loss: 0.1843 - accuracy: 0.9322 - val_loss: 0.6846 - val_accuracy: 0.7692\n",
      "Epoch 214/250\n",
      "2/2 - 0s - loss: 0.2000 - accuracy: 0.9492 - val_loss: 0.6864 - val_accuracy: 0.7692\n",
      "Epoch 215/250\n",
      "2/2 - 0s - loss: 0.1921 - accuracy: 0.9492 - val_loss: 0.6889 - val_accuracy: 0.7692\n",
      "Epoch 216/250\n",
      "2/2 - 0s - loss: 0.2418 - accuracy: 0.8983 - val_loss: 0.6921 - val_accuracy: 0.7692\n",
      "Epoch 217/250\n",
      "2/2 - 0s - loss: 0.2302 - accuracy: 0.8983 - val_loss: 0.6952 - val_accuracy: 0.7692\n",
      "Epoch 218/250\n",
      "2/2 - 0s - loss: 0.1897 - accuracy: 0.8983 - val_loss: 0.6983 - val_accuracy: 0.7692\n",
      "Epoch 219/250\n",
      "2/2 - 0s - loss: 0.2250 - accuracy: 0.8983 - val_loss: 0.7014 - val_accuracy: 0.7692\n",
      "Epoch 220/250\n",
      "2/2 - 0s - loss: 0.2097 - accuracy: 0.9322 - val_loss: 0.7036 - val_accuracy: 0.7692\n",
      "Epoch 221/250\n",
      "2/2 - 0s - loss: 0.2244 - accuracy: 0.9153 - val_loss: 0.7045 - val_accuracy: 0.7692\n",
      "Epoch 222/250\n",
      "2/2 - 0s - loss: 0.2313 - accuracy: 0.9153 - val_loss: 0.7060 - val_accuracy: 0.7692\n",
      "Epoch 223/250\n",
      "2/2 - 0s - loss: 0.2068 - accuracy: 0.8644 - val_loss: 0.7075 - val_accuracy: 0.7692\n",
      "Epoch 224/250\n",
      "2/2 - 0s - loss: 0.2189 - accuracy: 0.9322 - val_loss: 0.7097 - val_accuracy: 0.7692\n",
      "Epoch 225/250\n",
      "2/2 - 0s - loss: 0.2248 - accuracy: 0.8814 - val_loss: 0.7122 - val_accuracy: 0.7692\n",
      "Epoch 226/250\n",
      "2/2 - 0s - loss: 0.1820 - accuracy: 0.9492 - val_loss: 0.7149 - val_accuracy: 0.7692\n",
      "Epoch 227/250\n",
      "2/2 - 0s - loss: 0.2166 - accuracy: 0.9322 - val_loss: 0.7176 - val_accuracy: 0.7692\n",
      "Epoch 228/250\n",
      "2/2 - 0s - loss: 0.2178 - accuracy: 0.9492 - val_loss: 0.7213 - val_accuracy: 0.7692\n",
      "Epoch 229/250\n",
      "2/2 - 0s - loss: 0.1856 - accuracy: 0.9492 - val_loss: 0.7253 - val_accuracy: 0.7692\n",
      "Epoch 230/250\n",
      "2/2 - 0s - loss: 0.2051 - accuracy: 0.9322 - val_loss: 0.7293 - val_accuracy: 0.7692\n",
      "Epoch 231/250\n",
      "2/2 - 0s - loss: 0.2070 - accuracy: 0.9322 - val_loss: 0.7320 - val_accuracy: 0.7692\n",
      "Epoch 232/250\n",
      "2/2 - 0s - loss: 0.2339 - accuracy: 0.8814 - val_loss: 0.7348 - val_accuracy: 0.7692\n",
      "Epoch 233/250\n",
      "2/2 - 0s - loss: 0.1710 - accuracy: 1.0000 - val_loss: 0.7379 - val_accuracy: 0.7692\n",
      "Epoch 234/250\n",
      "2/2 - 0s - loss: 0.1784 - accuracy: 0.9492 - val_loss: 0.7414 - val_accuracy: 0.7692\n",
      "Epoch 235/250\n",
      "2/2 - 0s - loss: 0.2108 - accuracy: 0.9322 - val_loss: 0.7450 - val_accuracy: 0.7692\n",
      "Epoch 236/250\n",
      "2/2 - 0s - loss: 0.1910 - accuracy: 0.9322 - val_loss: 0.7483 - val_accuracy: 0.7692\n",
      "Epoch 237/250\n",
      "2/2 - 0s - loss: 0.2271 - accuracy: 0.9153 - val_loss: 0.7513 - val_accuracy: 0.7692\n",
      "Epoch 238/250\n",
      "2/2 - 0s - loss: 0.1913 - accuracy: 0.9492 - val_loss: 0.7546 - val_accuracy: 0.7692\n",
      "Epoch 239/250\n",
      "2/2 - 0s - loss: 0.1793 - accuracy: 0.9661 - val_loss: 0.7579 - val_accuracy: 0.7692\n",
      "Epoch 240/250\n",
      "2/2 - 0s - loss: 0.1765 - accuracy: 0.9831 - val_loss: 0.7611 - val_accuracy: 0.7692\n",
      "Epoch 241/250\n",
      "2/2 - 0s - loss: 0.2045 - accuracy: 0.9492 - val_loss: 0.7630 - val_accuracy: 0.7692\n",
      "Epoch 242/250\n",
      "2/2 - 0s - loss: 0.1961 - accuracy: 0.9831 - val_loss: 0.7650 - val_accuracy: 0.7692\n",
      "Epoch 243/250\n",
      "2/2 - 0s - loss: 0.1898 - accuracy: 0.9322 - val_loss: 0.7671 - val_accuracy: 0.7692\n",
      "Epoch 244/250\n",
      "2/2 - 0s - loss: 0.2187 - accuracy: 0.9322 - val_loss: 0.7694 - val_accuracy: 0.7692\n",
      "Epoch 245/250\n",
      "2/2 - 0s - loss: 0.1931 - accuracy: 0.9322 - val_loss: 0.7702 - val_accuracy: 0.7692\n",
      "Epoch 246/250\n",
      "2/2 - 0s - loss: 0.2165 - accuracy: 0.9153 - val_loss: 0.7692 - val_accuracy: 0.7692\n",
      "Epoch 247/250\n",
      "2/2 - 0s - loss: 0.2030 - accuracy: 0.9492 - val_loss: 0.7688 - val_accuracy: 0.7692\n",
      "Epoch 248/250\n",
      "2/2 - 0s - loss: 0.1930 - accuracy: 0.9492 - val_loss: 0.7689 - val_accuracy: 0.7692\n",
      "Epoch 249/250\n",
      "2/2 - 0s - loss: 0.1783 - accuracy: 0.9492 - val_loss: 0.7694 - val_accuracy: 0.7692\n",
      "Epoch 250/250\n",
      "2/2 - 0s - loss: 0.1943 - accuracy: 0.9492 - val_loss: 0.7706 - val_accuracy: 0.7692\n"
     ]
    }
   ],
   "source": [
    "mlp_farewell = mlp_farewell(shape)\n",
    "history = mlp_farewell.fit(X_train, np.asarray(y_train[\"Search\"]).reshape(-1,1),\n",
    "                  validation_data=(X_validation, np.asarray(y_validation[\"Search\"]).reshape(-1,1)),\n",
    "    epochs=250,\n",
    "    workers = 2, use_multiprocessing= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_greeting.save('model_greetings.h5')\n",
    "# mlp_search.save('model_search.h5')\n",
    "# mlp_suggestion.save('model_suggestion.h5')\n",
    "# mlp_farewell.save('model_farewell.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHATBOT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_greeting = keras.models.load_model('model_greetings.h5')\n",
    "mlp_search = keras.models.load_model('model_search.h5')\n",
    "mlp_suggestion = keras.models.load_model('model_suggestion.h5')\n",
    "mlp_farewell = keras.models.load_model('model_farewell.h5')\n",
    "# cv = joblib.load(\"vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    \n",
    "    input_text = input()\n",
    "    \n",
    "    test = pd.DataFrame(data = {'Sentence': [input_text]})\n",
    "    df_test_proc, test_proc = processing(test, cv = cv)\n",
    "    scipy.sparse.csr_matrix.sort_indices(test_proc)\n",
    "    \n",
    "    gret_prob = mlp_greeting.predict(test_proc)\n",
    "    search_prob = mlp_search.predict(test_proc)\n",
    "    sugg_prob = mlp_suggestion.predict(test_proc)\n",
    "    farewell_prob = mlp_farewell.predict(test_proc)\n",
    "    \n",
    "    probs = [gret_prob, search_prob, sugg_prob, farewell_prob]\n",
    "    print(probs)\n",
    "    idx = np.argmax(probs)\n",
    "    \n",
    "    if idx == 0:\n",
    "        print(\"Esto es un saludo\")\n",
    "    elif idx == 1:\n",
    "        print(\"Esto es una búsqueda\")\n",
    "    elif idx == 2:\n",
    "        print(\"Esto es una sugerencia\")\n",
    "    else:\n",
    "        print(\"Esto es una despedida\")\n",
    "        \n",
    "#     print('¿Hemos acertado?')\n",
    "    \n",
    "#     respuesta = input()\n",
    "#     if (respuesta == 'No' or respuesta == 'no'):\n",
    "#         probs = np.delete(probs, idx)\n",
    "#         idx_2 = np.argmax(probs)\n",
    "        \n",
    "#         if idx == 0:\n",
    "#             if idx_2 == 0:\n",
    "#                 print(\"Esto es una búsqueda\")\n",
    "#             else:\n",
    "#                 print(\"Esto es una sugerencia\")\n",
    "#         elif idx == 1:\n",
    "#             if idx_2 == 0:\n",
    "#                 print(\"Esto es un saludo\")\n",
    "#             else:\n",
    "#                 print(\"Esto es una sugerencia\")\n",
    "#         else:\n",
    "#             if idx_2 == 0:\n",
    "#                 print(\"Esto es un saludo\")\n",
    "#             else:\n",
    "#                 print(\"Esto es una búsqueda\")\n",
    "#     else:\n",
    "#         print('¡Genial! ¡Hemos acertado!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "[array([[0.8040894]], dtype=float32), array([[0.00038779]], dtype=float32), array([[3.612887e-05]], dtype=float32), array([[0.00043699]], dtype=float32)]\n",
      "Esto es un saludo\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "[array([[0.7962549]], dtype=float32), array([[0.01487446]], dtype=float32), array([[0.0009267]], dtype=float32), array([[4.4460567e-06]], dtype=float32)]\n",
      "Esto es un saludo\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Correctamente\n",
    " * La mayoría de saludos\n",
    " * I want to know about Data Science (búsqueda)\n",
    " * I want to know things connected to la Sagrada Familia (sugerencia)\n",
    " * Watcha doing'? (saludo)\n",
    " * Tell me things related to Data Science (sugerencia)\n",
    "\n",
    "* Incorrectamente\n",
    " * What is Data Science (sugerencia)\n",
    " * Tell me things related to Napoleon (saludo)\n",
    " * Who is Cristobal Colon (saludo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Opciones\n",
    " * Mostrar un comando *!options* que te de las opciones para hacer.\n",
    " * Detectar un intent\n",
    " * Mostrarlo al inicio\n",
    "\n",
    "\n",
    "* Headers\n",
    " * Dar las opciones una vez se detecta intent de búsqueda búsqueda\n",
    "   * *What is data science?* Y mostrarle los heades para qué elija qué queire saber \n",
    " * Intent nuevo de header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Intent_detection_function(keyboard):\n",
    "    gret_prob = mlp_greeting.predict_proba(test_proc)\n",
    "    search_prob = mlp_search.predict_proba(test_proc)\n",
    "    sugg_prob = mlp_suggestion.predict_proba(test_proc)\n",
    "    farewell_prob = mlp_farewell.predict_proba(test_proc)\n",
    "    cv = joblib.load(\"vectorizer.pkl\")\n",
    "\n",
    "\n",
    "    input_text = pd.DataFrame(data={'Sentence': [keyboard]})\n",
    "    _, test_proc = cv.transform(input_text['Sentence'])\n",
    "    #df_test_proc, test_proc = processing(test, cv=cv)\n",
    "\n",
    "    test_proc = test_proc.toarray()\n",
    "\n",
    "    gret_prob = mlp_greeting.predict(test_proc)\n",
    "\n",
    "    search_prob = mlp_search.predict(test_proc)\n",
    "    sugg_prob = mlp_suggestion.predict(test_proc)\n",
    "    fare_prob = mlp_farewell.predict(test_proc)\n",
    "\n",
    "\n",
    "    probs = [gret_prob, search_prob, sugg_prob, fare_prob]\n",
    "    print(probs)\n",
    "    idx = np.argmax(probs)\n",
    "\n",
    "    if idx == 0:\n",
    "        intent = \"Greeting\"\n",
    "        keyword = None\n",
    "    elif idx == 1:\n",
    "        intent = \"Search\"\n",
    "        keyword = getEntities(keyboard)\n",
    "    elif idx == 2:\n",
    "        intent = \"Suggestions\"\n",
    "        keyword = getEntities(keyboard)\n",
    "    elif idx == 3:\n",
    "        intent = \"Farewell\"\n",
    "        keyword = None\n",
    "\n",
    "    return intent, keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Intent_detection_function()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
