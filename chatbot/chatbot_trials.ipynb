{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent type</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hi!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>How are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Hi, how is it going?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greeting</td>\n",
       "      <td>Greetings!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Intent type              Sentence\n",
       "0    Greeting                   Hi!\n",
       "1    Greeting                 Hello\n",
       "2    Greeting          How are you?\n",
       "3    Greeting  Hi, how is it going?\n",
       "4    Greeting            Greetings!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r\"training_chatbot.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar get_dummies en vez de las 3 funciones\n",
    "df_oh = pd.concat([df, pd.get_dummies(df['Intent type'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_oh, train_size = 0.7, test_size = 0.3, random_state = 42,\n",
    "                                    shuffle = True, stratify = df_oh['Intent type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(df, pretreatment = False, Tfidf = True, cv = None, stopwords = []):\n",
    "  # Normalizamos y limpiamos el corpus \n",
    "  if pretreatment == True:\n",
    "    df[\"Sentence\"] = df['Sentence'].apply(lambda x: word_treatment(x))\n",
    "    print(\"El corpus ha sido pretratado\")\n",
    "    \n",
    "     # Transformamos nuestro corpus a un vector Tfidf\n",
    "  if Tfidf == True:\n",
    "\n",
    "    if cv == None:\n",
    "      cv = TfidfVectorizer(\n",
    "        stop_words= stopwords,\n",
    "        ngram_range=(1, 4),\n",
    "        strip_accents='ascii',\n",
    "        max_df=0.99,\n",
    "        min_df=0,\n",
    "        max_features=100\n",
    "      )\n",
    "      cv.fit(df[\"Sentence\"])\n",
    "      X = cv.transform(df[\"Sentence\"])\n",
    "      print(\"Se ha realizado una vectorizaci贸n Tfidf\")\n",
    "      return df, X, cv\n",
    "\n",
    "    else:\n",
    "      X = cv.transform(df[\"Sentence\"])\n",
    "      #print(\"Se ha realizado una vectorizaci贸n Tfidf basado en el corpus suministrado por cv\")\n",
    "    return df, X\n",
    "  else:\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha realizado una vectorizaci贸n Tfidf\n",
      "Se ha realizado una vectorizaci贸n Tfidf basado en el corpus suministrado por cv\n"
     ]
    }
   ],
   "source": [
    "df_train, X_train, cv = processing(df_train)\n",
    "df_test, X_test = processing(df_test, cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[[\"Greeting\",\"Search\",\"Suggestions\"]]\n",
    "y_test = df_test[[\"Greeting\",\"Search\",\"Suggestions\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, train_size=0.7, \n",
    "test_size=0.3, random_state=42, shuffle=True, stratify=df_train[\"Intent type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape= X_train.shape[1]\n",
    "\n",
    "X_train.sort_indices()\n",
    "X_validation.sort_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_greeting(shape):\n",
    "# define our MLP network\n",
    "    initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=42)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=shape, kernel_initializer = initializer, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2, activation=\"relu\"))\n",
    "# check to see if the regression node should be added\n",
    "    #if regress:\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "    #Compile model\n",
    "    opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss='binary_crossentropy', metrics = [\"accuracy\"], optimizer=opt)\n",
    "# return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53 samples, validate on 23 samples\n",
      "Epoch 1/200\n",
      " - 4s - loss: 0.6572 - acc: 0.6604 - val_loss: 0.6767 - val_acc: 0.7391\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6515 - acc: 0.6415 - val_loss: 0.6746 - val_acc: 0.7391\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6707 - acc: 0.5660 - val_loss: 0.6724 - val_acc: 0.7391\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6658 - acc: 0.6604 - val_loss: 0.6699 - val_acc: 0.7391\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6344 - acc: 0.6981 - val_loss: 0.6673 - val_acc: 0.7391\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6466 - acc: 0.5849 - val_loss: 0.6648 - val_acc: 0.7391\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6649 - acc: 0.6415 - val_loss: 0.6622 - val_acc: 0.7391\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6417 - acc: 0.7170 - val_loss: 0.6596 - val_acc: 0.7391\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6254 - acc: 0.6792 - val_loss: 0.6570 - val_acc: 0.7391\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6258 - acc: 0.6981 - val_loss: 0.6544 - val_acc: 0.7391\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6323 - acc: 0.6604 - val_loss: 0.6518 - val_acc: 0.7391\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6367 - acc: 0.6981 - val_loss: 0.6490 - val_acc: 0.7391\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6472 - acc: 0.6604 - val_loss: 0.6464 - val_acc: 0.7391\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6364 - acc: 0.7358 - val_loss: 0.6438 - val_acc: 0.7391\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6521 - acc: 0.6981 - val_loss: 0.6414 - val_acc: 0.7391\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6259 - acc: 0.6981 - val_loss: 0.6393 - val_acc: 0.7391\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6051 - acc: 0.7547 - val_loss: 0.6368 - val_acc: 0.7391\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6208 - acc: 0.6792 - val_loss: 0.6342 - val_acc: 0.7391\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6000 - acc: 0.7170 - val_loss: 0.6315 - val_acc: 0.7391\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6104 - acc: 0.6981 - val_loss: 0.6286 - val_acc: 0.7391\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.5982 - acc: 0.7170 - val_loss: 0.6256 - val_acc: 0.7391\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6402 - acc: 0.6981 - val_loss: 0.6229 - val_acc: 0.7391\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.5763 - acc: 0.7170 - val_loss: 0.6200 - val_acc: 0.7391\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6067 - acc: 0.7170 - val_loss: 0.6172 - val_acc: 0.7391\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6160 - acc: 0.6792 - val_loss: 0.6146 - val_acc: 0.7391\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.5687 - acc: 0.7170 - val_loss: 0.6120 - val_acc: 0.7391\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.5816 - acc: 0.6981 - val_loss: 0.6092 - val_acc: 0.7391\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.5689 - acc: 0.7170 - val_loss: 0.6064 - val_acc: 0.7391\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.5741 - acc: 0.6981 - val_loss: 0.6037 - val_acc: 0.7391\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.5727 - acc: 0.7358 - val_loss: 0.6009 - val_acc: 0.7391\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.5642 - acc: 0.7170 - val_loss: 0.5983 - val_acc: 0.7391\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.5587 - acc: 0.7170 - val_loss: 0.5958 - val_acc: 0.7391\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.6047 - acc: 0.6981 - val_loss: 0.5934 - val_acc: 0.7391\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.5720 - acc: 0.6792 - val_loss: 0.5911 - val_acc: 0.7391\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.5740 - acc: 0.6792 - val_loss: 0.5889 - val_acc: 0.7391\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.5559 - acc: 0.7358 - val_loss: 0.5867 - val_acc: 0.7391\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.5618 - acc: 0.7358 - val_loss: 0.5845 - val_acc: 0.7391\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.5670 - acc: 0.7170 - val_loss: 0.5822 - val_acc: 0.7391\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.5665 - acc: 0.7358 - val_loss: 0.5801 - val_acc: 0.7391\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.5667 - acc: 0.7170 - val_loss: 0.5777 - val_acc: 0.7391\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.5315 - acc: 0.6981 - val_loss: 0.5752 - val_acc: 0.7391\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.5643 - acc: 0.7170 - val_loss: 0.5731 - val_acc: 0.7391\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.5579 - acc: 0.7358 - val_loss: 0.5712 - val_acc: 0.7391\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.5545 - acc: 0.7170 - val_loss: 0.5692 - val_acc: 0.7391\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.5265 - acc: 0.7170 - val_loss: 0.5673 - val_acc: 0.7391\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.5300 - acc: 0.7358 - val_loss: 0.5652 - val_acc: 0.7391\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.5770 - acc: 0.7170 - val_loss: 0.5633 - val_acc: 0.7391\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.5092 - acc: 0.7170 - val_loss: 0.5616 - val_acc: 0.7391\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.5096 - acc: 0.6981 - val_loss: 0.5597 - val_acc: 0.7391\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.5089 - acc: 0.7170 - val_loss: 0.5576 - val_acc: 0.7391\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.5368 - acc: 0.7358 - val_loss: 0.5555 - val_acc: 0.7391\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.5032 - acc: 0.7170 - val_loss: 0.5535 - val_acc: 0.7391\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.5131 - acc: 0.7170 - val_loss: 0.5515 - val_acc: 0.7391\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.5178 - acc: 0.7170 - val_loss: 0.5494 - val_acc: 0.7391\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.4797 - acc: 0.7358 - val_loss: 0.5472 - val_acc: 0.7391\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.5765 - acc: 0.7358 - val_loss: 0.5451 - val_acc: 0.7391\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.4877 - acc: 0.7170 - val_loss: 0.5429 - val_acc: 0.7391\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.4744 - acc: 0.7170 - val_loss: 0.5404 - val_acc: 0.7391\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.4994 - acc: 0.7170 - val_loss: 0.5379 - val_acc: 0.7391\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.5451 - acc: 0.7170 - val_loss: 0.5356 - val_acc: 0.7391\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.5064 - acc: 0.7358 - val_loss: 0.5336 - val_acc: 0.7391\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.5012 - acc: 0.7358 - val_loss: 0.5319 - val_acc: 0.7391\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.5135 - acc: 0.7170 - val_loss: 0.5303 - val_acc: 0.7391\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.5304 - acc: 0.7358 - val_loss: 0.5286 - val_acc: 0.7391\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.4504 - acc: 0.7170 - val_loss: 0.5269 - val_acc: 0.7391\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.4672 - acc: 0.7358 - val_loss: 0.5253 - val_acc: 0.7391\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.4623 - acc: 0.7358 - val_loss: 0.5238 - val_acc: 0.7391\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.4995 - acc: 0.7547 - val_loss: 0.5223 - val_acc: 0.7391\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.5124 - acc: 0.6981 - val_loss: 0.5210 - val_acc: 0.7391\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.5217 - acc: 0.7170 - val_loss: 0.5197 - val_acc: 0.7391\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.5047 - acc: 0.6981 - val_loss: 0.5186 - val_acc: 0.7391\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.4675 - acc: 0.7170 - val_loss: 0.5174 - val_acc: 0.7391\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.5171 - acc: 0.7170 - val_loss: 0.5162 - val_acc: 0.7391\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.4713 - acc: 0.7170 - val_loss: 0.5149 - val_acc: 0.7391\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.4940 - acc: 0.7358 - val_loss: 0.5137 - val_acc: 0.7391\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.5338 - acc: 0.7358 - val_loss: 0.5125 - val_acc: 0.7391\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.5332 - acc: 0.7358 - val_loss: 0.5114 - val_acc: 0.7391\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.4844 - acc: 0.7170 - val_loss: 0.5104 - val_acc: 0.7391\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.4731 - acc: 0.7358 - val_loss: 0.5093 - val_acc: 0.7391\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.4563 - acc: 0.7547 - val_loss: 0.5082 - val_acc: 0.7391\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.5070 - acc: 0.7547 - val_loss: 0.5072 - val_acc: 0.7391\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.5095 - acc: 0.7547 - val_loss: 0.5062 - val_acc: 0.7391\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.4866 - acc: 0.7358 - val_loss: 0.5052 - val_acc: 0.7391\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.4885 - acc: 0.7358 - val_loss: 0.5041 - val_acc: 0.7391\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.4612 - acc: 0.7358 - val_loss: 0.5030 - val_acc: 0.7391\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.4334 - acc: 0.7547 - val_loss: 0.5018 - val_acc: 0.7391\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.5019 - acc: 0.7170 - val_loss: 0.5006 - val_acc: 0.7391\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.4389 - acc: 0.7736 - val_loss: 0.4993 - val_acc: 0.7391\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.4941 - acc: 0.7358 - val_loss: 0.4979 - val_acc: 0.7391\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.4075 - acc: 0.7358 - val_loss: 0.4966 - val_acc: 0.7391\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.5025 - acc: 0.7170 - val_loss: 0.4953 - val_acc: 0.7391\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.4656 - acc: 0.7736 - val_loss: 0.4940 - val_acc: 0.7391\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.4806 - acc: 0.7358 - val_loss: 0.4928 - val_acc: 0.7391\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.4394 - acc: 0.7358 - val_loss: 0.4915 - val_acc: 0.7391\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.4747 - acc: 0.7170 - val_loss: 0.4900 - val_acc: 0.7391\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.4603 - acc: 0.7736 - val_loss: 0.4885 - val_acc: 0.7391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      " - 0s - loss: 0.4387 - acc: 0.7547 - val_loss: 0.4868 - val_acc: 0.7391\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.4723 - acc: 0.7736 - val_loss: 0.4852 - val_acc: 0.7391\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.4875 - acc: 0.7547 - val_loss: 0.4836 - val_acc: 0.7391\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.3975 - acc: 0.8113 - val_loss: 0.4822 - val_acc: 0.7391\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.4233 - acc: 0.7736 - val_loss: 0.4807 - val_acc: 0.7391\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.4264 - acc: 0.7736 - val_loss: 0.4791 - val_acc: 0.7391\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.4355 - acc: 0.7925 - val_loss: 0.4775 - val_acc: 0.7391\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.4245 - acc: 0.7736 - val_loss: 0.4758 - val_acc: 0.7391\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.4133 - acc: 0.7547 - val_loss: 0.4744 - val_acc: 0.7391\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.4320 - acc: 0.7358 - val_loss: 0.4730 - val_acc: 0.7391\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.4757 - acc: 0.7358 - val_loss: 0.4715 - val_acc: 0.7391\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.4148 - acc: 0.7170 - val_loss: 0.4702 - val_acc: 0.7391\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.4120 - acc: 0.7925 - val_loss: 0.4689 - val_acc: 0.7391\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.4440 - acc: 0.7547 - val_loss: 0.4676 - val_acc: 0.7391\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.4381 - acc: 0.7170 - val_loss: 0.4661 - val_acc: 0.7391\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.4243 - acc: 0.8113 - val_loss: 0.4646 - val_acc: 0.7391\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.4055 - acc: 0.8113 - val_loss: 0.4631 - val_acc: 0.7391\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.4156 - acc: 0.7358 - val_loss: 0.4617 - val_acc: 0.7391\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.3954 - acc: 0.7925 - val_loss: 0.4603 - val_acc: 0.7391\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.4344 - acc: 0.8302 - val_loss: 0.4591 - val_acc: 0.7391\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.4261 - acc: 0.7736 - val_loss: 0.4578 - val_acc: 0.7391\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.3461 - acc: 0.8302 - val_loss: 0.4565 - val_acc: 0.7391\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.4683 - acc: 0.8302 - val_loss: 0.4553 - val_acc: 0.7391\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.3933 - acc: 0.8302 - val_loss: 0.4539 - val_acc: 0.7391\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.3784 - acc: 0.7925 - val_loss: 0.4525 - val_acc: 0.7391\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.3905 - acc: 0.8679 - val_loss: 0.4510 - val_acc: 0.7391\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.4207 - acc: 0.8113 - val_loss: 0.4494 - val_acc: 0.7391\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.3961 - acc: 0.7358 - val_loss: 0.4477 - val_acc: 0.7391\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.3865 - acc: 0.7925 - val_loss: 0.4461 - val_acc: 0.7391\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.4148 - acc: 0.7925 - val_loss: 0.4446 - val_acc: 0.7391\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.3490 - acc: 0.8679 - val_loss: 0.4432 - val_acc: 0.7391\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.3285 - acc: 0.8679 - val_loss: 0.4418 - val_acc: 0.7391\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.3718 - acc: 0.8679 - val_loss: 0.4401 - val_acc: 0.7391\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.3945 - acc: 0.8113 - val_loss: 0.4385 - val_acc: 0.7826\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.3645 - acc: 0.8113 - val_loss: 0.4369 - val_acc: 0.7826\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.3784 - acc: 0.7358 - val_loss: 0.4352 - val_acc: 0.7826\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.4317 - acc: 0.7547 - val_loss: 0.4336 - val_acc: 0.7826\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.3660 - acc: 0.7925 - val_loss: 0.4321 - val_acc: 0.7826\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.3806 - acc: 0.8113 - val_loss: 0.4307 - val_acc: 0.7826\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.3775 - acc: 0.8679 - val_loss: 0.4293 - val_acc: 0.7826\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.3997 - acc: 0.7547 - val_loss: 0.4279 - val_acc: 0.7826\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.3765 - acc: 0.7358 - val_loss: 0.4265 - val_acc: 0.7826\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.3737 - acc: 0.7925 - val_loss: 0.4253 - val_acc: 0.7826\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.3149 - acc: 0.8491 - val_loss: 0.4241 - val_acc: 0.7826\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.3322 - acc: 0.8491 - val_loss: 0.4229 - val_acc: 0.7826\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.3358 - acc: 0.8113 - val_loss: 0.4215 - val_acc: 0.7826\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.3490 - acc: 0.8491 - val_loss: 0.4201 - val_acc: 0.7826\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.3650 - acc: 0.8302 - val_loss: 0.4190 - val_acc: 0.7826\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.3379 - acc: 0.8868 - val_loss: 0.4180 - val_acc: 0.8261\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.3373 - acc: 0.8679 - val_loss: 0.4173 - val_acc: 0.8261\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.3186 - acc: 0.8868 - val_loss: 0.4167 - val_acc: 0.8261\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.3529 - acc: 0.8868 - val_loss: 0.4162 - val_acc: 0.8261\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.3291 - acc: 0.8113 - val_loss: 0.4156 - val_acc: 0.8261\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.3391 - acc: 0.8113 - val_loss: 0.4152 - val_acc: 0.8261\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.2782 - acc: 0.8491 - val_loss: 0.4150 - val_acc: 0.8261\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.3008 - acc: 0.8868 - val_loss: 0.4148 - val_acc: 0.8261\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.3211 - acc: 0.7358 - val_loss: 0.4139 - val_acc: 0.8261\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.2812 - acc: 0.8868 - val_loss: 0.4131 - val_acc: 0.8261\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.2937 - acc: 0.8679 - val_loss: 0.4125 - val_acc: 0.8261\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.3566 - acc: 0.7925 - val_loss: 0.4118 - val_acc: 0.8261\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.3183 - acc: 0.8113 - val_loss: 0.4110 - val_acc: 0.8261\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.3290 - acc: 0.8868 - val_loss: 0.4107 - val_acc: 0.8261\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.3257 - acc: 0.7925 - val_loss: 0.4106 - val_acc: 0.8261\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.3047 - acc: 0.8491 - val_loss: 0.4102 - val_acc: 0.8261\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.3101 - acc: 0.8679 - val_loss: 0.4095 - val_acc: 0.8261\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.2847 - acc: 0.8868 - val_loss: 0.4087 - val_acc: 0.8261\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.2833 - acc: 0.8679 - val_loss: 0.4080 - val_acc: 0.8261\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.3652 - acc: 0.7925 - val_loss: 0.4073 - val_acc: 0.8261\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.3469 - acc: 0.7925 - val_loss: 0.4069 - val_acc: 0.8261\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.3540 - acc: 0.8302 - val_loss: 0.4068 - val_acc: 0.8261\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.3145 - acc: 0.8679 - val_loss: 0.4067 - val_acc: 0.8261\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.2823 - acc: 0.8679 - val_loss: 0.4068 - val_acc: 0.8261\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.3322 - acc: 0.7547 - val_loss: 0.4068 - val_acc: 0.8261\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.2971 - acc: 0.8302 - val_loss: 0.4069 - val_acc: 0.8261\n",
      "Epoch 171/200\n",
      " - 0s - loss: 0.3067 - acc: 0.8491 - val_loss: 0.4072 - val_acc: 0.8261\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.2922 - acc: 0.8868 - val_loss: 0.4075 - val_acc: 0.8261\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.2496 - acc: 0.9434 - val_loss: 0.4075 - val_acc: 0.8261\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.3171 - acc: 0.8491 - val_loss: 0.4073 - val_acc: 0.8261\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.2260 - acc: 0.9434 - val_loss: 0.4073 - val_acc: 0.8261\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.2458 - acc: 0.8679 - val_loss: 0.4074 - val_acc: 0.8261\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.2605 - acc: 0.8491 - val_loss: 0.4075 - val_acc: 0.8261\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.2333 - acc: 0.9057 - val_loss: 0.4076 - val_acc: 0.8261\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.2464 - acc: 0.8868 - val_loss: 0.4076 - val_acc: 0.8261\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.2630 - acc: 0.7925 - val_loss: 0.4075 - val_acc: 0.8261\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.2492 - acc: 0.8302 - val_loss: 0.4074 - val_acc: 0.8261\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.2679 - acc: 0.8302 - val_loss: 0.4076 - val_acc: 0.8261\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.2618 - acc: 0.8113 - val_loss: 0.4078 - val_acc: 0.8261\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.2816 - acc: 0.8679 - val_loss: 0.4080 - val_acc: 0.8261\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.2451 - acc: 0.8491 - val_loss: 0.4085 - val_acc: 0.8261\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.2897 - acc: 0.8679 - val_loss: 0.4092 - val_acc: 0.8261\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.2793 - acc: 0.9057 - val_loss: 0.4099 - val_acc: 0.8261\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.2786 - acc: 0.8113 - val_loss: 0.4104 - val_acc: 0.8261\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.2458 - acc: 0.8302 - val_loss: 0.4112 - val_acc: 0.8261\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.2368 - acc: 0.8491 - val_loss: 0.4118 - val_acc: 0.8261\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.2646 - acc: 0.8868 - val_loss: 0.4126 - val_acc: 0.8261\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.2981 - acc: 0.7736 - val_loss: 0.4134 - val_acc: 0.8261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      " - 0s - loss: 0.2538 - acc: 0.8302 - val_loss: 0.4143 - val_acc: 0.8261\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.2720 - acc: 0.8113 - val_loss: 0.4151 - val_acc: 0.8261\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.2568 - acc: 0.8302 - val_loss: 0.4156 - val_acc: 0.8261\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.2326 - acc: 0.8113 - val_loss: 0.4161 - val_acc: 0.8261\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.2595 - acc: 0.8113 - val_loss: 0.4169 - val_acc: 0.8261\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.2101 - acc: 0.9245 - val_loss: 0.4176 - val_acc: 0.8261\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.2290 - acc: 0.8491 - val_loss: 0.4184 - val_acc: 0.8261\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.2498 - acc: 0.8302 - val_loss: 0.4193 - val_acc: 0.8261\n"
     ]
    }
   ],
   "source": [
    "mlp_greeting = mlp_greeting(shape)\n",
    "history = mlp_greeting.fit(X_train, np.asarray(y_train[\"Greeting\"]).reshape(-1,1),\n",
    "                  validation_data=(X_validation, np.asarray(y_validation[\"Greeting\"]).reshape(-1,1)),\n",
    "    epochs=200,\n",
    "    workers = 2, use_multiprocessing= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_search(shape):\n",
    "# define our MLP network\n",
    "    initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=42)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=shape, kernel_initializer = initializer, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2, activation=\"relu\"))\n",
    "# check to see if the regression node should be added\n",
    "    #if regress:\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    #Compile model\n",
    "    opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss='binary_crossentropy', metrics = [\"accuracy\"], optimizer=opt)\n",
    "# return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53 samples, validate on 23 samples\n",
      "Epoch 1/250\n",
      " - 1s - loss: 0.6908 - acc: 0.5660 - val_loss: 0.6915 - val_acc: 0.7391\n",
      "Epoch 2/250\n",
      " - 0s - loss: 0.6832 - acc: 0.7358 - val_loss: 0.6888 - val_acc: 0.7391\n",
      "Epoch 3/250\n",
      " - 0s - loss: 0.6851 - acc: 0.7358 - val_loss: 0.6859 - val_acc: 0.7391\n",
      "Epoch 4/250\n",
      " - 0s - loss: 0.6831 - acc: 0.7358 - val_loss: 0.6832 - val_acc: 0.7391\n",
      "Epoch 5/250\n",
      " - 0s - loss: 0.6923 - acc: 0.7358 - val_loss: 0.6807 - val_acc: 0.7391\n",
      "Epoch 6/250\n",
      " - 0s - loss: 0.6929 - acc: 0.7358 - val_loss: 0.6780 - val_acc: 0.7391\n",
      "Epoch 7/250\n",
      " - 0s - loss: 0.6764 - acc: 0.7358 - val_loss: 0.6756 - val_acc: 0.7391\n",
      "Epoch 8/250\n",
      " - 0s - loss: 0.6815 - acc: 0.7358 - val_loss: 0.6732 - val_acc: 0.7391\n",
      "Epoch 9/250\n",
      " - 0s - loss: 0.6908 - acc: 0.7358 - val_loss: 0.6709 - val_acc: 0.7391\n",
      "Epoch 10/250\n",
      " - 0s - loss: 0.6774 - acc: 0.7358 - val_loss: 0.6685 - val_acc: 0.7391\n",
      "Epoch 11/250\n",
      " - 0s - loss: 0.6800 - acc: 0.7358 - val_loss: 0.6662 - val_acc: 0.7391\n",
      "Epoch 12/250\n",
      " - 0s - loss: 0.6651 - acc: 0.7358 - val_loss: 0.6638 - val_acc: 0.7391\n",
      "Epoch 13/250\n",
      " - 0s - loss: 0.6695 - acc: 0.7358 - val_loss: 0.6610 - val_acc: 0.7391\n",
      "Epoch 14/250\n",
      " - 0s - loss: 0.6671 - acc: 0.7358 - val_loss: 0.6582 - val_acc: 0.7391\n",
      "Epoch 15/250\n",
      " - 0s - loss: 0.6604 - acc: 0.7358 - val_loss: 0.6553 - val_acc: 0.7391\n",
      "Epoch 16/250\n",
      " - 0s - loss: 0.6608 - acc: 0.7358 - val_loss: 0.6526 - val_acc: 0.7391\n",
      "Epoch 17/250\n",
      " - 0s - loss: 0.6569 - acc: 0.7358 - val_loss: 0.6495 - val_acc: 0.7391\n",
      "Epoch 18/250\n",
      " - 0s - loss: 0.6454 - acc: 0.7358 - val_loss: 0.6462 - val_acc: 0.7391\n",
      "Epoch 19/250\n",
      " - 0s - loss: 0.6342 - acc: 0.7358 - val_loss: 0.6423 - val_acc: 0.7391\n",
      "Epoch 20/250\n",
      " - 0s - loss: 0.6424 - acc: 0.7358 - val_loss: 0.6378 - val_acc: 0.7391\n",
      "Epoch 21/250\n",
      " - 0s - loss: 0.6462 - acc: 0.7358 - val_loss: 0.6336 - val_acc: 0.7391\n",
      "Epoch 22/250\n",
      " - 0s - loss: 0.6605 - acc: 0.7358 - val_loss: 0.6301 - val_acc: 0.7391\n",
      "Epoch 23/250\n",
      " - 0s - loss: 0.6342 - acc: 0.7358 - val_loss: 0.6267 - val_acc: 0.7391\n",
      "Epoch 24/250\n",
      " - 0s - loss: 0.6314 - acc: 0.7358 - val_loss: 0.6230 - val_acc: 0.7391\n",
      "Epoch 25/250\n",
      " - 0s - loss: 0.6281 - acc: 0.7358 - val_loss: 0.6190 - val_acc: 0.7391\n",
      "Epoch 26/250\n",
      " - 0s - loss: 0.6367 - acc: 0.7358 - val_loss: 0.6150 - val_acc: 0.7391\n",
      "Epoch 27/250\n",
      " - 0s - loss: 0.6357 - acc: 0.7358 - val_loss: 0.6111 - val_acc: 0.7391\n",
      "Epoch 28/250\n",
      " - 0s - loss: 0.6224 - acc: 0.7358 - val_loss: 0.6071 - val_acc: 0.7391\n",
      "Epoch 29/250\n",
      " - 0s - loss: 0.6127 - acc: 0.7358 - val_loss: 0.6029 - val_acc: 0.7391\n",
      "Epoch 30/250\n",
      " - 0s - loss: 0.6151 - acc: 0.7358 - val_loss: 0.5988 - val_acc: 0.7391\n",
      "Epoch 31/250\n",
      " - 0s - loss: 0.6287 - acc: 0.7358 - val_loss: 0.5947 - val_acc: 0.7391\n",
      "Epoch 32/250\n",
      " - 0s - loss: 0.6012 - acc: 0.7358 - val_loss: 0.5907 - val_acc: 0.7391\n",
      "Epoch 33/250\n",
      " - 0s - loss: 0.6124 - acc: 0.7358 - val_loss: 0.5867 - val_acc: 0.7391\n",
      "Epoch 34/250\n",
      " - 0s - loss: 0.6074 - acc: 0.7358 - val_loss: 0.5827 - val_acc: 0.7391\n",
      "Epoch 35/250\n",
      " - 0s - loss: 0.6169 - acc: 0.7358 - val_loss: 0.5788 - val_acc: 0.7391\n",
      "Epoch 36/250\n",
      " - 0s - loss: 0.5954 - acc: 0.7358 - val_loss: 0.5750 - val_acc: 0.7391\n",
      "Epoch 37/250\n",
      " - 0s - loss: 0.5852 - acc: 0.7358 - val_loss: 0.5711 - val_acc: 0.7391\n",
      "Epoch 38/250\n",
      " - 0s - loss: 0.5867 - acc: 0.7358 - val_loss: 0.5672 - val_acc: 0.7391\n",
      "Epoch 39/250\n",
      " - 0s - loss: 0.5748 - acc: 0.7358 - val_loss: 0.5633 - val_acc: 0.7391\n",
      "Epoch 40/250\n",
      " - 0s - loss: 0.6056 - acc: 0.7358 - val_loss: 0.5597 - val_acc: 0.7391\n",
      "Epoch 41/250\n",
      " - 0s - loss: 0.5845 - acc: 0.7358 - val_loss: 0.5563 - val_acc: 0.7391\n",
      "Epoch 42/250\n",
      " - 0s - loss: 0.5870 - acc: 0.7358 - val_loss: 0.5530 - val_acc: 0.7391\n",
      "Epoch 43/250\n",
      " - 0s - loss: 0.5761 - acc: 0.7358 - val_loss: 0.5498 - val_acc: 0.7391\n",
      "Epoch 44/250\n",
      " - 0s - loss: 0.5651 - acc: 0.7358 - val_loss: 0.5465 - val_acc: 0.7391\n",
      "Epoch 45/250\n",
      " - 0s - loss: 0.6156 - acc: 0.7358 - val_loss: 0.5435 - val_acc: 0.7391\n",
      "Epoch 46/250\n",
      " - 0s - loss: 0.5253 - acc: 0.7358 - val_loss: 0.5403 - val_acc: 0.7391\n",
      "Epoch 47/250\n",
      " - 0s - loss: 0.5793 - acc: 0.7358 - val_loss: 0.5372 - val_acc: 0.7391\n",
      "Epoch 48/250\n",
      " - 0s - loss: 0.5464 - acc: 0.7358 - val_loss: 0.5341 - val_acc: 0.7391\n",
      "Epoch 49/250\n",
      " - 0s - loss: 0.5457 - acc: 0.7358 - val_loss: 0.5310 - val_acc: 0.7391\n",
      "Epoch 50/250\n",
      " - 0s - loss: 0.5629 - acc: 0.7358 - val_loss: 0.5280 - val_acc: 0.7391\n",
      "Epoch 51/250\n",
      " - 0s - loss: 0.5640 - acc: 0.7358 - val_loss: 0.5251 - val_acc: 0.7391\n",
      "Epoch 52/250\n",
      " - 0s - loss: 0.5015 - acc: 0.7358 - val_loss: 0.5222 - val_acc: 0.7391\n",
      "Epoch 53/250\n",
      " - 0s - loss: 0.5275 - acc: 0.7358 - val_loss: 0.5191 - val_acc: 0.7391\n",
      "Epoch 54/250\n",
      " - 0s - loss: 0.5488 - acc: 0.7358 - val_loss: 0.5163 - val_acc: 0.7391\n",
      "Epoch 55/250\n",
      " - 0s - loss: 0.5454 - acc: 0.7358 - val_loss: 0.5137 - val_acc: 0.7391\n",
      "Epoch 56/250\n",
      " - 0s - loss: 0.5431 - acc: 0.7358 - val_loss: 0.5109 - val_acc: 0.7391\n",
      "Epoch 57/250\n",
      " - 0s - loss: 0.5440 - acc: 0.7358 - val_loss: 0.5082 - val_acc: 0.7391\n",
      "Epoch 58/250\n",
      " - 0s - loss: 0.5215 - acc: 0.7358 - val_loss: 0.5057 - val_acc: 0.7391\n",
      "Epoch 59/250\n",
      " - 0s - loss: 0.5051 - acc: 0.7358 - val_loss: 0.5033 - val_acc: 0.7391\n",
      "Epoch 60/250\n",
      " - 0s - loss: 0.5260 - acc: 0.7358 - val_loss: 0.5007 - val_acc: 0.7391\n",
      "Epoch 61/250\n",
      " - 0s - loss: 0.5438 - acc: 0.7358 - val_loss: 0.4985 - val_acc: 0.7391\n",
      "Epoch 62/250\n",
      " - 0s - loss: 0.5107 - acc: 0.7358 - val_loss: 0.4962 - val_acc: 0.7391\n",
      "Epoch 63/250\n",
      " - 0s - loss: 0.5048 - acc: 0.7358 - val_loss: 0.4939 - val_acc: 0.7391\n",
      "Epoch 64/250\n",
      " - 0s - loss: 0.5124 - acc: 0.7358 - val_loss: 0.4920 - val_acc: 0.7391\n",
      "Epoch 65/250\n",
      " - 0s - loss: 0.5330 - acc: 0.7358 - val_loss: 0.4900 - val_acc: 0.7391\n",
      "Epoch 66/250\n",
      " - 0s - loss: 0.4684 - acc: 0.7358 - val_loss: 0.4879 - val_acc: 0.7391\n",
      "Epoch 67/250\n",
      " - 0s - loss: 0.5225 - acc: 0.7358 - val_loss: 0.4860 - val_acc: 0.7391\n",
      "Epoch 68/250\n",
      " - 0s - loss: 0.4770 - acc: 0.7358 - val_loss: 0.4841 - val_acc: 0.7391\n",
      "Epoch 69/250\n",
      " - 0s - loss: 0.4948 - acc: 0.7358 - val_loss: 0.4821 - val_acc: 0.7391\n",
      "Epoch 70/250\n",
      " - 0s - loss: 0.4690 - acc: 0.7358 - val_loss: 0.4800 - val_acc: 0.7391\n",
      "Epoch 71/250\n",
      " - 0s - loss: 0.4641 - acc: 0.7358 - val_loss: 0.4779 - val_acc: 0.7391\n",
      "Epoch 72/250\n",
      " - 0s - loss: 0.4603 - acc: 0.7358 - val_loss: 0.4758 - val_acc: 0.7391\n",
      "Epoch 73/250\n",
      " - 0s - loss: 0.4406 - acc: 0.7358 - val_loss: 0.4738 - val_acc: 0.7391\n",
      "Epoch 74/250\n",
      " - 0s - loss: 0.4361 - acc: 0.7358 - val_loss: 0.4718 - val_acc: 0.7391\n",
      "Epoch 75/250\n",
      " - 0s - loss: 0.4374 - acc: 0.7358 - val_loss: 0.4700 - val_acc: 0.7391\n",
      "Epoch 76/250\n",
      " - 0s - loss: 0.4524 - acc: 0.7358 - val_loss: 0.4683 - val_acc: 0.7391\n",
      "Epoch 77/250\n",
      " - 0s - loss: 0.4089 - acc: 0.7358 - val_loss: 0.4667 - val_acc: 0.7391\n",
      "Epoch 78/250\n",
      " - 0s - loss: 0.4747 - acc: 0.7358 - val_loss: 0.4652 - val_acc: 0.7391\n",
      "Epoch 79/250\n",
      " - 0s - loss: 0.4286 - acc: 0.7358 - val_loss: 0.4639 - val_acc: 0.7391\n",
      "Epoch 80/250\n",
      " - 0s - loss: 0.4288 - acc: 0.7358 - val_loss: 0.4631 - val_acc: 0.7391\n",
      "Epoch 81/250\n",
      " - 0s - loss: 0.4295 - acc: 0.7358 - val_loss: 0.4623 - val_acc: 0.7391\n",
      "Epoch 82/250\n",
      " - 0s - loss: 0.4735 - acc: 0.7358 - val_loss: 0.4616 - val_acc: 0.7391\n",
      "Epoch 83/250\n",
      " - 0s - loss: 0.4344 - acc: 0.7358 - val_loss: 0.4611 - val_acc: 0.7391\n",
      "Epoch 84/250\n",
      " - 0s - loss: 0.3864 - acc: 0.7358 - val_loss: 0.4607 - val_acc: 0.7391\n",
      "Epoch 85/250\n",
      " - 0s - loss: 0.4342 - acc: 0.7358 - val_loss: 0.4602 - val_acc: 0.7391\n",
      "Epoch 86/250\n",
      " - 0s - loss: 0.4250 - acc: 0.7358 - val_loss: 0.4599 - val_acc: 0.7391\n",
      "Epoch 87/250\n",
      " - 0s - loss: 0.4143 - acc: 0.7358 - val_loss: 0.4597 - val_acc: 0.7391\n",
      "Epoch 88/250\n",
      " - 0s - loss: 0.4161 - acc: 0.7358 - val_loss: 0.4595 - val_acc: 0.7391\n",
      "Epoch 89/250\n",
      " - 0s - loss: 0.4426 - acc: 0.7358 - val_loss: 0.4592 - val_acc: 0.7391\n",
      "Epoch 90/250\n",
      " - 0s - loss: 0.4159 - acc: 0.7358 - val_loss: 0.4591 - val_acc: 0.7391\n",
      "Epoch 91/250\n",
      " - 0s - loss: 0.4206 - acc: 0.7358 - val_loss: 0.4592 - val_acc: 0.7391\n",
      "Epoch 92/250\n",
      " - 0s - loss: 0.3854 - acc: 0.7358 - val_loss: 0.4596 - val_acc: 0.7391\n",
      "Epoch 93/250\n",
      " - 0s - loss: 0.3916 - acc: 0.7358 - val_loss: 0.4601 - val_acc: 0.7391\n",
      "Epoch 94/250\n",
      " - 0s - loss: 0.3781 - acc: 0.7358 - val_loss: 0.4605 - val_acc: 0.7391\n",
      "Epoch 95/250\n",
      " - 0s - loss: 0.3339 - acc: 0.7358 - val_loss: 0.4609 - val_acc: 0.7391\n",
      "Epoch 96/250\n",
      " - 0s - loss: 0.3697 - acc: 0.7358 - val_loss: 0.4613 - val_acc: 0.7391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/250\n",
      " - 0s - loss: 0.4327 - acc: 0.7358 - val_loss: 0.4621 - val_acc: 0.7391\n",
      "Epoch 98/250\n",
      " - 0s - loss: 0.3580 - acc: 0.7358 - val_loss: 0.4629 - val_acc: 0.7391\n",
      "Epoch 99/250\n",
      " - 0s - loss: 0.3850 - acc: 0.7358 - val_loss: 0.4637 - val_acc: 0.7391\n",
      "Epoch 100/250\n",
      " - 0s - loss: 0.3737 - acc: 0.7358 - val_loss: 0.4646 - val_acc: 0.7391\n",
      "Epoch 101/250\n",
      " - 0s - loss: 0.3552 - acc: 0.7358 - val_loss: 0.4655 - val_acc: 0.7391\n",
      "Epoch 102/250\n",
      " - 0s - loss: 0.3789 - acc: 0.7358 - val_loss: 0.4663 - val_acc: 0.7391\n",
      "Epoch 103/250\n",
      " - 0s - loss: 0.3504 - acc: 0.7358 - val_loss: 0.4674 - val_acc: 0.7391\n",
      "Epoch 104/250\n",
      " - 0s - loss: 0.3691 - acc: 0.7358 - val_loss: 0.4684 - val_acc: 0.7391\n",
      "Epoch 105/250\n",
      " - 0s - loss: 0.3700 - acc: 0.7358 - val_loss: 0.4694 - val_acc: 0.7391\n",
      "Epoch 106/250\n",
      " - 0s - loss: 0.3503 - acc: 0.7358 - val_loss: 0.4707 - val_acc: 0.7391\n",
      "Epoch 107/250\n",
      " - 0s - loss: 0.3690 - acc: 0.7358 - val_loss: 0.4719 - val_acc: 0.7391\n",
      "Epoch 108/250\n",
      " - 0s - loss: 0.3437 - acc: 0.7358 - val_loss: 0.4731 - val_acc: 0.7391\n",
      "Epoch 109/250\n",
      " - 0s - loss: 0.3430 - acc: 0.7358 - val_loss: 0.4739 - val_acc: 0.7391\n",
      "Epoch 110/250\n",
      " - 0s - loss: 0.3413 - acc: 0.7358 - val_loss: 0.4741 - val_acc: 0.7391\n",
      "Epoch 111/250\n",
      " - 0s - loss: 0.3340 - acc: 0.7358 - val_loss: 0.4745 - val_acc: 0.7391\n",
      "Epoch 112/250\n",
      " - 0s - loss: 0.3509 - acc: 0.7358 - val_loss: 0.4752 - val_acc: 0.7391\n",
      "Epoch 113/250\n",
      " - 0s - loss: 0.3235 - acc: 0.7358 - val_loss: 0.4761 - val_acc: 0.7391\n",
      "Epoch 114/250\n",
      " - 0s - loss: 0.2883 - acc: 0.7358 - val_loss: 0.4773 - val_acc: 0.7391\n",
      "Epoch 115/250\n",
      " - 0s - loss: 0.3621 - acc: 0.7358 - val_loss: 0.4788 - val_acc: 0.7391\n",
      "Epoch 116/250\n",
      " - 0s - loss: 0.3003 - acc: 0.7358 - val_loss: 0.4807 - val_acc: 0.7391\n",
      "Epoch 117/250\n",
      " - 0s - loss: 0.3476 - acc: 0.7358 - val_loss: 0.4827 - val_acc: 0.7391\n",
      "Epoch 118/250\n",
      " - 0s - loss: 0.3788 - acc: 0.7358 - val_loss: 0.4850 - val_acc: 0.7391\n",
      "Epoch 119/250\n",
      " - 0s - loss: 0.3960 - acc: 0.7358 - val_loss: 0.4869 - val_acc: 0.7391\n",
      "Epoch 120/250\n",
      " - 0s - loss: 0.3034 - acc: 0.7358 - val_loss: 0.4886 - val_acc: 0.7391\n",
      "Epoch 121/250\n",
      " - 0s - loss: 0.3005 - acc: 0.7358 - val_loss: 0.4907 - val_acc: 0.7391\n",
      "Epoch 122/250\n",
      " - 0s - loss: 0.3041 - acc: 0.7358 - val_loss: 0.4931 - val_acc: 0.7391\n",
      "Epoch 123/250\n",
      " - 0s - loss: 0.3249 - acc: 0.7358 - val_loss: 0.4955 - val_acc: 0.7391\n",
      "Epoch 124/250\n",
      " - 0s - loss: 0.2845 - acc: 0.7358 - val_loss: 0.4971 - val_acc: 0.7391\n",
      "Epoch 125/250\n",
      " - 0s - loss: 0.3478 - acc: 0.7358 - val_loss: 0.4986 - val_acc: 0.7391\n",
      "Epoch 126/250\n",
      " - 0s - loss: 0.2994 - acc: 0.7358 - val_loss: 0.5005 - val_acc: 0.7391\n",
      "Epoch 127/250\n",
      " - 0s - loss: 0.3106 - acc: 0.7358 - val_loss: 0.5023 - val_acc: 0.7391\n",
      "Epoch 128/250\n",
      " - 0s - loss: 0.3156 - acc: 0.7358 - val_loss: 0.5038 - val_acc: 0.7391\n",
      "Epoch 129/250\n",
      " - 0s - loss: 0.3228 - acc: 0.7358 - val_loss: 0.5055 - val_acc: 0.7391\n",
      "Epoch 130/250\n",
      " - 0s - loss: 0.3292 - acc: 0.7358 - val_loss: 0.5065 - val_acc: 0.7391\n",
      "Epoch 131/250\n",
      " - 0s - loss: 0.2909 - acc: 0.7358 - val_loss: 0.5070 - val_acc: 0.7391\n",
      "Epoch 132/250\n",
      " - 0s - loss: 0.3104 - acc: 0.7358 - val_loss: 0.5078 - val_acc: 0.7391\n",
      "Epoch 133/250\n",
      " - 0s - loss: 0.3080 - acc: 0.7358 - val_loss: 0.5089 - val_acc: 0.7391\n",
      "Epoch 134/250\n",
      " - 0s - loss: 0.3137 - acc: 0.7358 - val_loss: 0.5095 - val_acc: 0.7391\n",
      "Epoch 135/250\n",
      " - 0s - loss: 0.3261 - acc: 0.7358 - val_loss: 0.5109 - val_acc: 0.7391\n",
      "Epoch 136/250\n",
      " - 0s - loss: 0.2964 - acc: 0.7358 - val_loss: 0.5127 - val_acc: 0.7391\n",
      "Epoch 137/250\n",
      " - 0s - loss: 0.3368 - acc: 0.7358 - val_loss: 0.5143 - val_acc: 0.7391\n",
      "Epoch 138/250\n",
      " - 0s - loss: 0.2840 - acc: 0.7358 - val_loss: 0.5168 - val_acc: 0.7391\n",
      "Epoch 139/250\n",
      " - 0s - loss: 0.3146 - acc: 0.7358 - val_loss: 0.5194 - val_acc: 0.7391\n",
      "Epoch 140/250\n",
      " - 0s - loss: 0.3186 - acc: 0.7358 - val_loss: 0.5216 - val_acc: 0.7391\n",
      "Epoch 141/250\n",
      " - 0s - loss: 0.2877 - acc: 0.7358 - val_loss: 0.5240 - val_acc: 0.7391\n",
      "Epoch 142/250\n",
      " - 0s - loss: 0.2521 - acc: 0.7358 - val_loss: 0.5267 - val_acc: 0.7391\n",
      "Epoch 143/250\n",
      " - 0s - loss: 0.2887 - acc: 0.7358 - val_loss: 0.5293 - val_acc: 0.7391\n",
      "Epoch 144/250\n",
      " - 0s - loss: 0.2954 - acc: 0.7358 - val_loss: 0.5323 - val_acc: 0.7391\n",
      "Epoch 145/250\n",
      " - 0s - loss: 0.2953 - acc: 0.7358 - val_loss: 0.5355 - val_acc: 0.7391\n",
      "Epoch 146/250\n",
      " - 0s - loss: 0.2616 - acc: 0.7358 - val_loss: 0.5386 - val_acc: 0.7391\n",
      "Epoch 147/250\n",
      " - 0s - loss: 0.2981 - acc: 0.7358 - val_loss: 0.5420 - val_acc: 0.7391\n",
      "Epoch 148/250\n",
      " - 0s - loss: 0.2988 - acc: 0.7358 - val_loss: 0.5457 - val_acc: 0.7391\n",
      "Epoch 149/250\n",
      " - 0s - loss: 0.2823 - acc: 0.7358 - val_loss: 0.5490 - val_acc: 0.7391\n",
      "Epoch 150/250\n",
      " - 0s - loss: 0.3029 - acc: 0.7358 - val_loss: 0.5519 - val_acc: 0.7391\n",
      "Epoch 151/250\n",
      " - 0s - loss: 0.2701 - acc: 0.7358 - val_loss: 0.5550 - val_acc: 0.7391\n",
      "Epoch 152/250\n",
      " - 0s - loss: 0.3039 - acc: 0.7358 - val_loss: 0.5581 - val_acc: 0.7391\n",
      "Epoch 153/250\n",
      " - 0s - loss: 0.2534 - acc: 0.7358 - val_loss: 0.5615 - val_acc: 0.7391\n",
      "Epoch 154/250\n",
      " - 0s - loss: 0.2832 - acc: 0.7358 - val_loss: 0.5643 - val_acc: 0.7391\n",
      "Epoch 155/250\n",
      " - 0s - loss: 0.2930 - acc: 0.7358 - val_loss: 0.5668 - val_acc: 0.7391\n",
      "Epoch 156/250\n",
      " - 0s - loss: 0.2496 - acc: 0.7358 - val_loss: 0.5689 - val_acc: 0.7391\n",
      "Epoch 157/250\n",
      " - 0s - loss: 0.2541 - acc: 0.7358 - val_loss: 0.5712 - val_acc: 0.7391\n",
      "Epoch 158/250\n",
      " - 0s - loss: 0.2336 - acc: 0.7358 - val_loss: 0.5743 - val_acc: 0.7391\n",
      "Epoch 159/250\n",
      " - 0s - loss: 0.3261 - acc: 0.7358 - val_loss: 0.5765 - val_acc: 0.7391\n",
      "Epoch 160/250\n",
      " - 0s - loss: 0.2445 - acc: 0.7358 - val_loss: 0.5792 - val_acc: 0.7391\n",
      "Epoch 161/250\n",
      " - 0s - loss: 0.3005 - acc: 0.7358 - val_loss: 0.5820 - val_acc: 0.7391\n",
      "Epoch 162/250\n",
      " - 0s - loss: 0.2524 - acc: 0.7358 - val_loss: 0.5846 - val_acc: 0.7391\n",
      "Epoch 163/250\n",
      " - 0s - loss: 0.2792 - acc: 0.7358 - val_loss: 0.5868 - val_acc: 0.7391\n",
      "Epoch 164/250\n",
      " - 0s - loss: 0.2927 - acc: 0.7358 - val_loss: 0.5896 - val_acc: 0.7391\n",
      "Epoch 165/250\n",
      " - 0s - loss: 0.2704 - acc: 0.7358 - val_loss: 0.5929 - val_acc: 0.7391\n",
      "Epoch 166/250\n",
      " - 0s - loss: 0.2508 - acc: 0.7358 - val_loss: 0.5964 - val_acc: 0.7391\n",
      "Epoch 167/250\n",
      " - 0s - loss: 0.2346 - acc: 0.7358 - val_loss: 0.5998 - val_acc: 0.7391\n",
      "Epoch 168/250\n",
      " - 0s - loss: 0.2981 - acc: 0.7358 - val_loss: 0.6027 - val_acc: 0.7391\n",
      "Epoch 169/250\n",
      " - 0s - loss: 0.2816 - acc: 0.7358 - val_loss: 0.6053 - val_acc: 0.7391\n",
      "Epoch 170/250\n",
      " - 0s - loss: 0.2804 - acc: 0.7358 - val_loss: 0.6073 - val_acc: 0.7391\n",
      "Epoch 171/250\n",
      " - 0s - loss: 0.2446 - acc: 0.7358 - val_loss: 0.6091 - val_acc: 0.7391\n",
      "Epoch 172/250\n",
      " - 0s - loss: 0.2524 - acc: 0.7358 - val_loss: 0.6110 - val_acc: 0.7391\n",
      "Epoch 173/250\n",
      " - 0s - loss: 0.2643 - acc: 0.7358 - val_loss: 0.6138 - val_acc: 0.7391\n",
      "Epoch 174/250\n",
      " - 0s - loss: 0.2927 - acc: 0.7358 - val_loss: 0.6168 - val_acc: 0.7391\n",
      "Epoch 175/250\n",
      " - 0s - loss: 0.2819 - acc: 0.7358 - val_loss: 0.6205 - val_acc: 0.7391\n",
      "Epoch 176/250\n",
      " - 0s - loss: 0.2503 - acc: 0.7358 - val_loss: 0.6243 - val_acc: 0.7391\n",
      "Epoch 177/250\n",
      " - 0s - loss: 0.2505 - acc: 0.7358 - val_loss: 0.6287 - val_acc: 0.7391\n",
      "Epoch 178/250\n",
      " - 0s - loss: 0.2642 - acc: 0.7358 - val_loss: 0.6326 - val_acc: 0.8261\n",
      "Epoch 179/250\n",
      " - 0s - loss: 0.2638 - acc: 0.9434 - val_loss: 0.6366 - val_acc: 0.8261\n",
      "Epoch 180/250\n",
      " - 0s - loss: 0.2834 - acc: 0.8302 - val_loss: 0.6389 - val_acc: 0.8261\n",
      "Epoch 181/250\n",
      " - 0s - loss: 0.2728 - acc: 0.8868 - val_loss: 0.6415 - val_acc: 0.8261\n",
      "Epoch 182/250\n",
      " - 0s - loss: 0.2672 - acc: 0.9434 - val_loss: 0.6441 - val_acc: 0.8261\n",
      "Epoch 183/250\n",
      " - 0s - loss: 0.2494 - acc: 0.9057 - val_loss: 0.6466 - val_acc: 0.8261\n",
      "Epoch 184/250\n",
      " - 0s - loss: 0.2346 - acc: 0.9245 - val_loss: 0.6498 - val_acc: 0.8261\n",
      "Epoch 185/250\n",
      " - 0s - loss: 0.2640 - acc: 0.8868 - val_loss: 0.6524 - val_acc: 0.8261\n",
      "Epoch 186/250\n",
      " - 0s - loss: 0.2403 - acc: 0.9245 - val_loss: 0.6549 - val_acc: 0.8261\n",
      "Epoch 187/250\n",
      " - 0s - loss: 0.2424 - acc: 0.9245 - val_loss: 0.6580 - val_acc: 0.8261\n",
      "Epoch 188/250\n",
      " - 0s - loss: 0.3160 - acc: 0.9057 - val_loss: 0.6617 - val_acc: 0.8261\n",
      "Epoch 189/250\n",
      " - 0s - loss: 0.2425 - acc: 0.9623 - val_loss: 0.6663 - val_acc: 0.8261\n",
      "Epoch 190/250\n",
      " - 0s - loss: 0.2086 - acc: 0.9245 - val_loss: 0.6707 - val_acc: 0.8261\n",
      "Epoch 191/250\n",
      " - 0s - loss: 0.2597 - acc: 0.9057 - val_loss: 0.6756 - val_acc: 0.8261\n",
      "Epoch 192/250\n",
      " - 0s - loss: 0.2771 - acc: 0.8868 - val_loss: 0.6798 - val_acc: 0.8261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/250\n",
      " - 0s - loss: 0.2457 - acc: 0.9245 - val_loss: 0.6835 - val_acc: 0.8261\n",
      "Epoch 194/250\n",
      " - 0s - loss: 0.2323 - acc: 0.9245 - val_loss: 0.6873 - val_acc: 0.8261\n",
      "Epoch 195/250\n",
      " - 0s - loss: 0.2582 - acc: 0.8868 - val_loss: 0.6910 - val_acc: 0.8261\n",
      "Epoch 196/250\n",
      " - 0s - loss: 0.2434 - acc: 0.9434 - val_loss: 0.6947 - val_acc: 0.8261\n",
      "Epoch 197/250\n",
      " - 0s - loss: 0.2535 - acc: 0.9434 - val_loss: 0.6985 - val_acc: 0.8261\n",
      "Epoch 198/250\n",
      " - 0s - loss: 0.2475 - acc: 0.8868 - val_loss: 0.7019 - val_acc: 0.8261\n",
      "Epoch 199/250\n",
      " - 0s - loss: 0.2530 - acc: 0.8679 - val_loss: 0.7050 - val_acc: 0.8261\n",
      "Epoch 200/250\n",
      " - 0s - loss: 0.2510 - acc: 0.9057 - val_loss: 0.7074 - val_acc: 0.8261\n",
      "Epoch 201/250\n",
      " - 0s - loss: 0.2185 - acc: 0.8868 - val_loss: 0.7092 - val_acc: 0.8261\n",
      "Epoch 202/250\n",
      " - 0s - loss: 0.2565 - acc: 0.8868 - val_loss: 0.7106 - val_acc: 0.8261\n",
      "Epoch 203/250\n",
      " - 0s - loss: 0.2422 - acc: 0.8868 - val_loss: 0.7126 - val_acc: 0.8261\n",
      "Epoch 204/250\n",
      " - 0s - loss: 0.2517 - acc: 0.9245 - val_loss: 0.7141 - val_acc: 0.8261\n",
      "Epoch 205/250\n",
      " - 0s - loss: 0.2128 - acc: 0.9434 - val_loss: 0.7161 - val_acc: 0.8261\n",
      "Epoch 206/250\n",
      " - 0s - loss: 0.2181 - acc: 0.9623 - val_loss: 0.7189 - val_acc: 0.8261\n",
      "Epoch 207/250\n",
      " - 0s - loss: 0.2228 - acc: 0.9245 - val_loss: 0.7219 - val_acc: 0.8261\n",
      "Epoch 208/250\n",
      " - 0s - loss: 0.2114 - acc: 0.9057 - val_loss: 0.7245 - val_acc: 0.8261\n",
      "Epoch 209/250\n",
      " - 0s - loss: 0.2205 - acc: 0.9057 - val_loss: 0.7260 - val_acc: 0.8261\n",
      "Epoch 210/250\n",
      " - 0s - loss: 0.2578 - acc: 0.9434 - val_loss: 0.7272 - val_acc: 0.8261\n",
      "Epoch 211/250\n",
      " - 0s - loss: 0.2510 - acc: 0.9434 - val_loss: 0.7295 - val_acc: 0.8261\n",
      "Epoch 212/250\n",
      " - 0s - loss: 0.3275 - acc: 0.9057 - val_loss: 0.7323 - val_acc: 0.8261\n",
      "Epoch 213/250\n",
      " - 0s - loss: 0.2299 - acc: 0.9245 - val_loss: 0.7336 - val_acc: 0.8261\n",
      "Epoch 214/250\n",
      " - 0s - loss: 0.2151 - acc: 0.9057 - val_loss: 0.7357 - val_acc: 0.8261\n",
      "Epoch 215/250\n",
      " - 0s - loss: 0.2427 - acc: 0.9245 - val_loss: 0.7388 - val_acc: 0.8261\n",
      "Epoch 216/250\n",
      " - 0s - loss: 0.2243 - acc: 0.9057 - val_loss: 0.7424 - val_acc: 0.8261\n",
      "Epoch 217/250\n",
      " - 0s - loss: 0.2815 - acc: 0.9245 - val_loss: 0.7459 - val_acc: 0.8261\n",
      "Epoch 218/250\n",
      " - 0s - loss: 0.2178 - acc: 0.9245 - val_loss: 0.7490 - val_acc: 0.8261\n",
      "Epoch 219/250\n",
      " - 0s - loss: 0.2734 - acc: 0.8679 - val_loss: 0.7519 - val_acc: 0.8261\n",
      "Epoch 220/250\n",
      " - 0s - loss: 0.2201 - acc: 0.9434 - val_loss: 0.7553 - val_acc: 0.8261\n",
      "Epoch 221/250\n",
      " - 0s - loss: 0.1986 - acc: 0.9057 - val_loss: 0.7585 - val_acc: 0.8261\n",
      "Epoch 222/250\n",
      " - 0s - loss: 0.2339 - acc: 0.9245 - val_loss: 0.7605 - val_acc: 0.8261\n",
      "Epoch 223/250\n",
      " - 0s - loss: 0.2332 - acc: 0.9434 - val_loss: 0.7624 - val_acc: 0.8261\n",
      "Epoch 224/250\n",
      " - 0s - loss: 0.2667 - acc: 0.9245 - val_loss: 0.7650 - val_acc: 0.8261\n",
      "Epoch 225/250\n",
      " - 0s - loss: 0.2094 - acc: 0.9057 - val_loss: 0.7685 - val_acc: 0.8261\n",
      "Epoch 226/250\n",
      " - 0s - loss: 0.2770 - acc: 0.8491 - val_loss: 0.7712 - val_acc: 0.8261\n",
      "Epoch 227/250\n",
      " - 0s - loss: 0.2536 - acc: 0.9057 - val_loss: 0.7738 - val_acc: 0.8261\n",
      "Epoch 228/250\n",
      " - 0s - loss: 0.2397 - acc: 0.8868 - val_loss: 0.7760 - val_acc: 0.8261\n",
      "Epoch 229/250\n",
      " - 0s - loss: 0.2035 - acc: 0.9434 - val_loss: 0.7780 - val_acc: 0.8261\n",
      "Epoch 230/250\n",
      " - 0s - loss: 0.2647 - acc: 0.9057 - val_loss: 0.7798 - val_acc: 0.8261\n",
      "Epoch 231/250\n",
      " - 0s - loss: 0.2144 - acc: 0.9434 - val_loss: 0.7821 - val_acc: 0.8261\n",
      "Epoch 232/250\n",
      " - 0s - loss: 0.2085 - acc: 0.9245 - val_loss: 0.7842 - val_acc: 0.8261\n",
      "Epoch 233/250\n",
      " - 0s - loss: 0.2291 - acc: 0.9245 - val_loss: 0.7859 - val_acc: 0.8261\n",
      "Epoch 234/250\n",
      " - 0s - loss: 0.2222 - acc: 0.9623 - val_loss: 0.7875 - val_acc: 0.8261\n",
      "Epoch 235/250\n",
      " - 0s - loss: 0.2332 - acc: 0.9057 - val_loss: 0.7865 - val_acc: 0.8261\n",
      "Epoch 236/250\n",
      " - 0s - loss: 0.2301 - acc: 0.9057 - val_loss: 0.7864 - val_acc: 0.8261\n",
      "Epoch 237/250\n",
      " - 0s - loss: 0.2172 - acc: 0.9434 - val_loss: 0.7874 - val_acc: 0.8261\n",
      "Epoch 238/250\n",
      " - 0s - loss: 0.2380 - acc: 0.9245 - val_loss: 0.7895 - val_acc: 0.8261\n",
      "Epoch 239/250\n",
      " - 0s - loss: 0.2355 - acc: 0.9434 - val_loss: 0.7899 - val_acc: 0.8261\n",
      "Epoch 240/250\n",
      " - 0s - loss: 0.2285 - acc: 0.9057 - val_loss: 0.7898 - val_acc: 0.8261\n",
      "Epoch 241/250\n",
      " - 0s - loss: 0.2127 - acc: 0.9434 - val_loss: 0.7910 - val_acc: 0.8261\n",
      "Epoch 242/250\n",
      " - 0s - loss: 0.2204 - acc: 0.9434 - val_loss: 0.7930 - val_acc: 0.8261\n",
      "Epoch 243/250\n",
      " - 0s - loss: 0.2248 - acc: 0.9057 - val_loss: 0.7947 - val_acc: 0.8261\n",
      "Epoch 244/250\n",
      " - 0s - loss: 0.2041 - acc: 0.9245 - val_loss: 0.7976 - val_acc: 0.8261\n",
      "Epoch 245/250\n",
      " - 0s - loss: 0.2223 - acc: 0.9245 - val_loss: 0.8011 - val_acc: 0.8261\n",
      "Epoch 246/250\n",
      " - 0s - loss: 0.2214 - acc: 0.9057 - val_loss: 0.8049 - val_acc: 0.8261\n",
      "Epoch 247/250\n",
      " - 0s - loss: 0.2955 - acc: 0.8868 - val_loss: 0.8090 - val_acc: 0.8261\n",
      "Epoch 248/250\n",
      " - 0s - loss: 0.2000 - acc: 0.9245 - val_loss: 0.8139 - val_acc: 0.8261\n",
      "Epoch 249/250\n",
      " - 0s - loss: 0.2149 - acc: 0.9057 - val_loss: 0.8186 - val_acc: 0.8261\n",
      "Epoch 250/250\n",
      " - 0s - loss: 0.2182 - acc: 0.8868 - val_loss: 0.8230 - val_acc: 0.8261\n"
     ]
    }
   ],
   "source": [
    "mlp_search = mlp_search(shape)\n",
    "history = mlp_search.fit(X_train, np.asarray(y_train[\"Search\"]).reshape(-1,1),\n",
    "                  validation_data=(X_validation, np.asarray(y_validation[\"Search\"]).reshape(-1,1)),\n",
    "    epochs=250,\n",
    "    workers = 2, use_multiprocessing= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_suggestion(shape):\n",
    "# define our MLP network\n",
    "    initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=42)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=shape, kernel_initializer = initializer, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2, activation=\"relu\"))\n",
    "# check to see if the regression node should be added\n",
    "    #if regress:\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    #Compile model\n",
    "    opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss='binary_crossentropy', metrics = [\"accuracy\"], optimizer = opt)\n",
    "# return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53 samples, validate on 23 samples\n",
      "Epoch 1/250\n",
      " - 1s - loss: 0.6945 - acc: 0.5283 - val_loss: 0.6956 - val_acc: 0.6522\n",
      "Epoch 2/250\n",
      " - 0s - loss: 0.6925 - acc: 0.6415 - val_loss: 0.6949 - val_acc: 0.6087\n",
      "Epoch 3/250\n",
      " - 0s - loss: 0.6898 - acc: 0.6415 - val_loss: 0.6941 - val_acc: 0.6087\n",
      "Epoch 4/250\n",
      " - 0s - loss: 0.6917 - acc: 0.6604 - val_loss: 0.6933 - val_acc: 0.6957\n",
      "Epoch 5/250\n",
      " - 0s - loss: 0.6883 - acc: 0.5472 - val_loss: 0.6924 - val_acc: 0.6957\n",
      "Epoch 6/250\n",
      " - 0s - loss: 0.6942 - acc: 0.5660 - val_loss: 0.6915 - val_acc: 0.6957\n",
      "Epoch 7/250\n",
      " - 0s - loss: 0.6853 - acc: 0.6792 - val_loss: 0.6903 - val_acc: 0.6957\n",
      "Epoch 8/250\n",
      " - 0s - loss: 0.6849 - acc: 0.6981 - val_loss: 0.6890 - val_acc: 0.6957\n",
      "Epoch 9/250\n",
      " - 0s - loss: 0.6860 - acc: 0.7170 - val_loss: 0.6877 - val_acc: 0.6957\n",
      "Epoch 10/250\n",
      " - 0s - loss: 0.6875 - acc: 0.6792 - val_loss: 0.6868 - val_acc: 0.6957\n",
      "Epoch 11/250\n",
      " - 0s - loss: 0.6839 - acc: 0.6792 - val_loss: 0.6854 - val_acc: 0.6957\n",
      "Epoch 12/250\n",
      " - 0s - loss: 0.6787 - acc: 0.6981 - val_loss: 0.6839 - val_acc: 0.6957\n",
      "Epoch 13/250\n",
      " - 0s - loss: 0.6742 - acc: 0.7170 - val_loss: 0.6824 - val_acc: 0.6957\n",
      "Epoch 14/250\n",
      " - 0s - loss: 0.6775 - acc: 0.7358 - val_loss: 0.6808 - val_acc: 0.7391\n",
      "Epoch 15/250\n",
      " - 0s - loss: 0.6738 - acc: 0.7170 - val_loss: 0.6790 - val_acc: 0.7391\n",
      "Epoch 16/250\n",
      " - 0s - loss: 0.6761 - acc: 0.7170 - val_loss: 0.6767 - val_acc: 0.7391\n",
      "Epoch 17/250\n",
      " - 0s - loss: 0.6776 - acc: 0.6792 - val_loss: 0.6745 - val_acc: 0.7391\n",
      "Epoch 18/250\n",
      " - 0s - loss: 0.6706 - acc: 0.7358 - val_loss: 0.6723 - val_acc: 0.7391\n",
      "Epoch 19/250\n",
      " - 0s - loss: 0.6736 - acc: 0.7547 - val_loss: 0.6704 - val_acc: 0.7391\n",
      "Epoch 20/250\n",
      " - 0s - loss: 0.6681 - acc: 0.6981 - val_loss: 0.6682 - val_acc: 0.7391\n",
      "Epoch 21/250\n",
      " - 0s - loss: 0.6550 - acc: 0.7547 - val_loss: 0.6659 - val_acc: 0.7391\n",
      "Epoch 22/250\n",
      " - 0s - loss: 0.6661 - acc: 0.6981 - val_loss: 0.6631 - val_acc: 0.7391\n",
      "Epoch 23/250\n",
      " - 0s - loss: 0.6597 - acc: 0.7358 - val_loss: 0.6603 - val_acc: 0.7391\n",
      "Epoch 24/250\n",
      " - 0s - loss: 0.6560 - acc: 0.7358 - val_loss: 0.6576 - val_acc: 0.7391\n",
      "Epoch 25/250\n",
      " - 0s - loss: 0.6544 - acc: 0.7170 - val_loss: 0.6549 - val_acc: 0.7391\n",
      "Epoch 26/250\n",
      " - 0s - loss: 0.6513 - acc: 0.7358 - val_loss: 0.6522 - val_acc: 0.7391\n",
      "Epoch 27/250\n",
      " - 0s - loss: 0.6496 - acc: 0.7358 - val_loss: 0.6494 - val_acc: 0.7391\n",
      "Epoch 28/250\n",
      " - 0s - loss: 0.6510 - acc: 0.7358 - val_loss: 0.6465 - val_acc: 0.7391\n",
      "Epoch 29/250\n",
      " - 0s - loss: 0.6548 - acc: 0.7547 - val_loss: 0.6436 - val_acc: 0.7391\n",
      "Epoch 30/250\n",
      " - 0s - loss: 0.6389 - acc: 0.7358 - val_loss: 0.6406 - val_acc: 0.7391\n",
      "Epoch 31/250\n",
      " - 0s - loss: 0.6458 - acc: 0.7358 - val_loss: 0.6377 - val_acc: 0.7391\n",
      "Epoch 32/250\n",
      " - 0s - loss: 0.6433 - acc: 0.7358 - val_loss: 0.6345 - val_acc: 0.7391\n",
      "Epoch 33/250\n",
      " - 0s - loss: 0.6456 - acc: 0.7358 - val_loss: 0.6305 - val_acc: 0.7391\n",
      "Epoch 34/250\n",
      " - 0s - loss: 0.6308 - acc: 0.7358 - val_loss: 0.6267 - val_acc: 0.7391\n",
      "Epoch 35/250\n",
      " - 0s - loss: 0.6270 - acc: 0.7358 - val_loss: 0.6230 - val_acc: 0.7391\n",
      "Epoch 36/250\n",
      " - 0s - loss: 0.6401 - acc: 0.7358 - val_loss: 0.6196 - val_acc: 0.7391\n",
      "Epoch 37/250\n",
      " - 0s - loss: 0.6375 - acc: 0.7358 - val_loss: 0.6161 - val_acc: 0.7391\n",
      "Epoch 38/250\n",
      " - 0s - loss: 0.6080 - acc: 0.7358 - val_loss: 0.6123 - val_acc: 0.7391\n",
      "Epoch 39/250\n",
      " - 0s - loss: 0.6238 - acc: 0.7358 - val_loss: 0.6084 - val_acc: 0.7391\n",
      "Epoch 40/250\n",
      " - 0s - loss: 0.6199 - acc: 0.7358 - val_loss: 0.6047 - val_acc: 0.7391\n",
      "Epoch 41/250\n",
      " - 0s - loss: 0.6058 - acc: 0.7358 - val_loss: 0.6005 - val_acc: 0.7391\n",
      "Epoch 42/250\n",
      " - 0s - loss: 0.6169 - acc: 0.7358 - val_loss: 0.5967 - val_acc: 0.7391\n",
      "Epoch 43/250\n",
      " - 0s - loss: 0.6178 - acc: 0.7358 - val_loss: 0.5930 - val_acc: 0.7391\n",
      "Epoch 44/250\n",
      " - 0s - loss: 0.6157 - acc: 0.7358 - val_loss: 0.5895 - val_acc: 0.7391\n",
      "Epoch 45/250\n",
      " - 0s - loss: 0.6079 - acc: 0.7358 - val_loss: 0.5865 - val_acc: 0.7391\n",
      "Epoch 46/250\n",
      " - 0s - loss: 0.5774 - acc: 0.7358 - val_loss: 0.5838 - val_acc: 0.7391\n",
      "Epoch 47/250\n",
      " - 0s - loss: 0.5877 - acc: 0.7358 - val_loss: 0.5809 - val_acc: 0.7391\n",
      "Epoch 48/250\n",
      " - 0s - loss: 0.5735 - acc: 0.7358 - val_loss: 0.5777 - val_acc: 0.7391\n",
      "Epoch 49/250\n",
      " - 0s - loss: 0.5807 - acc: 0.7358 - val_loss: 0.5752 - val_acc: 0.7391\n",
      "Epoch 50/250\n",
      " - 0s - loss: 0.5859 - acc: 0.7358 - val_loss: 0.5728 - val_acc: 0.7391\n",
      "Epoch 51/250\n",
      " - 0s - loss: 0.5708 - acc: 0.7358 - val_loss: 0.5705 - val_acc: 0.7391\n",
      "Epoch 52/250\n",
      " - 0s - loss: 0.5922 - acc: 0.7358 - val_loss: 0.5683 - val_acc: 0.7391\n",
      "Epoch 53/250\n",
      " - 0s - loss: 0.5709 - acc: 0.7358 - val_loss: 0.5659 - val_acc: 0.7391\n",
      "Epoch 54/250\n",
      " - 0s - loss: 0.5779 - acc: 0.7358 - val_loss: 0.5634 - val_acc: 0.7391\n",
      "Epoch 55/250\n",
      " - 0s - loss: 0.5539 - acc: 0.7358 - val_loss: 0.5606 - val_acc: 0.7391\n",
      "Epoch 56/250\n",
      " - 0s - loss: 0.5628 - acc: 0.7358 - val_loss: 0.5576 - val_acc: 0.7391\n",
      "Epoch 57/250\n",
      " - 0s - loss: 0.5621 - acc: 0.7358 - val_loss: 0.5548 - val_acc: 0.7391\n",
      "Epoch 58/250\n",
      " - 0s - loss: 0.5603 - acc: 0.7358 - val_loss: 0.5521 - val_acc: 0.7391\n",
      "Epoch 59/250\n",
      " - 0s - loss: 0.5568 - acc: 0.7358 - val_loss: 0.5493 - val_acc: 0.7391\n",
      "Epoch 60/250\n",
      " - 0s - loss: 0.5095 - acc: 0.7358 - val_loss: 0.5464 - val_acc: 0.7391\n",
      "Epoch 61/250\n",
      " - 0s - loss: 0.5607 - acc: 0.7358 - val_loss: 0.5434 - val_acc: 0.7391\n",
      "Epoch 62/250\n",
      " - 0s - loss: 0.5889 - acc: 0.7358 - val_loss: 0.5407 - val_acc: 0.7391\n",
      "Epoch 63/250\n",
      " - 0s - loss: 0.5449 - acc: 0.7358 - val_loss: 0.5384 - val_acc: 0.7391\n",
      "Epoch 64/250\n",
      " - 0s - loss: 0.5477 - acc: 0.7358 - val_loss: 0.5360 - val_acc: 0.7391\n",
      "Epoch 65/250\n",
      " - 0s - loss: 0.5665 - acc: 0.7358 - val_loss: 0.5337 - val_acc: 0.7391\n",
      "Epoch 66/250\n",
      " - 0s - loss: 0.5366 - acc: 0.7358 - val_loss: 0.5314 - val_acc: 0.7391\n",
      "Epoch 67/250\n",
      " - 0s - loss: 0.5391 - acc: 0.7358 - val_loss: 0.5293 - val_acc: 0.7391\n",
      "Epoch 68/250\n",
      " - 0s - loss: 0.5484 - acc: 0.7358 - val_loss: 0.5271 - val_acc: 0.7391\n",
      "Epoch 69/250\n",
      " - 0s - loss: 0.5090 - acc: 0.7358 - val_loss: 0.5248 - val_acc: 0.7391\n",
      "Epoch 70/250\n",
      " - 0s - loss: 0.5237 - acc: 0.7358 - val_loss: 0.5223 - val_acc: 0.7391\n",
      "Epoch 71/250\n",
      " - 0s - loss: 0.5379 - acc: 0.7358 - val_loss: 0.5196 - val_acc: 0.7391\n",
      "Epoch 72/250\n",
      " - 0s - loss: 0.5290 - acc: 0.7358 - val_loss: 0.5166 - val_acc: 0.7391\n",
      "Epoch 73/250\n",
      " - 0s - loss: 0.5207 - acc: 0.7358 - val_loss: 0.5140 - val_acc: 0.7391\n",
      "Epoch 74/250\n",
      " - 0s - loss: 0.4925 - acc: 0.7358 - val_loss: 0.5114 - val_acc: 0.7391\n",
      "Epoch 75/250\n",
      " - 0s - loss: 0.4808 - acc: 0.7358 - val_loss: 0.5092 - val_acc: 0.7391\n",
      "Epoch 76/250\n",
      " - 0s - loss: 0.4512 - acc: 0.7358 - val_loss: 0.5069 - val_acc: 0.7391\n",
      "Epoch 77/250\n",
      " - 0s - loss: 0.4821 - acc: 0.7358 - val_loss: 0.5042 - val_acc: 0.7391\n",
      "Epoch 78/250\n",
      " - 0s - loss: 0.5213 - acc: 0.7358 - val_loss: 0.5017 - val_acc: 0.7391\n",
      "Epoch 79/250\n",
      " - 0s - loss: 0.4755 - acc: 0.7358 - val_loss: 0.4989 - val_acc: 0.7391\n",
      "Epoch 80/250\n",
      " - 0s - loss: 0.4735 - acc: 0.7358 - val_loss: 0.4961 - val_acc: 0.7391\n",
      "Epoch 81/250\n",
      " - 0s - loss: 0.5032 - acc: 0.7358 - val_loss: 0.4933 - val_acc: 0.7391\n",
      "Epoch 82/250\n",
      " - 0s - loss: 0.4867 - acc: 0.7358 - val_loss: 0.4905 - val_acc: 0.7391\n",
      "Epoch 83/250\n",
      " - 0s - loss: 0.4867 - acc: 0.7358 - val_loss: 0.4879 - val_acc: 0.7391\n",
      "Epoch 84/250\n",
      " - 0s - loss: 0.4993 - acc: 0.7358 - val_loss: 0.4856 - val_acc: 0.7391\n",
      "Epoch 85/250\n",
      " - 0s - loss: 0.4370 - acc: 0.7358 - val_loss: 0.4836 - val_acc: 0.7391\n",
      "Epoch 86/250\n",
      " - 0s - loss: 0.4665 - acc: 0.7358 - val_loss: 0.4816 - val_acc: 0.7391\n",
      "Epoch 87/250\n",
      " - 0s - loss: 0.4840 - acc: 0.7358 - val_loss: 0.4796 - val_acc: 0.7391\n",
      "Epoch 88/250\n",
      " - 0s - loss: 0.4707 - acc: 0.7358 - val_loss: 0.4776 - val_acc: 0.7391\n",
      "Epoch 89/250\n",
      " - 0s - loss: 0.4520 - acc: 0.7358 - val_loss: 0.4757 - val_acc: 0.7391\n",
      "Epoch 90/250\n",
      " - 0s - loss: 0.4431 - acc: 0.7358 - val_loss: 0.4737 - val_acc: 0.7391\n",
      "Epoch 91/250\n",
      " - 0s - loss: 0.4635 - acc: 0.7358 - val_loss: 0.4716 - val_acc: 0.7391\n",
      "Epoch 92/250\n",
      " - 0s - loss: 0.4767 - acc: 0.7358 - val_loss: 0.4695 - val_acc: 0.7391\n",
      "Epoch 93/250\n",
      " - 0s - loss: 0.4877 - acc: 0.7358 - val_loss: 0.4678 - val_acc: 0.7391\n",
      "Epoch 94/250\n",
      " - 0s - loss: 0.4078 - acc: 0.7358 - val_loss: 0.4660 - val_acc: 0.7391\n",
      "Epoch 95/250\n",
      " - 0s - loss: 0.4597 - acc: 0.7358 - val_loss: 0.4643 - val_acc: 0.7391\n",
      "Epoch 96/250\n",
      " - 0s - loss: 0.4519 - acc: 0.7358 - val_loss: 0.4627 - val_acc: 0.7391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/250\n",
      " - 0s - loss: 0.4512 - acc: 0.7358 - val_loss: 0.4611 - val_acc: 0.7391\n",
      "Epoch 98/250\n",
      " - 0s - loss: 0.4532 - acc: 0.7358 - val_loss: 0.4597 - val_acc: 0.7391\n",
      "Epoch 99/250\n",
      " - 0s - loss: 0.4357 - acc: 0.7358 - val_loss: 0.4585 - val_acc: 0.7391\n",
      "Epoch 100/250\n",
      " - 0s - loss: 0.4508 - acc: 0.7358 - val_loss: 0.4575 - val_acc: 0.7391\n",
      "Epoch 101/250\n",
      " - 0s - loss: 0.4423 - acc: 0.7358 - val_loss: 0.4565 - val_acc: 0.7391\n",
      "Epoch 102/250\n",
      " - 0s - loss: 0.4514 - acc: 0.7358 - val_loss: 0.4555 - val_acc: 0.7391\n",
      "Epoch 103/250\n",
      " - 0s - loss: 0.4103 - acc: 0.7358 - val_loss: 0.4545 - val_acc: 0.7391\n",
      "Epoch 104/250\n",
      " - 0s - loss: 0.4555 - acc: 0.7358 - val_loss: 0.4538 - val_acc: 0.7391\n",
      "Epoch 105/250\n",
      " - 0s - loss: 0.4222 - acc: 0.7358 - val_loss: 0.4531 - val_acc: 0.7391\n",
      "Epoch 106/250\n",
      " - 0s - loss: 0.3956 - acc: 0.7358 - val_loss: 0.4523 - val_acc: 0.7391\n",
      "Epoch 107/250\n",
      " - 0s - loss: 0.4150 - acc: 0.7358 - val_loss: 0.4513 - val_acc: 0.7391\n",
      "Epoch 108/250\n",
      " - 0s - loss: 0.4229 - acc: 0.7358 - val_loss: 0.4505 - val_acc: 0.7391\n",
      "Epoch 109/250\n",
      " - 0s - loss: 0.3890 - acc: 0.7358 - val_loss: 0.4495 - val_acc: 0.7391\n",
      "Epoch 110/250\n",
      " - 0s - loss: 0.4692 - acc: 0.7358 - val_loss: 0.4488 - val_acc: 0.7391\n",
      "Epoch 111/250\n",
      " - 0s - loss: 0.4380 - acc: 0.7358 - val_loss: 0.4481 - val_acc: 0.7391\n",
      "Epoch 112/250\n",
      " - 0s - loss: 0.3581 - acc: 0.7358 - val_loss: 0.4474 - val_acc: 0.7391\n",
      "Epoch 113/250\n",
      " - 0s - loss: 0.4056 - acc: 0.7358 - val_loss: 0.4467 - val_acc: 0.7391\n",
      "Epoch 114/250\n",
      " - 0s - loss: 0.3813 - acc: 0.7358 - val_loss: 0.4461 - val_acc: 0.7391\n",
      "Epoch 115/250\n",
      " - 0s - loss: 0.3805 - acc: 0.7358 - val_loss: 0.4456 - val_acc: 0.7391\n",
      "Epoch 116/250\n",
      " - 0s - loss: 0.3756 - acc: 0.7358 - val_loss: 0.4451 - val_acc: 0.7391\n",
      "Epoch 117/250\n",
      " - 0s - loss: 0.3857 - acc: 0.7358 - val_loss: 0.4445 - val_acc: 0.7391\n",
      "Epoch 118/250\n",
      " - 0s - loss: 0.4371 - acc: 0.7358 - val_loss: 0.4441 - val_acc: 0.7391\n",
      "Epoch 119/250\n",
      " - 0s - loss: 0.3954 - acc: 0.7358 - val_loss: 0.4437 - val_acc: 0.7391\n",
      "Epoch 120/250\n",
      " - 0s - loss: 0.3884 - acc: 0.7358 - val_loss: 0.4434 - val_acc: 0.7391\n",
      "Epoch 121/250\n",
      " - 0s - loss: 0.3956 - acc: 0.7358 - val_loss: 0.4432 - val_acc: 0.7391\n",
      "Epoch 122/250\n",
      " - 0s - loss: 0.3881 - acc: 0.7358 - val_loss: 0.4430 - val_acc: 0.7391\n",
      "Epoch 123/250\n",
      " - 0s - loss: 0.3878 - acc: 0.7358 - val_loss: 0.4427 - val_acc: 0.7391\n",
      "Epoch 124/250\n",
      " - 0s - loss: 0.4244 - acc: 0.7358 - val_loss: 0.4425 - val_acc: 0.7391\n",
      "Epoch 125/250\n",
      " - 0s - loss: 0.3768 - acc: 0.7358 - val_loss: 0.4423 - val_acc: 0.7391\n",
      "Epoch 126/250\n",
      " - 0s - loss: 0.4039 - acc: 0.7358 - val_loss: 0.4421 - val_acc: 0.7391\n",
      "Epoch 127/250\n",
      " - 0s - loss: 0.3908 - acc: 0.7358 - val_loss: 0.4418 - val_acc: 0.7391\n",
      "Epoch 128/250\n",
      " - 0s - loss: 0.4228 - acc: 0.7358 - val_loss: 0.4415 - val_acc: 0.7391\n",
      "Epoch 129/250\n",
      " - 0s - loss: 0.4000 - acc: 0.7358 - val_loss: 0.4411 - val_acc: 0.7391\n",
      "Epoch 130/250\n",
      " - 0s - loss: 0.3490 - acc: 0.7358 - val_loss: 0.4407 - val_acc: 0.7391\n",
      "Epoch 131/250\n",
      " - 0s - loss: 0.3922 - acc: 0.7358 - val_loss: 0.4404 - val_acc: 0.7391\n",
      "Epoch 132/250\n",
      " - 0s - loss: 0.3831 - acc: 0.7358 - val_loss: 0.4402 - val_acc: 0.7391\n",
      "Epoch 133/250\n",
      " - 0s - loss: 0.3484 - acc: 0.7358 - val_loss: 0.4400 - val_acc: 0.7391\n",
      "Epoch 134/250\n",
      " - 0s - loss: 0.3750 - acc: 0.7358 - val_loss: 0.4400 - val_acc: 0.7391\n",
      "Epoch 135/250\n",
      " - 0s - loss: 0.3391 - acc: 0.7358 - val_loss: 0.4400 - val_acc: 0.7391\n",
      "Epoch 136/250\n",
      " - 0s - loss: 0.4115 - acc: 0.7358 - val_loss: 0.4401 - val_acc: 0.7391\n",
      "Epoch 137/250\n",
      " - 0s - loss: 0.4005 - acc: 0.7358 - val_loss: 0.4401 - val_acc: 0.7391\n",
      "Epoch 138/250\n",
      " - 0s - loss: 0.3821 - acc: 0.7358 - val_loss: 0.4401 - val_acc: 0.7391\n",
      "Epoch 139/250\n",
      " - 0s - loss: 0.4016 - acc: 0.7358 - val_loss: 0.4402 - val_acc: 0.7391\n",
      "Epoch 140/250\n",
      " - 0s - loss: 0.3555 - acc: 0.7358 - val_loss: 0.4404 - val_acc: 0.7391\n",
      "Epoch 141/250\n",
      " - 0s - loss: 0.4271 - acc: 0.7358 - val_loss: 0.4406 - val_acc: 0.7391\n",
      "Epoch 142/250\n",
      " - 0s - loss: 0.3585 - acc: 0.7358 - val_loss: 0.4409 - val_acc: 0.7391\n",
      "Epoch 143/250\n",
      " - 0s - loss: 0.3583 - acc: 0.7358 - val_loss: 0.4410 - val_acc: 0.7391\n",
      "Epoch 144/250\n",
      " - 0s - loss: 0.3886 - acc: 0.7358 - val_loss: 0.4409 - val_acc: 0.7391\n",
      "Epoch 145/250\n",
      " - 0s - loss: 0.3556 - acc: 0.7358 - val_loss: 0.4409 - val_acc: 0.7391\n",
      "Epoch 146/250\n",
      " - 0s - loss: 0.3464 - acc: 0.7358 - val_loss: 0.4409 - val_acc: 0.7391\n",
      "Epoch 147/250\n",
      " - 0s - loss: 0.3792 - acc: 0.7358 - val_loss: 0.4409 - val_acc: 0.7391\n",
      "Epoch 148/250\n",
      " - 0s - loss: 0.4156 - acc: 0.7358 - val_loss: 0.4409 - val_acc: 0.7391\n",
      "Epoch 149/250\n",
      " - 0s - loss: 0.3941 - acc: 0.7358 - val_loss: 0.4410 - val_acc: 0.7391\n",
      "Epoch 150/250\n",
      " - 0s - loss: 0.4131 - acc: 0.7358 - val_loss: 0.4410 - val_acc: 0.7391\n",
      "Epoch 151/250\n",
      " - 0s - loss: 0.3693 - acc: 0.7358 - val_loss: 0.4411 - val_acc: 0.7391\n",
      "Epoch 152/250\n",
      " - 0s - loss: 0.3603 - acc: 0.7358 - val_loss: 0.4414 - val_acc: 0.7391\n",
      "Epoch 153/250\n",
      " - 0s - loss: 0.3601 - acc: 0.7358 - val_loss: 0.4417 - val_acc: 0.7391\n",
      "Epoch 154/250\n",
      " - 0s - loss: 0.4087 - acc: 0.7358 - val_loss: 0.4421 - val_acc: 0.7391\n",
      "Epoch 155/250\n",
      " - 0s - loss: 0.3644 - acc: 0.7358 - val_loss: 0.4426 - val_acc: 0.7391\n",
      "Epoch 156/250\n",
      " - 0s - loss: 0.3372 - acc: 0.7358 - val_loss: 0.4431 - val_acc: 0.7391\n",
      "Epoch 157/250\n",
      " - 0s - loss: 0.4214 - acc: 0.7358 - val_loss: 0.4437 - val_acc: 0.7391\n",
      "Epoch 158/250\n",
      " - 0s - loss: 0.4112 - acc: 0.7358 - val_loss: 0.4443 - val_acc: 0.7391\n",
      "Epoch 159/250\n",
      " - 0s - loss: 0.3151 - acc: 0.7358 - val_loss: 0.4450 - val_acc: 0.7391\n",
      "Epoch 160/250\n",
      " - 0s - loss: 0.3474 - acc: 0.7358 - val_loss: 0.4455 - val_acc: 0.7391\n",
      "Epoch 161/250\n",
      " - 0s - loss: 0.3520 - acc: 0.7358 - val_loss: 0.4458 - val_acc: 0.7391\n",
      "Epoch 162/250\n",
      " - 0s - loss: 0.3630 - acc: 0.7358 - val_loss: 0.4460 - val_acc: 0.7391\n",
      "Epoch 163/250\n",
      " - 0s - loss: 0.3667 - acc: 0.7358 - val_loss: 0.4463 - val_acc: 0.7391\n",
      "Epoch 164/250\n",
      " - 0s - loss: 0.3835 - acc: 0.7358 - val_loss: 0.4465 - val_acc: 0.7391\n",
      "Epoch 165/250\n",
      " - 0s - loss: 0.3540 - acc: 0.7358 - val_loss: 0.4468 - val_acc: 0.7391\n",
      "Epoch 166/250\n",
      " - 0s - loss: 0.3617 - acc: 0.7358 - val_loss: 0.4472 - val_acc: 0.7391\n",
      "Epoch 167/250\n",
      " - 0s - loss: 0.3799 - acc: 0.7358 - val_loss: 0.4474 - val_acc: 0.7391\n",
      "Epoch 168/250\n",
      " - 0s - loss: 0.3901 - acc: 0.7358 - val_loss: 0.4477 - val_acc: 0.7391\n",
      "Epoch 169/250\n",
      " - 0s - loss: 0.2916 - acc: 0.7358 - val_loss: 0.4480 - val_acc: 0.7391\n",
      "Epoch 170/250\n",
      " - 0s - loss: 0.3736 - acc: 0.7358 - val_loss: 0.4482 - val_acc: 0.7391\n",
      "Epoch 171/250\n",
      " - 0s - loss: 0.3240 - acc: 0.7358 - val_loss: 0.4485 - val_acc: 0.7391\n",
      "Epoch 172/250\n",
      " - 0s - loss: 0.3945 - acc: 0.7358 - val_loss: 0.4488 - val_acc: 0.7391\n",
      "Epoch 173/250\n",
      " - 0s - loss: 0.3709 - acc: 0.7358 - val_loss: 0.4491 - val_acc: 0.7391\n",
      "Epoch 174/250\n",
      " - 0s - loss: 0.3594 - acc: 0.7358 - val_loss: 0.4496 - val_acc: 0.7391\n",
      "Epoch 175/250\n",
      " - 0s - loss: 0.2966 - acc: 0.7358 - val_loss: 0.4503 - val_acc: 0.7391\n",
      "Epoch 176/250\n",
      " - 0s - loss: 0.3893 - acc: 0.7358 - val_loss: 0.4509 - val_acc: 0.7391\n",
      "Epoch 177/250\n",
      " - 0s - loss: 0.3927 - acc: 0.7358 - val_loss: 0.4514 - val_acc: 0.7391\n",
      "Epoch 178/250\n",
      " - 0s - loss: 0.3445 - acc: 0.7358 - val_loss: 0.4518 - val_acc: 0.7391\n",
      "Epoch 179/250\n",
      " - 0s - loss: 0.3922 - acc: 0.7358 - val_loss: 0.4523 - val_acc: 0.7391\n",
      "Epoch 180/250\n",
      " - 0s - loss: 0.3018 - acc: 0.7358 - val_loss: 0.4527 - val_acc: 0.7391\n",
      "Epoch 181/250\n",
      " - 0s - loss: 0.3908 - acc: 0.7358 - val_loss: 0.4526 - val_acc: 0.7391\n",
      "Epoch 182/250\n",
      " - 0s - loss: 0.3889 - acc: 0.7358 - val_loss: 0.4525 - val_acc: 0.7391\n",
      "Epoch 183/250\n",
      " - 0s - loss: 0.3596 - acc: 0.7358 - val_loss: 0.4527 - val_acc: 0.7391\n",
      "Epoch 184/250\n",
      " - 0s - loss: 0.3249 - acc: 0.7358 - val_loss: 0.4530 - val_acc: 0.7391\n",
      "Epoch 185/250\n",
      " - 0s - loss: 0.3430 - acc: 0.7358 - val_loss: 0.4534 - val_acc: 0.7391\n",
      "Epoch 186/250\n",
      " - 0s - loss: 0.3290 - acc: 0.7358 - val_loss: 0.4540 - val_acc: 0.7391\n",
      "Epoch 187/250\n",
      " - 0s - loss: 0.3655 - acc: 0.7358 - val_loss: 0.4547 - val_acc: 0.7391\n",
      "Epoch 188/250\n",
      " - 0s - loss: 0.3701 - acc: 0.7358 - val_loss: 0.4552 - val_acc: 0.7391\n",
      "Epoch 189/250\n",
      " - 0s - loss: 0.3559 - acc: 0.7358 - val_loss: 0.4558 - val_acc: 0.7391\n",
      "Epoch 190/250\n",
      " - 0s - loss: 0.3227 - acc: 0.7358 - val_loss: 0.4568 - val_acc: 0.7391\n",
      "Epoch 191/250\n",
      " - 0s - loss: 0.3637 - acc: 0.7358 - val_loss: 0.4579 - val_acc: 0.7391\n",
      "Epoch 192/250\n",
      " - 0s - loss: 0.3587 - acc: 0.7358 - val_loss: 0.4591 - val_acc: 0.7391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/250\n",
      " - 0s - loss: 0.3331 - acc: 0.7358 - val_loss: 0.4605 - val_acc: 0.7391\n",
      "Epoch 194/250\n",
      " - 0s - loss: 0.3616 - acc: 0.7358 - val_loss: 0.4620 - val_acc: 0.7391\n",
      "Epoch 195/250\n",
      " - 0s - loss: 0.3550 - acc: 0.7358 - val_loss: 0.4635 - val_acc: 0.7391\n",
      "Epoch 196/250\n",
      " - 0s - loss: 0.3491 - acc: 0.7358 - val_loss: 0.4648 - val_acc: 0.7391\n",
      "Epoch 197/250\n",
      " - 0s - loss: 0.3121 - acc: 0.7358 - val_loss: 0.4660 - val_acc: 0.7391\n",
      "Epoch 198/250\n",
      " - 0s - loss: 0.3316 - acc: 0.7358 - val_loss: 0.4666 - val_acc: 0.7391\n",
      "Epoch 199/250\n",
      " - 0s - loss: 0.3721 - acc: 0.7358 - val_loss: 0.4670 - val_acc: 0.7391\n",
      "Epoch 200/250\n",
      " - 0s - loss: 0.2921 - acc: 0.7358 - val_loss: 0.4675 - val_acc: 0.7391\n",
      "Epoch 201/250\n",
      " - 0s - loss: 0.3276 - acc: 0.7358 - val_loss: 0.4678 - val_acc: 0.7391\n",
      "Epoch 202/250\n",
      " - 0s - loss: 0.3307 - acc: 0.7358 - val_loss: 0.4680 - val_acc: 0.7391\n",
      "Epoch 203/250\n",
      " - 0s - loss: 0.3824 - acc: 0.7358 - val_loss: 0.4682 - val_acc: 0.7391\n",
      "Epoch 204/250\n",
      " - 0s - loss: 0.2963 - acc: 0.7358 - val_loss: 0.4687 - val_acc: 0.7391\n",
      "Epoch 205/250\n",
      " - 0s - loss: 0.3503 - acc: 0.7358 - val_loss: 0.4692 - val_acc: 0.7391\n",
      "Epoch 206/250\n",
      " - 0s - loss: 0.3057 - acc: 0.7358 - val_loss: 0.4699 - val_acc: 0.7391\n",
      "Epoch 207/250\n",
      " - 0s - loss: 0.3186 - acc: 0.7358 - val_loss: 0.4708 - val_acc: 0.7391\n",
      "Epoch 208/250\n",
      " - 0s - loss: 0.3590 - acc: 0.7358 - val_loss: 0.4713 - val_acc: 0.7391\n",
      "Epoch 209/250\n",
      " - 0s - loss: 0.3220 - acc: 0.7358 - val_loss: 0.4720 - val_acc: 0.7391\n",
      "Epoch 210/250\n",
      " - 0s - loss: 0.3541 - acc: 0.7358 - val_loss: 0.4727 - val_acc: 0.7391\n",
      "Epoch 211/250\n",
      " - 0s - loss: 0.2851 - acc: 0.7358 - val_loss: 0.4736 - val_acc: 0.7391\n",
      "Epoch 212/250\n",
      " - 0s - loss: 0.3557 - acc: 0.7358 - val_loss: 0.4747 - val_acc: 0.7391\n",
      "Epoch 213/250\n",
      " - 0s - loss: 0.2740 - acc: 0.7358 - val_loss: 0.4758 - val_acc: 0.7391\n",
      "Epoch 214/250\n",
      " - 0s - loss: 0.3597 - acc: 0.7358 - val_loss: 0.4762 - val_acc: 0.7391\n",
      "Epoch 215/250\n",
      " - 0s - loss: 0.2996 - acc: 0.7358 - val_loss: 0.4765 - val_acc: 0.7391\n",
      "Epoch 216/250\n",
      " - 0s - loss: 0.3540 - acc: 0.7358 - val_loss: 0.4771 - val_acc: 0.7391\n",
      "Epoch 217/250\n",
      " - 0s - loss: 0.3030 - acc: 0.7358 - val_loss: 0.4780 - val_acc: 0.7391\n",
      "Epoch 218/250\n",
      " - 0s - loss: 0.3292 - acc: 0.7358 - val_loss: 0.4786 - val_acc: 0.7391\n",
      "Epoch 219/250\n",
      " - 0s - loss: 0.3924 - acc: 0.7358 - val_loss: 0.4792 - val_acc: 0.7391\n",
      "Epoch 220/250\n",
      " - 0s - loss: 0.3583 - acc: 0.7358 - val_loss: 0.4798 - val_acc: 0.7391\n",
      "Epoch 221/250\n",
      " - 0s - loss: 0.4158 - acc: 0.7358 - val_loss: 0.4807 - val_acc: 0.7391\n",
      "Epoch 222/250\n",
      " - 0s - loss: 0.3300 - acc: 0.7358 - val_loss: 0.4819 - val_acc: 0.7391\n",
      "Epoch 223/250\n",
      " - 0s - loss: 0.3202 - acc: 0.7358 - val_loss: 0.4829 - val_acc: 0.7391\n",
      "Epoch 224/250\n",
      " - 0s - loss: 0.3060 - acc: 0.7358 - val_loss: 0.4841 - val_acc: 0.7391\n",
      "Epoch 225/250\n",
      " - 0s - loss: 0.3305 - acc: 0.7358 - val_loss: 0.4854 - val_acc: 0.7391\n",
      "Epoch 226/250\n",
      " - 0s - loss: 0.3228 - acc: 0.7358 - val_loss: 0.4868 - val_acc: 0.7391\n",
      "Epoch 227/250\n",
      " - 0s - loss: 0.3181 - acc: 0.7358 - val_loss: 0.4883 - val_acc: 0.7391\n",
      "Epoch 228/250\n",
      " - 0s - loss: 0.3126 - acc: 0.7358 - val_loss: 0.4901 - val_acc: 0.7391\n",
      "Epoch 229/250\n",
      " - 0s - loss: 0.3289 - acc: 0.7358 - val_loss: 0.4918 - val_acc: 0.7391\n",
      "Epoch 230/250\n",
      " - 0s - loss: 0.3797 - acc: 0.7358 - val_loss: 0.4935 - val_acc: 0.7391\n",
      "Epoch 231/250\n",
      " - 0s - loss: 0.3099 - acc: 0.7358 - val_loss: 0.4945 - val_acc: 0.7391\n",
      "Epoch 232/250\n",
      " - 0s - loss: 0.3079 - acc: 0.7358 - val_loss: 0.4952 - val_acc: 0.7391\n",
      "Epoch 233/250\n",
      " - 0s - loss: 0.3045 - acc: 0.7358 - val_loss: 0.4961 - val_acc: 0.7391\n",
      "Epoch 234/250\n",
      " - 0s - loss: 0.3393 - acc: 0.7358 - val_loss: 0.4966 - val_acc: 0.7391\n",
      "Epoch 235/250\n",
      " - 0s - loss: 0.3707 - acc: 0.7358 - val_loss: 0.4971 - val_acc: 0.7391\n",
      "Epoch 236/250\n",
      " - 0s - loss: 0.3077 - acc: 0.7358 - val_loss: 0.4978 - val_acc: 0.7391\n",
      "Epoch 237/250\n",
      " - 0s - loss: 0.2809 - acc: 0.7358 - val_loss: 0.4986 - val_acc: 0.7391\n",
      "Epoch 238/250\n",
      " - 0s - loss: 0.3450 - acc: 0.7358 - val_loss: 0.4998 - val_acc: 0.7391\n",
      "Epoch 239/250\n",
      " - 0s - loss: 0.3540 - acc: 0.7358 - val_loss: 0.5007 - val_acc: 0.7391\n",
      "Epoch 240/250\n",
      " - 0s - loss: 0.3586 - acc: 0.7358 - val_loss: 0.5016 - val_acc: 0.7391\n",
      "Epoch 241/250\n",
      " - 0s - loss: 0.2976 - acc: 0.7358 - val_loss: 0.5025 - val_acc: 0.7391\n",
      "Epoch 242/250\n",
      " - 0s - loss: 0.3470 - acc: 0.7358 - val_loss: 0.5036 - val_acc: 0.7391\n",
      "Epoch 243/250\n",
      " - 0s - loss: 0.3199 - acc: 0.7358 - val_loss: 0.5049 - val_acc: 0.7391\n",
      "Epoch 244/250\n",
      " - 0s - loss: 0.3348 - acc: 0.7358 - val_loss: 0.5061 - val_acc: 0.7391\n",
      "Epoch 245/250\n",
      " - 0s - loss: 0.3248 - acc: 0.7358 - val_loss: 0.5064 - val_acc: 0.7391\n",
      "Epoch 246/250\n",
      " - 0s - loss: 0.3601 - acc: 0.7358 - val_loss: 0.5064 - val_acc: 0.7391\n",
      "Epoch 247/250\n",
      " - 0s - loss: 0.3731 - acc: 0.7358 - val_loss: 0.5057 - val_acc: 0.7391\n",
      "Epoch 248/250\n",
      " - 0s - loss: 0.3728 - acc: 0.7358 - val_loss: 0.5051 - val_acc: 0.7391\n",
      "Epoch 249/250\n",
      " - 0s - loss: 0.3312 - acc: 0.7358 - val_loss: 0.5043 - val_acc: 0.7391\n",
      "Epoch 250/250\n",
      " - 0s - loss: 0.2655 - acc: 0.7358 - val_loss: 0.5040 - val_acc: 0.7391\n"
     ]
    }
   ],
   "source": [
    "mlp_suggestion = mlp_suggestion(shape)\n",
    "history = mlp_suggestion.fit(X_train, np.asarray(y_train[\"Search\"]).reshape(-1,1),\n",
    "                  validation_data=(X_validation, np.asarray(y_validation[\"Search\"]).reshape(-1,1)),\n",
    "    epochs=250,\n",
    "    workers = 2, use_multiprocessing= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_farewell(shape):\n",
    "# define our MLP network\n",
    "    initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=42)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=shape, kernel_initializer = initializer, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(2, activation=\"relu\"))\n",
    "# check to see if the regression node should be added\n",
    "    #if regress:\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "    #Compile model\n",
    "    opt = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss='binary_crossentropy', metrics = [\"accuracy\"], optimizer=opt)\n",
    "# return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53 samples, validate on 23 samples\n",
      "Epoch 1/250\n",
      " - 1s - loss: 0.6915 - acc: 0.7547 - val_loss: 0.6928 - val_acc: 0.7391\n",
      "Epoch 2/250\n",
      " - 0s - loss: 0.6929 - acc: 0.7170 - val_loss: 0.6923 - val_acc: 0.7391\n",
      "Epoch 3/250\n",
      " - 0s - loss: 0.6928 - acc: 0.7170 - val_loss: 0.6919 - val_acc: 0.7391\n",
      "Epoch 4/250\n",
      " - 0s - loss: 0.6943 - acc: 0.6415 - val_loss: 0.6914 - val_acc: 0.7391\n",
      "Epoch 5/250\n",
      " - 0s - loss: 0.6922 - acc: 0.6981 - val_loss: 0.6909 - val_acc: 0.7391\n",
      "Epoch 6/250\n",
      " - 0s - loss: 0.6904 - acc: 0.7358 - val_loss: 0.6904 - val_acc: 0.7391\n",
      "Epoch 7/250\n",
      " - 0s - loss: 0.6909 - acc: 0.7358 - val_loss: 0.6899 - val_acc: 0.7391\n",
      "Epoch 8/250\n",
      " - 0s - loss: 0.6900 - acc: 0.6981 - val_loss: 0.6894 - val_acc: 0.7391\n",
      "Epoch 9/250\n",
      " - 0s - loss: 0.6884 - acc: 0.6981 - val_loss: 0.6889 - val_acc: 0.7391\n",
      "Epoch 10/250\n",
      " - 0s - loss: 0.6863 - acc: 0.7925 - val_loss: 0.6884 - val_acc: 0.7391\n",
      "Epoch 11/250\n",
      " - 0s - loss: 0.6887 - acc: 0.7170 - val_loss: 0.6879 - val_acc: 0.7391\n",
      "Epoch 12/250\n",
      " - 0s - loss: 0.6885 - acc: 0.7547 - val_loss: 0.6874 - val_acc: 0.7391\n",
      "Epoch 13/250\n",
      " - 0s - loss: 0.6893 - acc: 0.6981 - val_loss: 0.6869 - val_acc: 0.7391\n",
      "Epoch 14/250\n",
      " - 0s - loss: 0.6870 - acc: 0.7736 - val_loss: 0.6864 - val_acc: 0.7391\n",
      "Epoch 15/250\n",
      " - 0s - loss: 0.6856 - acc: 0.7547 - val_loss: 0.6859 - val_acc: 0.7391\n",
      "Epoch 16/250\n",
      " - 0s - loss: 0.6868 - acc: 0.7170 - val_loss: 0.6854 - val_acc: 0.7391\n",
      "Epoch 17/250\n",
      " - 0s - loss: 0.6836 - acc: 0.8113 - val_loss: 0.6849 - val_acc: 0.7391\n",
      "Epoch 18/250\n",
      " - 0s - loss: 0.6866 - acc: 0.7358 - val_loss: 0.6844 - val_acc: 0.7391\n",
      "Epoch 19/250\n",
      " - 0s - loss: 0.6823 - acc: 0.7736 - val_loss: 0.6839 - val_acc: 0.7391\n",
      "Epoch 20/250\n",
      " - 0s - loss: 0.6796 - acc: 0.8113 - val_loss: 0.6834 - val_acc: 0.7391\n",
      "Epoch 21/250\n",
      " - 0s - loss: 0.6831 - acc: 0.7547 - val_loss: 0.6829 - val_acc: 0.7391\n",
      "Epoch 22/250\n",
      " - 0s - loss: 0.6817 - acc: 0.7547 - val_loss: 0.6824 - val_acc: 0.7391\n",
      "Epoch 23/250\n",
      " - 0s - loss: 0.6841 - acc: 0.7170 - val_loss: 0.6819 - val_acc: 0.7391\n",
      "Epoch 24/250\n",
      " - 0s - loss: 0.6826 - acc: 0.7547 - val_loss: 0.6814 - val_acc: 0.7391\n",
      "Epoch 25/250\n",
      " - 0s - loss: 0.6816 - acc: 0.7547 - val_loss: 0.6809 - val_acc: 0.7391\n",
      "Epoch 26/250\n",
      " - 0s - loss: 0.6797 - acc: 0.7547 - val_loss: 0.6804 - val_acc: 0.7391\n",
      "Epoch 27/250\n",
      " - 0s - loss: 0.6819 - acc: 0.7170 - val_loss: 0.6799 - val_acc: 0.7391\n",
      "Epoch 28/250\n",
      " - 0s - loss: 0.6792 - acc: 0.7358 - val_loss: 0.6794 - val_acc: 0.7391\n",
      "Epoch 29/250\n",
      " - 0s - loss: 0.6781 - acc: 0.7736 - val_loss: 0.6790 - val_acc: 0.7391\n",
      "Epoch 30/250\n",
      " - 0s - loss: 0.6777 - acc: 0.7547 - val_loss: 0.6785 - val_acc: 0.7391\n",
      "Epoch 31/250\n",
      " - 0s - loss: 0.6769 - acc: 0.7736 - val_loss: 0.6780 - val_acc: 0.7391\n",
      "Epoch 32/250\n",
      " - 0s - loss: 0.6759 - acc: 0.7736 - val_loss: 0.6775 - val_acc: 0.7391\n",
      "Epoch 33/250\n",
      " - 0s - loss: 0.6765 - acc: 0.7358 - val_loss: 0.6770 - val_acc: 0.7391\n",
      "Epoch 34/250\n",
      " - 0s - loss: 0.6763 - acc: 0.7547 - val_loss: 0.6766 - val_acc: 0.7391\n",
      "Epoch 35/250\n",
      " - 0s - loss: 0.6751 - acc: 0.7547 - val_loss: 0.6761 - val_acc: 0.7391\n",
      "Epoch 36/250\n",
      " - 0s - loss: 0.6725 - acc: 0.7925 - val_loss: 0.6756 - val_acc: 0.7391\n",
      "Epoch 37/250\n",
      " - 0s - loss: 0.6723 - acc: 0.7736 - val_loss: 0.6751 - val_acc: 0.7391\n",
      "Epoch 38/250\n",
      " - 0s - loss: 0.6772 - acc: 0.7170 - val_loss: 0.6746 - val_acc: 0.7391\n",
      "Epoch 39/250\n",
      " - 0s - loss: 0.6719 - acc: 0.7547 - val_loss: 0.6740 - val_acc: 0.7391\n",
      "Epoch 40/250\n",
      " - 0s - loss: 0.6720 - acc: 0.7547 - val_loss: 0.6735 - val_acc: 0.7391\n",
      "Epoch 41/250\n",
      " - 0s - loss: 0.6701 - acc: 0.7736 - val_loss: 0.6730 - val_acc: 0.7391\n",
      "Epoch 42/250\n",
      " - 0s - loss: 0.6704 - acc: 0.7736 - val_loss: 0.6725 - val_acc: 0.7391\n",
      "Epoch 43/250\n",
      " - 0s - loss: 0.6714 - acc: 0.7547 - val_loss: 0.6720 - val_acc: 0.7391\n",
      "Epoch 44/250\n",
      " - 0s - loss: 0.6721 - acc: 0.7170 - val_loss: 0.6715 - val_acc: 0.7391\n",
      "Epoch 45/250\n",
      " - 0s - loss: 0.6703 - acc: 0.7547 - val_loss: 0.6710 - val_acc: 0.7391\n",
      "Epoch 46/250\n",
      " - 0s - loss: 0.6658 - acc: 0.7925 - val_loss: 0.6705 - val_acc: 0.7391\n",
      "Epoch 47/250\n",
      " - 0s - loss: 0.6688 - acc: 0.7358 - val_loss: 0.6701 - val_acc: 0.7391\n",
      "Epoch 48/250\n",
      " - 0s - loss: 0.6655 - acc: 0.7925 - val_loss: 0.6696 - val_acc: 0.7391\n",
      "Epoch 49/250\n",
      " - 0s - loss: 0.6642 - acc: 0.7925 - val_loss: 0.6692 - val_acc: 0.7391\n",
      "Epoch 50/250\n",
      " - 0s - loss: 0.6681 - acc: 0.7547 - val_loss: 0.6685 - val_acc: 0.7391\n",
      "Epoch 51/250\n",
      " - 0s - loss: 0.6617 - acc: 0.7925 - val_loss: 0.6679 - val_acc: 0.7391\n",
      "Epoch 52/250\n",
      " - 0s - loss: 0.6609 - acc: 0.7925 - val_loss: 0.6673 - val_acc: 0.7391\n",
      "Epoch 53/250\n",
      " - 0s - loss: 0.6645 - acc: 0.7736 - val_loss: 0.6666 - val_acc: 0.7391\n",
      "Epoch 54/250\n",
      " - 0s - loss: 0.6652 - acc: 0.7547 - val_loss: 0.6659 - val_acc: 0.7391\n",
      "Epoch 55/250\n",
      " - 0s - loss: 0.6615 - acc: 0.7547 - val_loss: 0.6654 - val_acc: 0.7391\n",
      "Epoch 56/250\n",
      " - 0s - loss: 0.6572 - acc: 0.7925 - val_loss: 0.6649 - val_acc: 0.7391\n",
      "Epoch 57/250\n",
      " - 0s - loss: 0.6627 - acc: 0.7736 - val_loss: 0.6643 - val_acc: 0.7391\n",
      "Epoch 58/250\n",
      " - 0s - loss: 0.6626 - acc: 0.7547 - val_loss: 0.6636 - val_acc: 0.7391\n",
      "Epoch 59/250\n",
      " - 0s - loss: 0.6644 - acc: 0.7358 - val_loss: 0.6630 - val_acc: 0.7391\n",
      "Epoch 60/250\n",
      " - 0s - loss: 0.6541 - acc: 0.8113 - val_loss: 0.6625 - val_acc: 0.7391\n",
      "Epoch 61/250\n",
      " - 0s - loss: 0.6528 - acc: 0.7925 - val_loss: 0.6620 - val_acc: 0.7391\n",
      "Epoch 62/250\n",
      " - 0s - loss: 0.6573 - acc: 0.7547 - val_loss: 0.6615 - val_acc: 0.7391\n",
      "Epoch 63/250\n",
      " - 0s - loss: 0.6566 - acc: 0.7736 - val_loss: 0.6610 - val_acc: 0.7391\n",
      "Epoch 64/250\n",
      " - 0s - loss: 0.6543 - acc: 0.7925 - val_loss: 0.6606 - val_acc: 0.7391\n",
      "Epoch 65/250\n",
      " - 0s - loss: 0.6493 - acc: 0.7925 - val_loss: 0.6601 - val_acc: 0.7391\n",
      "Epoch 66/250\n",
      " - 0s - loss: 0.6517 - acc: 0.7547 - val_loss: 0.6596 - val_acc: 0.7391\n",
      "Epoch 67/250\n",
      " - 0s - loss: 0.6491 - acc: 0.7925 - val_loss: 0.6592 - val_acc: 0.7391\n",
      "Epoch 68/250\n",
      " - 0s - loss: 0.6515 - acc: 0.7925 - val_loss: 0.6588 - val_acc: 0.7391\n",
      "Epoch 69/250\n",
      " - 0s - loss: 0.6502 - acc: 0.7547 - val_loss: 0.6584 - val_acc: 0.7391\n",
      "Epoch 70/250\n",
      " - 0s - loss: 0.6488 - acc: 0.7736 - val_loss: 0.6581 - val_acc: 0.7391\n",
      "Epoch 71/250\n",
      " - 0s - loss: 0.6524 - acc: 0.7925 - val_loss: 0.6578 - val_acc: 0.7391\n",
      "Epoch 72/250\n",
      " - 0s - loss: 0.6455 - acc: 0.7736 - val_loss: 0.6574 - val_acc: 0.7391\n",
      "Epoch 73/250\n",
      " - 0s - loss: 0.6367 - acc: 0.8113 - val_loss: 0.6572 - val_acc: 0.7391\n",
      "Epoch 74/250\n",
      " - 0s - loss: 0.6312 - acc: 0.8491 - val_loss: 0.6570 - val_acc: 0.6957\n",
      "Epoch 75/250\n",
      " - 0s - loss: 0.6470 - acc: 0.7736 - val_loss: 0.6568 - val_acc: 0.6957\n",
      "Epoch 76/250\n",
      " - 0s - loss: 0.6466 - acc: 0.7736 - val_loss: 0.6566 - val_acc: 0.6957\n",
      "Epoch 77/250\n",
      " - 0s - loss: 0.6373 - acc: 0.8113 - val_loss: 0.6564 - val_acc: 0.6957\n",
      "Epoch 78/250\n",
      " - 0s - loss: 0.6412 - acc: 0.7736 - val_loss: 0.6562 - val_acc: 0.6957\n",
      "Epoch 79/250\n",
      " - 0s - loss: 0.6334 - acc: 0.8491 - val_loss: 0.6561 - val_acc: 0.6957\n",
      "Epoch 80/250\n",
      " - 0s - loss: 0.6346 - acc: 0.8113 - val_loss: 0.6559 - val_acc: 0.6957\n",
      "Epoch 81/250\n",
      " - 0s - loss: 0.6295 - acc: 0.8113 - val_loss: 0.6559 - val_acc: 0.6957\n",
      "Epoch 82/250\n",
      " - 0s - loss: 0.6425 - acc: 0.7925 - val_loss: 0.6559 - val_acc: 0.6957\n",
      "Epoch 83/250\n",
      " - 0s - loss: 0.6409 - acc: 0.7170 - val_loss: 0.6559 - val_acc: 0.6957\n",
      "Epoch 84/250\n",
      " - 0s - loss: 0.6260 - acc: 0.8491 - val_loss: 0.6559 - val_acc: 0.6957\n",
      "Epoch 85/250\n",
      " - 0s - loss: 0.6246 - acc: 0.8302 - val_loss: 0.6559 - val_acc: 0.6957\n",
      "Epoch 86/250\n",
      " - 0s - loss: 0.6228 - acc: 0.8491 - val_loss: 0.6558 - val_acc: 0.6957\n",
      "Epoch 87/250\n",
      " - 0s - loss: 0.6207 - acc: 0.8679 - val_loss: 0.6557 - val_acc: 0.6957\n",
      "Epoch 88/250\n",
      " - 0s - loss: 0.6266 - acc: 0.8113 - val_loss: 0.6556 - val_acc: 0.6957\n",
      "Epoch 89/250\n",
      " - 0s - loss: 0.6162 - acc: 0.8491 - val_loss: 0.6554 - val_acc: 0.6957\n",
      "Epoch 90/250\n",
      " - 0s - loss: 0.6252 - acc: 0.7925 - val_loss: 0.6552 - val_acc: 0.6957\n",
      "Epoch 91/250\n",
      " - 0s - loss: 0.6367 - acc: 0.7547 - val_loss: 0.6550 - val_acc: 0.6957\n",
      "Epoch 92/250\n",
      " - 0s - loss: 0.6061 - acc: 0.8679 - val_loss: 0.6548 - val_acc: 0.6957\n",
      "Epoch 93/250\n",
      " - 0s - loss: 0.5960 - acc: 0.8868 - val_loss: 0.6546 - val_acc: 0.6957\n",
      "Epoch 94/250\n",
      " - 0s - loss: 0.6182 - acc: 0.8113 - val_loss: 0.6545 - val_acc: 0.6522\n",
      "Epoch 95/250\n",
      " - 0s - loss: 0.6153 - acc: 0.8113 - val_loss: 0.6540 - val_acc: 0.6522\n",
      "Epoch 96/250\n",
      " - 0s - loss: 0.6073 - acc: 0.8302 - val_loss: 0.6536 - val_acc: 0.6522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/250\n",
      " - 0s - loss: 0.5954 - acc: 0.8491 - val_loss: 0.6532 - val_acc: 0.6522\n",
      "Epoch 98/250\n",
      " - 0s - loss: 0.6044 - acc: 0.8113 - val_loss: 0.6529 - val_acc: 0.6522\n",
      "Epoch 99/250\n",
      " - 0s - loss: 0.6038 - acc: 0.8679 - val_loss: 0.6526 - val_acc: 0.6522\n",
      "Epoch 100/250\n",
      " - 0s - loss: 0.5745 - acc: 0.8868 - val_loss: 0.6523 - val_acc: 0.6522\n",
      "Epoch 101/250\n",
      " - 0s - loss: 0.5877 - acc: 0.8302 - val_loss: 0.6519 - val_acc: 0.6522\n",
      "Epoch 102/250\n",
      " - 0s - loss: 0.5968 - acc: 0.8113 - val_loss: 0.6515 - val_acc: 0.6522\n",
      "Epoch 103/250\n",
      " - 0s - loss: 0.5774 - acc: 0.9057 - val_loss: 0.6511 - val_acc: 0.6522\n",
      "Epoch 104/250\n",
      " - 0s - loss: 0.5768 - acc: 0.9057 - val_loss: 0.6509 - val_acc: 0.6522\n",
      "Epoch 105/250\n",
      " - 0s - loss: 0.6047 - acc: 0.8302 - val_loss: 0.6506 - val_acc: 0.6522\n",
      "Epoch 106/250\n",
      " - 0s - loss: 0.5676 - acc: 0.8679 - val_loss: 0.6501 - val_acc: 0.6957\n",
      "Epoch 107/250\n",
      " - 0s - loss: 0.5600 - acc: 0.8868 - val_loss: 0.6496 - val_acc: 0.6957\n",
      "Epoch 108/250\n",
      " - 0s - loss: 0.5855 - acc: 0.8302 - val_loss: 0.6492 - val_acc: 0.6957\n",
      "Epoch 109/250\n",
      " - 0s - loss: 0.5744 - acc: 0.8868 - val_loss: 0.6488 - val_acc: 0.6957\n",
      "Epoch 110/250\n",
      " - 0s - loss: 0.5788 - acc: 0.8491 - val_loss: 0.6485 - val_acc: 0.6957\n",
      "Epoch 111/250\n",
      " - 0s - loss: 0.5521 - acc: 0.8679 - val_loss: 0.6480 - val_acc: 0.6957\n",
      "Epoch 112/250\n",
      " - 0s - loss: 0.5869 - acc: 0.7925 - val_loss: 0.6475 - val_acc: 0.6957\n",
      "Epoch 113/250\n",
      " - 0s - loss: 0.5669 - acc: 0.8679 - val_loss: 0.6472 - val_acc: 0.6957\n",
      "Epoch 114/250\n",
      " - 0s - loss: 0.5550 - acc: 0.8868 - val_loss: 0.6468 - val_acc: 0.6957\n",
      "Epoch 115/250\n",
      " - 0s - loss: 0.5590 - acc: 0.8679 - val_loss: 0.6465 - val_acc: 0.6957\n",
      "Epoch 116/250\n",
      " - 0s - loss: 0.5587 - acc: 0.8868 - val_loss: 0.6461 - val_acc: 0.6957\n",
      "Epoch 117/250\n",
      " - 0s - loss: 0.5422 - acc: 0.9057 - val_loss: 0.6457 - val_acc: 0.6957\n",
      "Epoch 118/250\n",
      " - 0s - loss: 0.5410 - acc: 0.8868 - val_loss: 0.6452 - val_acc: 0.7826\n",
      "Epoch 119/250\n",
      " - 0s - loss: 0.5184 - acc: 0.9245 - val_loss: 0.6449 - val_acc: 0.7826\n",
      "Epoch 120/250\n",
      " - 0s - loss: 0.5328 - acc: 0.8868 - val_loss: 0.6449 - val_acc: 0.7826\n",
      "Epoch 121/250\n",
      " - 0s - loss: 0.5032 - acc: 0.9245 - val_loss: 0.6448 - val_acc: 0.7826\n",
      "Epoch 122/250\n",
      " - 0s - loss: 0.5357 - acc: 0.8679 - val_loss: 0.6447 - val_acc: 0.7826\n",
      "Epoch 123/250\n",
      " - 0s - loss: 0.5406 - acc: 0.8491 - val_loss: 0.6445 - val_acc: 0.7826\n",
      "Epoch 124/250\n",
      " - 0s - loss: 0.5441 - acc: 0.8868 - val_loss: 0.6445 - val_acc: 0.7826\n",
      "Epoch 125/250\n",
      " - 0s - loss: 0.5628 - acc: 0.8302 - val_loss: 0.6444 - val_acc: 0.7826\n",
      "Epoch 126/250\n",
      " - 0s - loss: 0.5079 - acc: 0.9057 - val_loss: 0.6443 - val_acc: 0.7826\n",
      "Epoch 127/250\n",
      " - 0s - loss: 0.5105 - acc: 0.9434 - val_loss: 0.6443 - val_acc: 0.7826\n",
      "Epoch 128/250\n",
      " - 0s - loss: 0.5273 - acc: 0.9245 - val_loss: 0.6445 - val_acc: 0.7826\n",
      "Epoch 129/250\n",
      " - 0s - loss: 0.5320 - acc: 0.8868 - val_loss: 0.6447 - val_acc: 0.7826\n",
      "Epoch 130/250\n",
      " - 0s - loss: 0.4942 - acc: 0.9811 - val_loss: 0.6450 - val_acc: 0.7826\n",
      "Epoch 131/250\n",
      " - 0s - loss: 0.4872 - acc: 0.9623 - val_loss: 0.6454 - val_acc: 0.7826\n",
      "Epoch 132/250\n",
      " - 0s - loss: 0.5078 - acc: 0.9434 - val_loss: 0.6459 - val_acc: 0.7826\n",
      "Epoch 133/250\n",
      " - 0s - loss: 0.5277 - acc: 0.9057 - val_loss: 0.6463 - val_acc: 0.7826\n",
      "Epoch 134/250\n",
      " - 0s - loss: 0.5123 - acc: 0.8868 - val_loss: 0.6466 - val_acc: 0.7826\n",
      "Epoch 135/250\n",
      " - 0s - loss: 0.4984 - acc: 0.9245 - val_loss: 0.6466 - val_acc: 0.7826\n",
      "Epoch 136/250\n",
      " - 0s - loss: 0.4945 - acc: 0.9057 - val_loss: 0.6460 - val_acc: 0.7826\n",
      "Epoch 137/250\n",
      " - 0s - loss: 0.5182 - acc: 0.9057 - val_loss: 0.6454 - val_acc: 0.7826\n",
      "Epoch 138/250\n",
      " - 0s - loss: 0.4918 - acc: 0.9434 - val_loss: 0.6447 - val_acc: 0.7826\n",
      "Epoch 139/250\n",
      " - 0s - loss: 0.4552 - acc: 0.9811 - val_loss: 0.6442 - val_acc: 0.7826\n",
      "Epoch 140/250\n",
      " - 0s - loss: 0.4987 - acc: 0.9245 - val_loss: 0.6438 - val_acc: 0.7826\n",
      "Epoch 141/250\n",
      " - 0s - loss: 0.4886 - acc: 0.9057 - val_loss: 0.6432 - val_acc: 0.7826\n",
      "Epoch 142/250\n",
      " - 0s - loss: 0.4620 - acc: 0.9434 - val_loss: 0.6426 - val_acc: 0.7826\n",
      "Epoch 143/250\n",
      " - 0s - loss: 0.4604 - acc: 0.9434 - val_loss: 0.6421 - val_acc: 0.7826\n",
      "Epoch 144/250\n",
      " - 0s - loss: 0.4578 - acc: 0.9623 - val_loss: 0.6418 - val_acc: 0.7826\n",
      "Epoch 145/250\n",
      " - 0s - loss: 0.4454 - acc: 0.9434 - val_loss: 0.6416 - val_acc: 0.7826\n",
      "Epoch 146/250\n",
      " - 0s - loss: 0.4596 - acc: 0.9434 - val_loss: 0.6413 - val_acc: 0.7826\n",
      "Epoch 147/250\n",
      " - 0s - loss: 0.4429 - acc: 0.9623 - val_loss: 0.6412 - val_acc: 0.7826\n",
      "Epoch 148/250\n",
      " - 0s - loss: 0.4368 - acc: 0.9245 - val_loss: 0.6407 - val_acc: 0.7826\n",
      "Epoch 149/250\n",
      " - 0s - loss: 0.4355 - acc: 0.9811 - val_loss: 0.6404 - val_acc: 0.7826\n",
      "Epoch 150/250\n",
      " - 0s - loss: 0.4459 - acc: 0.9434 - val_loss: 0.6403 - val_acc: 0.7826\n",
      "Epoch 151/250\n",
      " - 0s - loss: 0.5141 - acc: 0.9057 - val_loss: 0.6402 - val_acc: 0.7826\n",
      "Epoch 152/250\n",
      " - 0s - loss: 0.4489 - acc: 0.9434 - val_loss: 0.6402 - val_acc: 0.7826\n",
      "Epoch 153/250\n",
      " - 0s - loss: 0.4579 - acc: 0.9623 - val_loss: 0.6400 - val_acc: 0.7826\n",
      "Epoch 154/250\n",
      " - 0s - loss: 0.4222 - acc: 0.9623 - val_loss: 0.6397 - val_acc: 0.7826\n",
      "Epoch 155/250\n",
      " - 0s - loss: 0.4439 - acc: 0.9434 - val_loss: 0.6392 - val_acc: 0.7826\n",
      "Epoch 156/250\n",
      " - 0s - loss: 0.4501 - acc: 0.9623 - val_loss: 0.6390 - val_acc: 0.7826\n",
      "Epoch 157/250\n",
      " - 0s - loss: 0.4259 - acc: 0.9623 - val_loss: 0.6392 - val_acc: 0.7826\n",
      "Epoch 158/250\n",
      " - 0s - loss: 0.4544 - acc: 0.9245 - val_loss: 0.6395 - val_acc: 0.7826\n",
      "Epoch 159/250\n",
      " - 0s - loss: 0.4259 - acc: 0.9245 - val_loss: 0.6398 - val_acc: 0.7826\n",
      "Epoch 160/250\n",
      " - 0s - loss: 0.3777 - acc: 1.0000 - val_loss: 0.6401 - val_acc: 0.7826\n",
      "Epoch 161/250\n",
      " - 0s - loss: 0.3841 - acc: 1.0000 - val_loss: 0.6405 - val_acc: 0.7826\n",
      "Epoch 162/250\n",
      " - 0s - loss: 0.4422 - acc: 0.9057 - val_loss: 0.6412 - val_acc: 0.7826\n",
      "Epoch 163/250\n",
      " - 0s - loss: 0.4227 - acc: 0.9811 - val_loss: 0.6418 - val_acc: 0.7826\n",
      "Epoch 164/250\n",
      " - 0s - loss: 0.4082 - acc: 0.9623 - val_loss: 0.6420 - val_acc: 0.7826\n",
      "Epoch 165/250\n",
      " - 0s - loss: 0.4143 - acc: 0.9434 - val_loss: 0.6423 - val_acc: 0.7826\n",
      "Epoch 166/250\n",
      " - 0s - loss: 0.4117 - acc: 0.9623 - val_loss: 0.6428 - val_acc: 0.7826\n",
      "Epoch 167/250\n",
      " - 0s - loss: 0.4102 - acc: 0.9623 - val_loss: 0.6433 - val_acc: 0.7826\n",
      "Epoch 168/250\n",
      " - 0s - loss: 0.4305 - acc: 0.9434 - val_loss: 0.6431 - val_acc: 0.7826\n",
      "Epoch 169/250\n",
      " - 0s - loss: 0.4066 - acc: 0.9434 - val_loss: 0.6424 - val_acc: 0.7826\n",
      "Epoch 170/250\n",
      " - 0s - loss: 0.3906 - acc: 0.9623 - val_loss: 0.6419 - val_acc: 0.7826\n",
      "Epoch 171/250\n",
      " - 0s - loss: 0.4135 - acc: 0.9434 - val_loss: 0.6411 - val_acc: 0.7826\n",
      "Epoch 172/250\n",
      " - 0s - loss: 0.3798 - acc: 0.9623 - val_loss: 0.6406 - val_acc: 0.7826\n",
      "Epoch 173/250\n",
      " - 0s - loss: 0.4023 - acc: 0.9434 - val_loss: 0.6403 - val_acc: 0.7826\n",
      "Epoch 174/250\n",
      " - 0s - loss: 0.3758 - acc: 1.0000 - val_loss: 0.6403 - val_acc: 0.7826\n",
      "Epoch 175/250\n",
      " - 0s - loss: 0.4028 - acc: 0.9434 - val_loss: 0.6408 - val_acc: 0.7826\n",
      "Epoch 176/250\n",
      " - 0s - loss: 0.4010 - acc: 0.9434 - val_loss: 0.6416 - val_acc: 0.7826\n",
      "Epoch 177/250\n",
      " - 0s - loss: 0.3662 - acc: 0.9811 - val_loss: 0.6422 - val_acc: 0.7826\n",
      "Epoch 178/250\n",
      " - 0s - loss: 0.4032 - acc: 0.9811 - val_loss: 0.6430 - val_acc: 0.7826\n",
      "Epoch 179/250\n",
      " - 0s - loss: 0.3998 - acc: 0.9623 - val_loss: 0.6441 - val_acc: 0.7826\n",
      "Epoch 180/250\n",
      " - 0s - loss: 0.3763 - acc: 1.0000 - val_loss: 0.6454 - val_acc: 0.7826\n",
      "Epoch 181/250\n",
      " - 0s - loss: 0.3633 - acc: 0.9811 - val_loss: 0.6468 - val_acc: 0.7826\n",
      "Epoch 182/250\n",
      " - 0s - loss: 0.3998 - acc: 0.9623 - val_loss: 0.6481 - val_acc: 0.7826\n",
      "Epoch 183/250\n",
      " - 0s - loss: 0.4036 - acc: 0.9434 - val_loss: 0.6486 - val_acc: 0.7826\n",
      "Epoch 184/250\n",
      " - 0s - loss: 0.3797 - acc: 0.9623 - val_loss: 0.6490 - val_acc: 0.7826\n",
      "Epoch 185/250\n",
      " - 0s - loss: 0.3508 - acc: 1.0000 - val_loss: 0.6493 - val_acc: 0.7826\n",
      "Epoch 186/250\n",
      " - 0s - loss: 0.3835 - acc: 0.9623 - val_loss: 0.6497 - val_acc: 0.7826\n",
      "Epoch 187/250\n",
      " - 0s - loss: 0.3674 - acc: 0.9623 - val_loss: 0.6505 - val_acc: 0.7826\n",
      "Epoch 188/250\n",
      " - 0s - loss: 0.3775 - acc: 0.9623 - val_loss: 0.6511 - val_acc: 0.7826\n",
      "Epoch 189/250\n",
      " - 0s - loss: 0.4080 - acc: 0.9245 - val_loss: 0.6517 - val_acc: 0.7826\n",
      "Epoch 190/250\n",
      " - 0s - loss: 0.3559 - acc: 0.9623 - val_loss: 0.6523 - val_acc: 0.7826\n",
      "Epoch 191/250\n",
      " - 0s - loss: 0.3287 - acc: 1.0000 - val_loss: 0.6529 - val_acc: 0.7826\n",
      "Epoch 192/250\n",
      " - 0s - loss: 0.3953 - acc: 0.9434 - val_loss: 0.6538 - val_acc: 0.7826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/250\n",
      " - 0s - loss: 0.3789 - acc: 0.9434 - val_loss: 0.6551 - val_acc: 0.7826\n",
      "Epoch 194/250\n",
      " - 0s - loss: 0.3399 - acc: 0.9811 - val_loss: 0.6565 - val_acc: 0.7826\n",
      "Epoch 195/250\n",
      " - 0s - loss: 0.3935 - acc: 0.9245 - val_loss: 0.6580 - val_acc: 0.7826\n",
      "Epoch 196/250\n",
      " - 0s - loss: 0.3726 - acc: 0.9434 - val_loss: 0.6594 - val_acc: 0.7826\n",
      "Epoch 197/250\n",
      " - 0s - loss: 0.3560 - acc: 0.9434 - val_loss: 0.6608 - val_acc: 0.7826\n",
      "Epoch 198/250\n",
      " - 0s - loss: 0.3302 - acc: 0.9811 - val_loss: 0.6622 - val_acc: 0.7826\n",
      "Epoch 199/250\n",
      " - 0s - loss: 0.3705 - acc: 0.9811 - val_loss: 0.6640 - val_acc: 0.7826\n",
      "Epoch 200/250\n",
      " - 0s - loss: 0.3662 - acc: 0.9434 - val_loss: 0.6660 - val_acc: 0.7826\n",
      "Epoch 201/250\n",
      " - 0s - loss: 0.3583 - acc: 0.9623 - val_loss: 0.6678 - val_acc: 0.7826\n",
      "Epoch 202/250\n",
      " - 0s - loss: 0.3385 - acc: 0.9811 - val_loss: 0.6698 - val_acc: 0.7826\n",
      "Epoch 203/250\n",
      " - 0s - loss: 0.3898 - acc: 0.9434 - val_loss: 0.6715 - val_acc: 0.7826\n",
      "Epoch 204/250\n",
      " - 0s - loss: 0.3396 - acc: 0.9811 - val_loss: 0.6730 - val_acc: 0.7826\n",
      "Epoch 205/250\n",
      " - 0s - loss: 0.3245 - acc: 1.0000 - val_loss: 0.6739 - val_acc: 0.7826\n",
      "Epoch 206/250\n",
      " - 0s - loss: 0.3096 - acc: 0.9811 - val_loss: 0.6742 - val_acc: 0.7826\n",
      "Epoch 207/250\n",
      " - 0s - loss: 0.3634 - acc: 0.9434 - val_loss: 0.6748 - val_acc: 0.7826\n",
      "Epoch 208/250\n",
      " - 0s - loss: 0.2945 - acc: 1.0000 - val_loss: 0.6756 - val_acc: 0.7826\n",
      "Epoch 209/250\n",
      " - 0s - loss: 0.3976 - acc: 0.9057 - val_loss: 0.6763 - val_acc: 0.7826\n",
      "Epoch 210/250\n",
      " - 0s - loss: 0.3293 - acc: 0.9434 - val_loss: 0.6771 - val_acc: 0.7826\n",
      "Epoch 211/250\n",
      " - 0s - loss: 0.2903 - acc: 1.0000 - val_loss: 0.6786 - val_acc: 0.7826\n",
      "Epoch 212/250\n",
      " - 0s - loss: 0.3033 - acc: 0.9811 - val_loss: 0.6799 - val_acc: 0.7826\n",
      "Epoch 213/250\n",
      " - 0s - loss: 0.3546 - acc: 0.9434 - val_loss: 0.6817 - val_acc: 0.7826\n",
      "Epoch 214/250\n",
      " - 0s - loss: 0.3073 - acc: 0.9811 - val_loss: 0.6839 - val_acc: 0.7826\n",
      "Epoch 215/250\n",
      " - 0s - loss: 0.2968 - acc: 0.9811 - val_loss: 0.6859 - val_acc: 0.7826\n",
      "Epoch 216/250\n",
      " - 0s - loss: 0.3129 - acc: 0.9623 - val_loss: 0.6880 - val_acc: 0.7826\n",
      "Epoch 217/250\n",
      " - 0s - loss: 0.3405 - acc: 0.9623 - val_loss: 0.6903 - val_acc: 0.7826\n",
      "Epoch 218/250\n",
      " - 0s - loss: 0.3212 - acc: 0.9623 - val_loss: 0.6918 - val_acc: 0.7826\n",
      "Epoch 219/250\n",
      " - 0s - loss: 0.2930 - acc: 0.9811 - val_loss: 0.6928 - val_acc: 0.7826\n",
      "Epoch 220/250\n",
      " - 0s - loss: 0.2769 - acc: 0.9811 - val_loss: 0.6937 - val_acc: 0.7826\n",
      "Epoch 221/250\n",
      " - 0s - loss: 0.2858 - acc: 0.9811 - val_loss: 0.6944 - val_acc: 0.7826\n",
      "Epoch 222/250\n",
      " - 0s - loss: 0.3016 - acc: 0.9811 - val_loss: 0.6949 - val_acc: 0.7826\n",
      "Epoch 223/250\n",
      " - 0s - loss: 0.3135 - acc: 0.9623 - val_loss: 0.6949 - val_acc: 0.7826\n",
      "Epoch 224/250\n",
      " - 0s - loss: 0.3023 - acc: 0.9623 - val_loss: 0.6943 - val_acc: 0.7826\n",
      "Epoch 225/250\n",
      " - 0s - loss: 0.3115 - acc: 1.0000 - val_loss: 0.6946 - val_acc: 0.7826\n",
      "Epoch 226/250\n",
      " - 0s - loss: 0.3183 - acc: 0.9623 - val_loss: 0.6957 - val_acc: 0.7826\n",
      "Epoch 227/250\n",
      " - 0s - loss: 0.3078 - acc: 0.9623 - val_loss: 0.6972 - val_acc: 0.7826\n",
      "Epoch 228/250\n",
      " - 0s - loss: 0.2938 - acc: 0.9811 - val_loss: 0.6984 - val_acc: 0.7826\n",
      "Epoch 229/250\n",
      " - 0s - loss: 0.2854 - acc: 0.9811 - val_loss: 0.6975 - val_acc: 0.7826\n",
      "Epoch 230/250\n",
      " - 0s - loss: 0.3246 - acc: 0.9434 - val_loss: 0.6969 - val_acc: 0.7826\n",
      "Epoch 231/250\n",
      " - 0s - loss: 0.2678 - acc: 1.0000 - val_loss: 0.6966 - val_acc: 0.7826\n",
      "Epoch 232/250\n",
      " - 0s - loss: 0.3158 - acc: 0.9434 - val_loss: 0.6954 - val_acc: 0.7826\n",
      "Epoch 233/250\n",
      " - 0s - loss: 0.2760 - acc: 1.0000 - val_loss: 0.6949 - val_acc: 0.7826\n",
      "Epoch 234/250\n",
      " - 0s - loss: 0.3116 - acc: 0.9434 - val_loss: 0.6931 - val_acc: 0.7826\n",
      "Epoch 235/250\n",
      " - 0s - loss: 0.3026 - acc: 0.9623 - val_loss: 0.6919 - val_acc: 0.7826\n",
      "Epoch 236/250\n",
      " - 0s - loss: 0.2680 - acc: 1.0000 - val_loss: 0.6914 - val_acc: 0.7826\n",
      "Epoch 237/250\n",
      " - 0s - loss: 0.2837 - acc: 0.9811 - val_loss: 0.6915 - val_acc: 0.7826\n",
      "Epoch 238/250\n",
      " - 0s - loss: 0.3091 - acc: 0.9623 - val_loss: 0.6924 - val_acc: 0.7826\n",
      "Epoch 239/250\n",
      " - 0s - loss: 0.2773 - acc: 0.9811 - val_loss: 0.6938 - val_acc: 0.7826\n",
      "Epoch 240/250\n",
      " - 0s - loss: 0.2600 - acc: 1.0000 - val_loss: 0.6955 - val_acc: 0.7826\n",
      "Epoch 241/250\n",
      " - 0s - loss: 0.3007 - acc: 0.9434 - val_loss: 0.6974 - val_acc: 0.7826\n",
      "Epoch 242/250\n",
      " - 0s - loss: 0.2915 - acc: 0.9811 - val_loss: 0.6999 - val_acc: 0.7826\n",
      "Epoch 243/250\n",
      " - 0s - loss: 0.2544 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.7826\n",
      "Epoch 244/250\n",
      " - 0s - loss: 0.2635 - acc: 0.9811 - val_loss: 0.7054 - val_acc: 0.7826\n",
      "Epoch 245/250\n",
      " - 0s - loss: 0.2344 - acc: 1.0000 - val_loss: 0.7076 - val_acc: 0.7826\n",
      "Epoch 246/250\n",
      " - 0s - loss: 0.3169 - acc: 0.9434 - val_loss: 0.7096 - val_acc: 0.7826\n",
      "Epoch 247/250\n",
      " - 0s - loss: 0.2615 - acc: 1.0000 - val_loss: 0.7121 - val_acc: 0.7826\n",
      "Epoch 248/250\n",
      " - 0s - loss: 0.2361 - acc: 1.0000 - val_loss: 0.7147 - val_acc: 0.7826\n",
      "Epoch 249/250\n",
      " - 0s - loss: 0.2343 - acc: 1.0000 - val_loss: 0.7171 - val_acc: 0.7826\n",
      "Epoch 250/250\n",
      " - 0s - loss: 0.3010 - acc: 0.9434 - val_loss: 0.7192 - val_acc: 0.7826\n"
     ]
    }
   ],
   "source": [
    "mlp_farewell = mlp_farewell(shape)\n",
    "history = mlp_farewell.fit(X_train, np.asarray(y_train[\"Search\"]).reshape(-1,1),\n",
    "                  validation_data=(X_validation, np.asarray(y_validation[\"Search\"]).reshape(-1,1)),\n",
    "    epochs=250,\n",
    "    workers = 2, use_multiprocessing= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHATBOT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    \n",
    "    input_text = input()\n",
    "    \n",
    "    test = pd.DataFrame(data = {'Sentence': [input_text]})\n",
    "    df_test_proc, test_proc = processing(test, cv = cv)\n",
    "\n",
    "    gret_prob = mlp_greeting.predict_proba(test_proc)\n",
    "    search_prob = mlp_search.predict_proba(test_proc)\n",
    "    sugg_prob = mlp_suggestion.predict_proba(test_proc)\n",
    "    \n",
    "    probs = [gret_prob, search_prob, sugg_prob]\n",
    "    idx = np.argmax(probs)\n",
    "    \n",
    "    if idx == 0:\n",
    "        print(\"Esto es un saludo\")\n",
    "    elif idx == 1:\n",
    "        print(\"Esto es una b煤squeda\")\n",
    "    else:\n",
    "        print(\"Esto es una sugerencia\")\n",
    "        \n",
    "#     print('驴Hemos acertado?')\n",
    "    \n",
    "#     respuesta = input()\n",
    "#     if (respuesta == 'No' or respuesta == 'no'):\n",
    "#         probs = np.delete(probs, idx)\n",
    "#         idx_2 = np.argmax(probs)\n",
    "        \n",
    "#         if idx == 0:\n",
    "#             if idx_2 == 0:\n",
    "#                 print(\"Esto es una b煤squeda\")\n",
    "#             else:\n",
    "#                 print(\"Esto es una sugerencia\")\n",
    "#         elif idx == 1:\n",
    "#             if idx_2 == 0:\n",
    "#                 print(\"Esto es un saludo\")\n",
    "#             else:\n",
    "#                 print(\"Esto es una sugerencia\")\n",
    "#         else:\n",
    "#             if idx_2 == 0:\n",
    "#                 print(\"Esto es un saludo\")\n",
    "#             else:\n",
    "#                 print(\"Esto es una b煤squeda\")\n",
    "#     else:\n",
    "#         print('隆Genial! 隆Hemos acertado!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me things related to Napoleon\n",
      "Esto es un saludo\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Correctamente\n",
    " * La mayor铆a de saludos\n",
    " * I want to know about Data Science (b煤squeda)\n",
    " * I want to know things connected to la Sagrada Familia (sugerencia)\n",
    " * Watcha doing'? (saludo)\n",
    " * Tell me things related to Data Science (sugerencia)\n",
    "\n",
    "* Incorrectamente\n",
    " * What is Data Science (sugerencia)\n",
    " * Tell me things related to Napoleon (saludo)\n",
    " * Who is Cristobal Colon (saludo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Opciones\n",
    " * Mostrar un comando *!options* que te de las opciones para hacer.\n",
    " * Detectar un intent\n",
    " * Mostrarlo al inicio\n",
    "\n",
    "\n",
    "* Headers\n",
    " * Dar las opciones una vez se detecta intent de b煤squeda b煤squeda\n",
    "   * *What is data science?* Y mostrarle los heades para qu茅 elija qu茅 queire saber \n",
    " * Intent nuevo de header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
