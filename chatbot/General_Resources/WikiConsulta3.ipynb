{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WikiConsulta3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPFHp1DvUmIWaUOHyd6t7Sg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cFbsMH76ZGlN"},"source":["### Uso de la libreria Wikipedia para Python\n","\n","Buscar la palabra en wikipedia, crear un json con los resultados de la palabra a buscar y los otros 9 resultados sugeridos.\n","\n"]},{"cell_type":"code","metadata":{"id":"YtTd_rQYSw6e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630672282702,"user_tz":-120,"elapsed":5607,"user":{"displayName":"Guillem GG","photoUrl":"","userId":"07304960059166782939"}},"outputId":"8805752f-a92e-4c43-e7e0-cae11f3040f4"},"source":["!pip install wikipedia\n","\n","import wikipedia as wiki\n","import pandas as pd\n","import numpy as np\n","import re\n","import json\n","\n","# seleccionar idioma\n","wiki.set_lang(\"en\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wikipedia\n","  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11696 sha256=bf72ed75f05ea63bbf7981170efe2259a3e74fc28aa6ab6e8d540a2f87e4e0d8\n","  Stored in directory: /root/.cache/pip/wheels/15/93/6d/5b2c68b8a64c7a7a04947b4ed6d89fb557dcc6bc27d1d7f3ba\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n"]}]},{"cell_type":"code","metadata":{"id":"FzTZ12EPqKII"},"source":["def wiki_extraction(resultados):\n","\n","  for i in range(0, len(resultados[0])):\n","    try:\n","      #print(resultados[0][i])\n","      w_page = wiki.page(resultados[0][i])\n","      # extract_apartados\n","      splitted_text = re.split(r'[\\r\\n][\\r\\n]+', w_page.content)\n","      d_apartados = {}\n","      for i in range(1, len(splitted_text)):\n","        splitted_par = re.split(\"==\\n\", splitted_text[i])\n","        #print(str(splitted_par[0].replace(\"=\",\"\").strip()))\n","        if len(splitted_par) == 1: splitted_par.append(\"\")\n","        #print(splitted_par[1])\n","        d_apartados[str(i)+\". \"+splitted_par[0].replace(\"=\",\"\").strip()] = splitted_par[1]\n","      \n","      # create_json\n","      data = {}\n","      data[\"title\"] = w_page.title\n","      data[\"summary\"] = w_page.summary\n","      data[\"content\"] = d_apartados\n","      \n","      #for i in reversed(sorted(data.items())): print(i)  \n","      \n","      n_file = data[\"title\"]+'.json'\n","      #print(n_file)\n","      with open(n_file, 'w') as file:\n","        json.dump(data, file, ensure_ascii=False)\n","\n","    except:\n","      # si la palabra a extraer da error, no para el proceso, simplemente se ignora.\n","      #print(\"---  Disambiguation error: term << \" + resultados[0][i] + \" >> Ignored  ---\")\n","      pass\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzW6pD1mojGE","executionInfo":{"status":"ok","timestamp":1630672992394,"user_tz":-120,"elapsed":6558,"user":{"displayName":"Guillem GG","photoUrl":"","userId":"07304960059166782939"}},"outputId":"c623cd0d-9b72-4111-9b00-ade3a214edd6"},"source":["#Búsqueda \n","num_resultados = 10 #número máximo de resultados al buscar\n","sugerencias = True #sugerencia de posible palabra en el caso de que no exista\n","\n","loop = True\n","while loop==True :\n","  palabra = input(\"\\n Term to search: \") #idea a buscar en wikipedia\n","  resultados = wiki.search(palabra, num_resultados, sugerencias)\n","\n","  if (resultados[1] == None) : #no hay sugerencia porque se encuentra lo buscado\n","    print(\"Extracting information for <<\"+str(palabra)+\">>\\n\")\n","    wiki_extraction(resultados)\n","\n","    print(\"Title: \\n\" + wiki.page(resultados[0][0]).title +\"\\n\")\n","    print(\"Summary: \\n\" + wiki.page(resultados[0][0]).summary)\n","    \n","    loop = False\n","  else:  #no se encuentra en wiki lo que busca y da una sugerencia\n","    print(\" << \"+ str(palabra)+ \" >> not found. Suggestion: \\n\")\n","    print(resultados[1])\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Term to search: data science\n","Extracting information for <<data science>>\n","\n","Title: \n","Data science\n","\n","Summary: \n","Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. Data science is related to data mining, machine learning and big data.\n","Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyze actual phenomena\" with data. It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"VLZMlTGSxsef"},"source":["#integrado en la funcion principal\n","def extract_apartados(contenido):\n","  splitted_text = re.split(r'[\\r\\n][\\r\\n]+', contenido.content)\n","  d_apartados = {}\n","  for i in range(1, len(splitted_text)):\n","    splitted_par = re.split(\"==\\n\", splitted_text[i])\n","    #print(str(splitted_par[0].replace(\"=\",\"\").strip()))\n","    if len(splitted_par) == 1: splitted_par.append(\"\")\n","    #print(splitted_par[1])\n","    d_apartados[str(i)+\". \"+splitted_par[0].replace(\"=\",\"\").strip()] = splitted_par[1]\n","  return d_apartados"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_U6cziTtx2rn"},"source":["#integrado en la funcion principal\n","def create_json(contenido, apartados):\n","  data = {}\n","  data[\"title\"] = contenido.title\n","  data[\"summary\"] = contenido.summary\n","  data[\"content\"] = apartados\n","  \n","  for i in reversed(sorted(data.items())): print(i)  \n","  \n","  n_file = data[\"title\"]+'.json'\n","  print(n_file)\n","  with open(n_file, 'w') as file:\n","    json.dump(data, file, ensure_ascii=False)"],"execution_count":null,"outputs":[]}]}